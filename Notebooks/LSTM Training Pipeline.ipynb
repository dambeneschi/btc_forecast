{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZojMHtim_IOE"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,12)\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Bidirectional\n",
    "#from keras.losses import BinaryCrossentropy\n",
    "from keras.optimizers import RMSprop\n",
    "#from keras.metrics import AUC\n",
    "from keras import Sequential, Input\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ketVJymn_IOK"
   },
   "source": [
    "**TABLE OF CONTENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J11zUKT9_IOK"
   },
   "source": [
    "--- \n",
    "# Data Query\n",
    "## Prices Query\n",
    "- Platform is coinBase\n",
    "- BTC/USD price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "hZAUvcOA_IOL",
    "outputId": "3d8f33fb-aca8-42ca-aa36-0f58da67214b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- EUR/BTC Prices from 1589425200 to 1596625200 \n",
      "- EUR/BTC Prices from 1582225200 to 1589425200 \n",
      "- EUR/BTC Prices from 1575025200 to 1582225200 \n",
      "- EUR/BTC Prices from 1567825200 to 1575025200 \n",
      "- EUR/BTC Prices from 1560625200 to 1567825200 \n",
      "- EUR/BTC Prices from 1553425200 to 1560625200 \n",
      "- EUR/BTC Prices from 1546225200 to 1553425200 \n",
      "- EUR/BTC Prices from 1539025200 to 1546225200 \n"
     ]
    }
   ],
   "source": [
    "url_call = 'https://min-api.cryptocompare.com/data/v2/histohour?fsym=BTC&tsym={}&limit={}&e=Coinbase'\n",
    "\n",
    "# get data\n",
    "currency = 'EUR'\n",
    "n_batch_obs = 8\n",
    "n_obs = n_batch_obs * 2000\n",
    "reqs = []\n",
    "\n",
    "if n_obs > 2000:\n",
    "    \n",
    "    # Initial Call\n",
    "    req = json.loads(requests.get(url_call.format(currency, 2000)).text)\n",
    "    print('- {}/BTC Prices from {} to {} '.format(currency, req['Data']['TimeFrom'], req['Data']['TimeTo']))\n",
    "    reqs.append(req)\n",
    "    \n",
    "    for i in range(1, n_batch_obs):\n",
    "        # Second query to ave double the history if n_obs > 2000\n",
    "        req = json.loads(requests.get(url_call.format(currency, 2000) + '&toTs={}'.format(req['Data']['TimeFrom'])).text)\n",
    "        print('- {}/BTC Prices from {} to {} '.format(currency, req['Data']['TimeFrom'], req['Data']['TimeTo']))\n",
    "        reqs.append(req)\n",
    "\n",
    "else:\n",
    "\n",
    "    req = json.loads(requests.get(url_call.format(currency, n_obs)).text)\n",
    "    print('- {}/BTC Prices from {} to {} '.format(currency, req['Data']['TimeFrom'], req['Data']['TimeTo']))\n",
    "    reqs.append(req)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "6SOtyFr1_IOO",
    "outputId": "b6467d69-9cbf-405e-eb42-1264fc9eac16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15996 entries, 2018-10-08 19:00:00 to 2020-08-05 11:00:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   close       15996 non-null  float64\n",
      " 1   high        15996 non-null  float64\n",
      " 2   low         15996 non-null  float64\n",
      " 3   open        15996 non-null  float64\n",
      " 4   volumefrom  15996 non-null  float64\n",
      " 5   volumeto    15996 non-null  float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 874.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Format as dataframe & sort DatetimeIndex\n",
    "df = pd.concat([pd.DataFrame(req['Data']['Data']) for req in reqs], axis=0)\n",
    "df.index = pd.to_datetime(df['time'], origin='unix', unit='s')\n",
    "df.drop(columns=['time', 'conversionType', 'conversionSymbol'], inplace=True)\n",
    "df.sort_index(ascending=True, inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ct3eSeFu_IOR"
   },
   "source": [
    "## News query"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpNVRxWv_IOS"
   },
   "source": [
    "url_news = 'https://min-api.cryptocompare.com/data/v2/news/?lang=EN&excludeCategories=ETH,LTC,XMR,ZEC,XRP,TRX,ADA,DASH,XTZ,USDT&feeds=coindesk,yahoofinance,cointelegraph,bitcoin.com&ITs=1486506200'\n",
    "api_key = 'xxxx'\n",
    "\n",
    "req = json.loads(requests.get(url_news + api_key).text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BaCOUi9v_IOV",
    "outputId": "f9741432-2717-4d27-996e-62a2b257a3d5"
   },
   "source": [
    "df_news = pd.DataFrame(req['Data'])\n",
    "df_news.index = pd.to_datetime(df_news['published_on'], origin='unix', unit='s')\n",
    "df_news.drop(columns=['published_on', 'id', 'guid', 'imageurl', 'url', 'source', 'upvotes', 'downvotes', 'lang', 'source_info'], inplace=True)\n",
    "df_news.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "df_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OADTfXzu_IOY"
   },
   "source": [
    "# Features Engineering\n",
    "## Features Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQfWEf_z_IOY"
   },
   "outputs": [],
   "source": [
    "def rolling_tscores(series, window):\n",
    "    '''\n",
    "    Compute the T-Score on the previous values from a rolling window\n",
    "    in order to not calculate a t-score based on a distribution containing future values\n",
    "\n",
    "    return: time series of the t-score based on previous values window sample\n",
    "    '''\n",
    "\n",
    "    # Get the rolling window\n",
    "    roll_series = series.rolling(window)\n",
    "\n",
    "    # Get the mean & std of the sample of previous records (distribution)\n",
    "    m = roll_series.mean().shift(1)\n",
    "    s = roll_series.std(ddof=0).shift(1)\n",
    "\n",
    "    tscores = (series - m) / s\n",
    "\n",
    "    return tscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "LYVQI1Pz_IOc",
    "outputId": "3890976f-cfba-4bf9-a488-ac7a0131c612"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15996 entries, 2018-10-08 19:00:00 to 2020-08-05 11:00:00\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   volumefrom         15996 non-null  float64\n",
      " 1   volumeto           15996 non-null  float64\n",
      " 2   close_mov1H        15995 non-null  float64\n",
      " 3   high_mov1H         15995 non-null  float64\n",
      " 4   low_mov1H          15995 non-null  float64\n",
      " 5   open_mov1H         15995 non-null  float64\n",
      " 6   volumefrom_mov1H   15995 non-null  float64\n",
      " 7   volumeto_mov1H     15995 non-null  float64\n",
      " 8   close_mov6H        15990 non-null  float64\n",
      " 9   high_mov6H         15990 non-null  float64\n",
      " 10  low_mov6H          15990 non-null  float64\n",
      " 11  open_mov6H         15990 non-null  float64\n",
      " 12  volumefrom_mov6H   15990 non-null  float64\n",
      " 13  volumeto_mov6H     15990 non-null  float64\n",
      " 14  close_mov12H       15984 non-null  float64\n",
      " 15  high_mov12H        15984 non-null  float64\n",
      " 16  low_mov12H         15984 non-null  float64\n",
      " 17  open_mov12H        15984 non-null  float64\n",
      " 18  volumefrom_mov12H  15984 non-null  float64\n",
      " 19  volumeto_mov12H    15984 non-null  float64\n",
      " 20  close_mov24H       15972 non-null  float64\n",
      " 21  high_mov24H        15972 non-null  float64\n",
      " 22  low_mov24H         15972 non-null  float64\n",
      " 23  open_mov24H        15972 non-null  float64\n",
      " 24  volumefrom_mov24H  15972 non-null  float64\n",
      " 25  volumeto_mov24H    15972 non-null  float64\n",
      "dtypes: float64(26)\n",
      "memory usage: 3.3 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15996 entries, 2018-10-08 19:00:00 to 2020-08-05 11:00:00\n",
      "Columns: 858 entries, volumefrom to volumeto_mov24H.MSum24H.diff\n",
      "dtypes: float64(858)\n",
      "memory usage: 104.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# original columns to keep\n",
    "orig_cols = df.columns.tolist()[-2:]\n",
    "\n",
    "#----------------------\n",
    "# Movements and pct return (time step is hour)\n",
    "periods = [1, 6, 12, 24]\n",
    "movs_list = [df.diff(i) for i in periods]# + [df.pct_change(i) for i in periods]\n",
    "movs_labels = []\n",
    "\n",
    "for i in periods:\n",
    "    # Labels for the time derivatives\n",
    "    movs_labels += [col + '_mov{}H'.format(i) for col in df.columns]\n",
    "    \n",
    "#for i in periods:\n",
    "    # Labels for pct change\n",
    "    #movs_labels += [col + '_return{}H'.format(i) for col in df.columns]\n",
    "\n",
    "# Concatenate\n",
    "feats_df = pd.concat([df.loc[:, orig_cols]] + movs_list, axis=1)\n",
    "feats_df.columns = orig_cols + movs_labels\n",
    "\n",
    "print(feats_df.info())\n",
    "\n",
    "\n",
    "#----------------------\n",
    "# Rolling Statistics & T-Score\n",
    "for col in feats_df.columns:\n",
    "    # Get the series\n",
    "    series = feats_df.loc[:, col]\n",
    "    \n",
    "    for i in periods[1:]:\n",
    "\n",
    "        # Moving Averages series & combinations\n",
    "        feats_df[col +'.MA{}H'.format(i)] = series.rolling(\"{}H\".format(i)).mean()\n",
    "        feats_df[col + '.MA{}H.diff'.format(i)] = series.rolling(\"{}H\".format(i)).mean().diff()\n",
    "        \n",
    "        # Moving stats\n",
    "        feats_df[col + '.MStd{}H'.format(i)] = series.rolling(\"{}H\".format(i)).std()\n",
    "        feats_df[col + '.MStd{}H.diff'.format(i)] = series.rolling(\"{}H\".format(i)).std().diff()\n",
    "        \n",
    "        feats_df[col + '.MMin{}H'.format(i)] = series.rolling(\"{}H\".format(i)).min()\n",
    "        feats_df[col + '.MMin{}H.diff'.format(i)] = series.rolling(\"{}H\".format(i)).min().diff()\n",
    "        \n",
    "        feats_df[col + '.MMax{}H'.format(i)] = series.rolling(\"{}H\".format(i)).max()\n",
    "        feats_df[col + '.MMax{}H.diff'.format(i)] = series.rolling(\"{}H\".format(i)).max().diff()\n",
    "        \n",
    "        feats_df[col + '.MSum{}H'.format(i)] = series.rolling(\"{}H\".format(i)).sum()\n",
    "        feats_df[col + '.MSum{}H.diff'.format(i)] = series.rolling(\"{}H\".format(i)).sum().diff()\n",
    "      \n",
    "\n",
    "        # T-Score on rolling 1 month & 6 months sample (tscore is zscore on a sample, not on whole distribution)\n",
    "        feats_df[col + '.TScore6M'] = rolling_tscores(series=series, window='4400H')\n",
    "        feats_df[col + '.TScore1M'] = rolling_tscores(series=series, window='720H')\n",
    "        \n",
    "\n",
    "\n",
    "print(feats_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "kEg6f2eV_IOe",
    "outputId": "d8f051ec-a977-4a5f-99a0-5748dda84b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15996 entries, 2018-10-08 19:00:00 to 2020-08-05 11:00:00\n",
      "Columns: 1716 entries, volumefrom to volumeto_mov24H.MSum24H.diff.Squared\n",
      "dtypes: float64(1716)\n",
      "memory usage: 209.5 MB\n"
     ]
    }
   ],
   "source": [
    "# suqared features\n",
    "squared = []\n",
    "\n",
    "for col in feats_df.columns:\n",
    "    feats_df[col + '.Squared'] = feats_df[col] * feats_df[col]\n",
    "    \n",
    "feats_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "n1Z7Pz88_IOj",
    "outputId": "87cdadc9-e695-4692-fb49-ca191ad2b121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15970 entries, 2018-10-09 21:00:00 to 2020-08-05 11:00:00\n",
      "Columns: 1716 entries, volumefrom to volumeto_mov24H.MSum24H.diff.Squared\n",
      "dtypes: float64(1716)\n",
      "memory usage: 209.2 MB\n",
      "None\n",
      "0 NaNs in the features\n",
      "0 inf values in the features\n"
     ]
    }
   ],
   "source": [
    "# Check for Inf or Nan values\n",
    "feats_df.dropna(inplace=True)\n",
    "print(feats_df.info())\n",
    "print('{} NaNs in the features'.format(feats_df.isnull().sum().sum()))\n",
    "print('{} inf values in the features'.format(feats_df.isin([np.inf, -np.inf]).sum().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hz2qyUELh6Nk"
   },
   "source": [
    "### **TO ADD**\n",
    "* Difference from minimum / maximum\n",
    "* TA indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "vu0qYF3T_IOm"
   },
   "source": [
    "%%time \n",
    "\n",
    "#----------------------\n",
    "# Polynomial features\n",
    "poly_transformer = PolynomialFeatures(degree=2, interaction_only=False, include_bias=True, order='F')\n",
    "feats_poly_values = poly_transformer.fit_transform(feats_df.dropna())\n",
    "\n",
    "feats_poly = pd.DataFrame(feats_poly_values,\n",
    "                          index=feats_df.index,\n",
    "                          columns=['PolyFeat{}'.format(i) for i in range(1, poly_transformer.n_output_features_+1)])\n",
    "\n",
    "print(feats_poly.info())\n",
    "\n",
    "# Add to the features df\n",
    "all_feats_df = pd.concat([feats_df, feats_poly], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C8_HkUrq_IOm"
   },
   "source": [
    "## TArget Engineering\n",
    "Target:\n",
    "* 2 labels: up/down\n",
    "* trend keep/change\n",
    "\n",
    "Features derived from target\n",
    "* difference of price from the min or max, average over last period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "bge4CE82_IOn",
    "outputId": "6a8a87af-4c91-4d6d-8c4f-cc4ed607640c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIoAAALMCAYAAACLwFm+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAA66klEQVR4nO3dfdhd1V0n/O+v0FL6goU2IE2o4DRaAW0rGcTWdlQcSadVmBc6UStReSaWQa2vHfCZZzrOTMbqaB25RhiZvhC0FmPHDkwVLYO2tZYpTV8spRSJhUIMQmxLS2ulQn/PH3tFTu7cSe5Akvsm+Xyu61xnn7XX2mftc5Kcne9Za53q7gAAAADA4xa7AwAAAAAsDYIiAAAAAJIIigAAAAAYBEUAAAAAJBEUAQAAADAIigAAAABIIigC9pOq+vdV9Ztj+1lV9fmqOuwAPO/3VdU79vfzAAD7X1Utq6pbq+qJC6h7XFXdUlVHPIrnO7GquqoOf6TH2F8O9Guxv4zX99kLrOt6EhaBoAj2s/k+DGc/9PbiOH9eVV9TVVdU1Zeq6v5x+2hV/XxVfcW+7fm+0913dvdTuvuhfXnc+S7muvvN3f2d+/J5lqKquqOqvmOx+wHAoWHu505Vramqz1TVP9rPT31Rkjd199+O5z2iqt5YVZ+rqr+qqp/cXrG770nyx0nWzdP/d1TVd47tr6mq36mqv66qz1bVR6rqJw9EAPEozX0tXl5V762qv6mqd85W3N1rMdpeO0KXz1fV341ry+2P//v+PpFHwvXkI1NV31pVWxa7Hzy2CIrgMaCq/kGSx3X3n4+iX+zupyZZluQHk5yR5E+r6smL1cdHqib+LQKAx4iqWpvk15K8tLvftR+f54gka5PMfrn275OsTPJVSb4tyauravXM/jcn+eE5x3lyktOSvGtcU70vyV1Jvr67vyLJuUlWJXnq/jmTR28Xr8Wnk/zXJK/dRbOdXovtuvslI3R5yqj3i9sfd/crZ553yY2smo/rSdi3/GWCRbY95a+qnx3fbN1RVd83p9pLk/z+3Lbd/bfd/f4k353k6ZlCo1TV46rq31bVJ6vq3qq6cvuIo6raUFU/NbaXj29Q/vV4/Oyq+vT4sN3er58ax7i7qn5wN+dxUlW9a4xyui7JM2b27fBNTVW9s6rWV9WfJvmbJF9dVc+pquvG899aVS+faX9kVf3yOJ/PVtV7qurIJO8eVe4b34B9c1X9QFW9Z6btC6rq/aPd+6vqBTP73llV/7Gq/nT0+x1V9Yyx74lV9ZtV9amqum+0PW4X535CVf1uVW0b9f/bAt6Hnb7dqZlva2sadbZxtLm/qm6uqlVj328keVaS/z3O+9W7el8AYF+qqnVJfjnJWd393lH2FVX1hnGt8JdV9Z9qZnROVf1QTdOgPlNVf1hVXzWzr6vqx6rqE+M66L/M/If/m5Lc192zn5fnJfmP3f2Z7r4lyf9I8gMz+9+X6briq2bKzkzyp939QJKfS/Le7v7J7r47Sbr71u7+3u6+b6bN91XVnaNP/+9Mf0+vqhvGtcHdVfXfquoJc87nlVV12zjfX6uqGvsOG9czf11Vt1fVj8y5Ptrd67jTa9Hd/6e7NybZuou3a77XYo9Gny6sqtuS3DbKXlZVHx7n/d6q+oaZ+ndU1U/XNDLrs1X12zUzPa6qfmac09aq+qE9PPdJdRBdT+7iHM8er+XnquovagSdVfXMqrpm9H1zVf2rmTZXVNV/mnm8w3Xkrt6DmkLSa5M8sx4eMfbM3b0HkAiKYKn4ykwfhMszfVt0eVV97cz+f5Lk93bVuLvvT3JdkheNoh8Yt29L8tVJnpLkv41970ryrWP7HyX5xLhPkhcn+ZPu7pl+fcXo1/lJfq2qjt5FN34ryQfGefzHcR678/2ZhkM/Ncm20f/fSnJsku9JcmlVnTLq/lKmbwJfkOSYJK9O8uXR3yR52vgG7IbZJ6iqYzK9bpdkCtJel+T3qurpM9W+N1PAdmySJyT56VG+dpz7CaPtK5N8ce5JjAu4tyf5ZJITM71WV43dP5Bdvw8L8d3jWE9Lcs32tt39/UnuTPJd47x/cS+OCQCP1AWZPuPP7O5NM+UbkjyY5NlJnp/kO5P8P0lSVeck+dkk/yzTSOg/SfKWOcf9p5lG9HxjkrOTbA8Tvj7JrdsrjWuQZyb5s5m2f5Zk+/VCuvvBJJuTPHemzux11HckeesCzvVbknxtppDp31XV143yh5L8RKbrnW8e+//1nLYvS/IPRx9enuSsUf6vkrwkyfPGuZ4zp90uX8fMeS0WYhevxUKdkymcOrmqvjHJGzONTnp6kl9Pck3tuP7Ry5OsTnJSkm/ICO9GCPLTSf5xppFge5o2f7BdT+6gqk5PcmWSn8l0fffiJHeM3W9JsiXTn/F/keQ/V9WZezj/WTu9B939hUx/5rbOjBjbVbAIf09QBEvH/9fdD4wh3L+X6R/7VNWTMl1s7Glo99ZMH3pJ8n1JXtfdn+juzye5OMma8Q3Mu5K8qKZv616c5BeTvHC0+0dznufvkvyH7v677v79JJ/PdNG0g6p61ujj9nN4d5L/vYf+XtHdN4+LmNVJ7ujuN3X3g939wST/M8m/GP38oSSv6u6/7O6Huvu941vBPXlpktu6+zfGcd+S5ONJvmumzpu6+8+7+4tJNma6eNt+7k9P8uzxnB/o7s/N8xynZ/pA/5nu/sIY5bX9G6jdvQ8L8Z7u/v0xF/838sgu9ABgX/nHSf5vkpu2F9Q02vYlSX58fA7em+RXkqwZVX44yc939y3jM/8/J3nenFEuv9Ddn+7uOzNNpfqeUf60JPfP1HvKuP/sTNlns/OUsftH2+1ekodHZj89yd0LONef6+4vdvefZQqjnpsk43rg/47rijsyhSZz12l6bXffN87nj/PwtcXLk/xqd2/p7s9kZsrYAl7Hp2XH12Kh5r4WC/Xz4z35YqaA69e7+33jmmhDkgcyLX2w3SXdvbW7P53pGvB5o/zlma61PjpCi3+/qyc8SK8n5zo/yRu7+7ru/vLoy8er6oRM4eS/GdeSH07y+kxB2ELt6j2AvSYogv3voSSPn1P2+ExBxHafGR+e230yU/iQTN9UvbfHwoW7sTzTXPWMtp+cc7zDkxzX3X+RKfB5XqYRSG9PsnWMYJobFH1qfPBu9zd5+CJt1jN3cQ67c9fM9lcl+aYxnPm+qrovU8iyfaTVE5P8xR6ON5+5r8P2fi2fefxXM9uz5/cbSf4wyVVjqPQvVtXc9zGZRhx9cs7rtKvn//v3YYH9n9u3J+5FyAQA+9ork3xNktdXTdOpMn2GPz7J3TOf4b+eaWTF9v2/OrPv00kqO34Wz14TzF4DfSY7hkCfH/dHzZQdlZ0DlKcmuS9Jqurrk3yuu7c/x6eSHL+Ac533+qCmhbDfXtNC2p/LFHzNnWa0q2uLZ2bHc517LbS713Hua7FQf/9a7KW5ffupOddpJ+Th9ylZ+Dnv7vrwYLyenOuEXfThmUk+PWYJ7Oo59mShfYA9EhTB/ndnpilJs07Kjh84R9eOC1E/Kw/PN9/ttLMkqaqnZBrK+yejaGumD8vZ4z2Y5J7x+F2ZhrQ+obv/cjw+L8nRST68pxOax927OIfd6Zntu5K8q7ufNnN7SndfkOSvk/xtkn+wh2PMZ+7rsL1ff7mHdhmjqH6uu0/ONET5ZZleo7nuSvKsXQQ4u3sfvpDkSdt3jClsy/bUr9ku7kVdANgX7s30BdaLklw6yu7KNLrkGTOf4Ud19ykz+394zmf8kT3WNxpOmNmevQb6SKZgKkkyRuHcnR1H2D43yc3bH4zP42fn4elpc6+j/k+Sf76X5z3rskyjSVZ291GZptXV7pv8vbuTrJh5PHvee3odd3gtFmKe12JvzL1OWz/nPXzSGFmzJ3dn5/d3d3UPquvJedy1iz5sTXJMVc2GgbPPscN1Y6bwa6FcM7LXBEWw//12kn9bVStqWtz4OzINVZ07P/7nquoJVfWiTKHE74zy2eHSO6jpJ2JPS/K/Mn3T9Kax6y1JfqKmBQGfkunbrt+eGfXyriQ/kocX73tnkh/NNNVpr39ytLs/mWTTzDl8S3Ycjrsnb0/yNVX1/VX1+HH7h1X1dd395Uzz4l83Fvk7rKZFBo/INBf9y5nW/5nP74/jfm9VHV5V/zLJyeP5dquqvq2qvn4EOJ/LNAJsvtfmxkwXNq+tqiePhQO3T+Xb3fvw55lGCL10jFT6t0mOmOf4u3JPdn3eALBf9LS+ybcnWV1Vv9LTgtDvSPLLVXXUuNb5B1W1fTrWf09y8fZ1YmpasPncOYf9mao6eky/eVWma6dk+ox9WlXNjqq4MtN11dFV9ZxM06KumNl/eqbpR9u/kJv7gyCvSfKCmhbN/srRp2fX9AMWT1vAS/DUTNcFnx/Pf8EC2my3Mcmravoxkacl+TfbdyzgddzptRjXRE/MNFr5ceMaZHb089zX4pH6H0leWVXfVJMnj+uXhYxw2pjkB6rq5JqWU3jNrioejNeT83hDkh+sqjPHe7y8qp4zRry9N8nPj/fxGzJNU3vzaPfhJP+kqo4Zf25/fC+e854kT6/xgyqwEIIi2P/+Q6Z/+N+TKcz5xSTf190fnanzV2Pf1kwfCK8c85VPTfL5Mcd91qur6v5Mw7evzLTo3wtmhuq+MdPUqXcnuT3TNyg/OtP+XZkudLYHRe/J9C3Fu/PIfW+mRQ8/neki4MqFNhzDbL8z0zz8rZlej1/Iw8HJT2daD+H94/i/kORx3f03SdYn+dMxxPiMOcf9VKbQ7acyDTV/dZKXdfdfL6BbX5kpzPtcklsyvWa/ObfSCNa+K9M3dndmWoTwX47du3wfuvuzmRa/fH2mb4u+MNou1M9nulC+r6rmXTARAPaH8Z/ab8+09svPZxpx+4QkH8t0PfPWjOld3f22TJ/bV9U0Veujmb4Em3V1pmuZD2ca/fOG0fZLmUKgV8zUfU2mqTufzPTZ/F+6+w9m9n9fpnAq4z/GX5fpOmx73/8i0yLUJya5uao+m2kdm01Z2BpAP53pmuf+TAHKb++++g7+R6Yw6CNJPpQpgHgwD38RtbvXcb7X4vsz/dDGZZlGeX1xPMd2f/9aPBo9LVz+rzL9qMZnMi2Q/QMLbHttpnWn/mi0+6M9NDnYrifn9vHGTIte/0qm9bXelYdHK31Ppj+XW5O8Lclruvu6se83Mo0MuyPTn6EF/7nr7o9n+vLyE+P8/OoZe1TdRqLBYqqqb03ym929Yp59r840BNnPnwMAB52q6kzTuDbvYv/2X0p7/lgoeHfHOjbTf7yf391/W9NPo/+L7n757totlqp6SZL/3t0L+vn6R/NaPOrOAocUi6LC0nZH9vxrDwAAB6Xu3pbkOQuse2+mEUTb3Zdp5MaSUFVHJvm2TCNCjss0YuZtC23/KF8LgAUTFMES1t0bF7sPAACPRd39jsXuwxyV5OcyTRv6YqZpdv9uUXsEMA9TzwAAAABIYjFrAAAAAAZBEQAAAABJHgNrFD3jGc/oE088cbG7AQDsJx/4wAf+uruXLXY/eJjrLwA4+O3qGmzJB0UnnnhiNm3atNjdAAD2k6r65GL3gR25/gKAg9+ursFMPQMAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAAAGQREAAAAASQRFAAAAAAyCIgAAAACSCIoAAAAAGARFAAAAACQRFAEAAAAwCIoAAAAASCIoAgAAAGAQFAEAAACQRFAEAAAAwCAoAgAAACCJoAgAAACAQVAEAAAAQBJBEQAAAACDoAgAAACAJIIiAAAAAAZBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJBEUAQAAADAIigAAAABIkhy+2B1g10686PcWuwsskjte+9LF7gIAHLJcgx26XIMBGFEEAAAAwCAoAgAAACCJoAgAAACAQVAEAAAAQBJBEQAAAACDoAgAAACAJIIiAAAAAAZBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJFlgUFRVP1FVN1fVR6vqLVX1xKo6pqquq6rbxv3RM/UvrqrNVXVrVZ01U35aVd009l1SVbU/TgoAAACAvbfHoKiqlif5sSSruvvUJIclWZPkoiTXd/fKJNePx6mqk8f+U5KsTnJpVR02DndZknVJVo7b6n16NgAAAAA8YgudenZ4kiOr6vAkT0qyNcnZSTaM/RuSnDO2z05yVXc/0N23J9mc5PSqOj7JUd19Q3d3kitn2gAAAACwyPYYFHX3Xyb5pSR3Jrk7yWe7+x1Jjuvuu0edu5McO5osT3LXzCG2jLLlY3tuOQAAAABLwEKmnh2daZTQSUmemeTJVfWK3TWZp6x3Uz7fc66rqk1VtWnbtm176iIAAAAA+8BCpp59R5Lbu3tbd/9dkt9N8oIk94zpZBn39476W5KcMNN+RaapalvG9tzynXT35d29qrtXLVu2bG/OBwAAAIBHaCFB0Z1JzqiqJ41fKTszyS1JrkmydtRZm+TqsX1NkjVVdURVnZRp0eobx/S0+6vqjHGc82baAAAAALDIDt9The5+X1W9NckHkzyY5ENJLk/ylCQbq+r8TGHSuaP+zVW1McnHRv0Lu/uhcbgLklyR5Mgk144bAAAAAEvAHoOiJOnu1yR5zZziBzKNLpqv/vok6+cp35Tk1L3sIwAAAAAHwEKmngEAAABwCBAUAQAAAJBEUAQAAADAICgCAAAAIImgCAAAAIBBUAQAAABAEkERAAAAAIOgCAAAAIAkgiIAAAAABkERAAAAAEkERQAAAAAMgiIAAAAAkiSHL3YHAHjYiRf93mJ3gUVyx2tfuthdAAAAI4oAAAAAmAiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgCAJauqfqKqbq6qj1bVW6rqiVV1TFVdV1W3jfujZ+pfXFWbq+rWqjprpvy0qrpp7LukqmpxzggAWOoERQAAS1BVLU/yY0lWdfepSQ5LsibJRUmu7+6VSa4fj1NVJ4/9pyRZneTSqjpsHO6yJOuSrBy31QfwVACAxxBBEQDA0nV4kiOr6vAkT0qyNcnZSTaM/RuSnDO2z05yVXc/0N23J9mc5PSqOj7JUd19Q3d3kitn2gAA7EBQBACwBHX3Xyb5pSR3Jrk7yWe7+x1Jjuvuu0edu5McO5osT3LXzCG2jLLlY3tuOQDATgRFAABL0Fh76OwkJyV5ZpInV9UrdtdknrLeTfnc51tXVZuqatO2bdseSZcBgIOAoAgAYGn6jiS3d/e27v67JL+b5AVJ7hnTyTLu7x31tyQ5Yab9ikxT1baM7bnlO+juy7t7VXevWrZs2T4/GQDgsUFQBACwNN2Z5IyqetL4lbIzk9yS5Joka0edtUmuHtvXJFlTVUdU1UmZFq2+cUxPu7+qzhjHOW+mDQDADg5f7A4AALCz7n5fVb01yQeTPJjkQ0kuT/KUJBur6vxMYdK5o/7NVbUxycdG/Qu7+6FxuAuSXJHkyCTXjhsAwE4ERQAAS1R3vybJa+YUP5BpdNF89dcnWT9P+aYkp+7zDgIABx1TzwAAAABIIigCAAAAYBAUAQAAAJBEUAQAAADAICgCAAAAIImgCAAAAIBBUAQAAABAEkERAAAAAIOgCAAAAIAkgiIAAAAABkERAAAAAEkERQAAAAAMgiIAAAAAkgiKAAAAABgERQAAAAAkERQBAAAAMAiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAAAGQREAAAAASQRFAAAAAAyCIgAAAACSCIoAAAAAGARFAAAAACQRFAEAAAAwCIoAAAAASCIoAgAAAGAQFAEAAACQZAFBUVV9bVV9eOb2uar68ao6pqquq6rbxv3RM20urqrNVXVrVZ01U35aVd009l1SVbW/TgwAAACAvbPHoKi7b+3u53X385KcluRvkrwtyUVJru/ulUmuH49TVScnWZPklCSrk1xaVYeNw12WZF2SleO2ep+eDQAAAACP2N5OPTszyV909yeTnJ1kwyjfkOScsX12kqu6+4Huvj3J5iSnV9XxSY7q7hu6u5NcOdMGAAAAgEW2t0HRmiRvGdvHdffdSTLujx3ly5PcNdNmyyhbPrbnlu+kqtZV1aaq2rRt27a97CIAAAAAj8SCg6KqekKS707yO3uqOk9Z76Z858Luy7t7VXevWrZs2UK7CAAAAMCjsDcjil6S5IPdfc94fM+YTpZxf+8o35LkhJl2K5JsHeUr5ikHAAAAYAnYm6Doe/LwtLMkuSbJ2rG9NsnVM+VrquqIqjop06LVN47pafdX1Rnj187Om2kDAAAAwCI7fCGVqupJSf5xkh+eKX5tko1VdX6SO5OcmyTdfXNVbUzysSQPJrmwux8abS5IckWSI5NcO24AAAAALAELCoq6+2+SPH1O2acy/QrafPXXJ1k/T/mmJKfufTcBAAAA2N8WFBQBAADAwejEi35vsbvAIrnjtS9d7C4sSXuzRhEAAAAABzFBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJBEUAQAAADAIigAAAABIIigCAAAAYBAUAQAAAJBEUAQAAADAICgCAAAAIImgCAAAAIBBUAQAAABAEkERAAAAAIOgCAAAAIAkgiIAAAAABkERAAAAAEkERQAAAAAMgiIAAAAAkgiKAAAAABgERQAAAAAkERQBAAAAMAiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAAAGQREAAAAASQRFAAAAAAyCIgAAAACSCIoAAAAAGARFAAAAACQRFAEAAAAwCIoAAAAASCIoAgAAAGAQFAEAAACQRFAEAAAAwCAoAgAAACCJoAgAAACAQVAEAAAAQBJBEQAAAACDoAgAAACAJIIiAAAAAAZBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJBEUAQAAADAIigAAAABIIigCAAAAYBAUAQAAAJBEUAQAAADAICgCAAAAIImgCAAAAIBBUAQAAABAEkERAAAAAIOgCAAAAIAkgiIAAAAAhgUFRVX1tKp6a1V9vKpuqapvrqpjquq6qrpt3B89U//iqtpcVbdW1Vkz5adV1U1j3yVVVfvjpAAAAADYewsdUfSrSf6gu5+T5LlJbklyUZLru3tlkuvH41TVyUnWJDklyeokl1bVYeM4lyVZl2TluK3eR+cBAAAAwKO0x6Coqo5K8uIkb0iS7v5Sd9+X5OwkG0a1DUnOGdtnJ7mqux/o7tuTbE5yelUdn+So7r6huzvJlTNtAAAAAFhkCxlR9NVJtiV5U1V9qKpeX1VPTnJcd9+dJOP+2FF/eZK7ZtpvGWXLx/bccgAAAACWgIUERYcn+cYkl3X385N8IWOa2S7Mt+5Q76Z85wNUrauqTVW1adu2bQvoIgAAAACP1kKCoi1JtnT3+8bjt2YKju4Z08ky7u+dqX/CTPsVSbaO8hXzlO+kuy/v7lXdvWrZsmULPRcAAAAAHoU9BkXd/VdJ7qqqrx1FZyb5WJJrkqwdZWuTXD22r0mypqqOqKqTMi1afeOYnnZ/VZ0xfu3svJk2AAAAACyywxdY70eTvLmqnpDkE0l+MFPItLGqzk9yZ5Jzk6S7b66qjZnCpAeTXNjdD43jXJDkiiRHJrl23AAAAABYAhYUFHX3h5OsmmfXmbuovz7J+nnKNyU5dS/6BwAAAMABspA1igAAAAA4BAiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAAAGQREAAAAASQRFAAAAAAyCIgAAAACSCIoAAAAAGARFAABLVFU9rareWlUfr6pbquqbq+qYqrquqm4b90fP1L+4qjZX1a1VddZM+WlVddPYd0lV1eKcEQCw1AmKAACWrl9N8gfd/Zwkz01yS5KLklzf3SuTXD8ep6pOTrImySlJVie5tKoOG8e5LMm6JCvHbfWBPAkA4LFDUAQAsARV1VFJXpzkDUnS3V/q7vuSnJ1kw6i2Ick5Y/vsJFd19wPdfXuSzUlOr6rjkxzV3Td0dye5cqYNAMAOBEUAAEvTVyfZluRNVfWhqnp9VT05yXHdfXeSjPtjR/3lSe6aab9llC0f23PLAQB2IigCAFiaDk/yjUku6+7nJ/lCxjSzXZhv3aHeTfmOjavWVdWmqtq0bdu2R9JfAOAgICgCAFiatiTZ0t3vG4/fmik4umdMJ8u4v3em/gkz7Vck2TrKV8xTvoPuvry7V3X3qmXLlu3TEwEAHjsERQAAS1B3/1WSu6rqa0fRmUk+luSaJGtH2dokV4/ta5KsqaojquqkTItW3zimp91fVWeMXzs7b6YNAMAODl/sDgAAsEs/muTNVfWEJJ9I8oOZvujbWFXnJ7kzyblJ0t03V9XGTGHSg0ku7O6HxnEuSHJFkiOTXDtuAAA7ERQBACxR3f3hJKvm2XXmLuqvT7J+nvJNSU7dp50DAA5Kpp4BAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAAAGQREAAAAASQRFAAAAAAyCIgAAAACSCIoAAAAAGARFAAAAACQRFAEAAAAwCIoAAAAASCIoAgAAAGAQFAEAAACQRFAEAAAAwCAoAgAAACCJoAgAAACAQVAEAAAAQBJBEQAAAACDoAgAAACAJIIiAAAAAAZBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJBEUAQAAADAIigAAAABIIigCAAAAYBAUAQAAAJBEUAQAAADAICgCAAAAIImgCAAAAIBBUAQAAABAEkERAAAAAIOgCAAAAIAkgiIAAAAABkERAAAAAEkERQAAAAAMgiIAAAAAkiwwKKqqO6rqpqr6cFVtGmXHVNV1VXXbuD96pv7FVbW5qm6tqrNmyk8bx9lcVZdUVe37UwIAAADgkdibEUXf1t3P6+5V4/FFSa7v7pVJrh+PU1UnJ1mT5JQkq5NcWlWHjTaXJVmXZOW4rX70pwAAAADAvvBopp6dnWTD2N6Q5JyZ8qu6+4Huvj3J5iSnV9XxSY7q7hu6u5NcOdMGAAAAgEW20KCok7yjqj5QVetG2XHdfXeSjPtjR/nyJHfNtN0yypaP7bnlO6mqdVW1qao2bdu2bYFdBAAAAODROHyB9V7Y3Vur6tgk11XVx3dTd751h3o35TsXdl+e5PIkWbVq1bx1AAAAANi3FjSiqLu3jvt7k7wtyelJ7hnTyTLu7x3VtyQ5Yab5iiRbR/mKecoBAAAAWAL2GBRV1ZOr6qnbt5N8Z5KPJrkmydpRbW2Sq8f2NUnWVNURVXVSpkWrbxzT0+6vqjPGr52dN9MGAAAAgEW2kKlnxyV52/gl+8OT/FZ3/0FVvT/Jxqo6P8mdSc5Nku6+uao2JvlYkgeTXNjdD41jXZDkiiRHJrl23AAAAABYAvYYFHX3J5I8d57yTyU5cxdt1idZP0/5piSn7n03AQAAANjfFvqrZwAAAAAc5ARFAAAAACQRFAEAAAAwCIoAAAAASCIoAgAAAGAQFAEAAACQRFAEAAAAwCAoAgAAACCJoAgAAACAQVAEAAAAQBJBEQAAAACDoAgAAACAJIIiAAAAAAZBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJBEUAQAAADAIigAAAABIIigCAAAAYBAUAQAAAJBEUAQAAADAICgCAAAAIImgCAAAAIBBUAQAAABAEkERAAAAAIOgCAAAAIAkgiIAAAAABkERAAAAAEkERQAAAAAMgiIAAAAAkgiKAAAAABgERQAAAAAkERQBAAAAMAiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAAAGQREAAAAASQRFAAAAAAyCIgAAAACSCIoAAAAAGARFAAAAACQRFAEAAAAwCIoAAAAASCIoAgAAAGAQFAEAAACQRFAEAAAAwCAoAgAAACCJoAgAAACAQVAEAAAAQBJBEQAAAACDoAgAAACAJIIiAAAAAAZBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJNmLoKiqDquqD1XV28fjY6rquqq6bdwfPVP34qraXFW3VtVZM+WnVdVNY98lVVX79nQAAAAAeKT2ZkTRq5LcMvP4oiTXd/fKJNePx6mqk5OsSXJKktVJLq2qw0aby5KsS7Jy3FY/qt4DAAAAsM8sKCiqqhVJXprk9TPFZyfZMLY3JDlnpvyq7n6gu29PsjnJ6VV1fJKjuvuG7u4kV860AQAAAGCRLXRE0X9N8uokX54pO667706ScX/sKF+e5K6ZeltG2fKxPbccAAAAgCVgj0FRVb0syb3d/YEFHnO+dYd6N+XzPee6qtpUVZu2bdu2wKcFAAAA4NFYyIiiFyb57qq6I8lVSb69qn4zyT1jOlnG/b2j/pYkJ8y0X5Fk6yhfMU/5Trr78u5e1d2rli1bthenAwAAAMAjtcegqLsv7u4V3X1ipkWq/6i7X5HkmiRrR7W1Sa4e29ckWVNVR1TVSZkWrb5xTE+7v6rOGL92dt5MGwAAAAAW2eGPou1rk2ysqvOT3Jnk3CTp7puramOSjyV5MMmF3f3QaHNBkiuSHJnk2nEDAAAAYAnYq6Cou9+Z5J1j+1NJztxFvfVJ1s9TvinJqXvbSQAAAAD2v4X+6hkAAAAABzlBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJBEUAQAAADAIigAAlqiqOqyqPlRVbx+Pj6mq66rqtnF/9Ezdi6tqc1XdWlVnzZSfVlU3jX2XVFUtxrkAAI8NgiIAgKXrVUlumXl8UZLru3tlkuvH41TVyUnWJDklyeokl1bVYaPNZUnWJVk5bqsPTNcBgMciQREAwBJUVSuSvDTJ62eKz06yYWxvSHLOTPlV3f1Ad9+eZHOS06vq+CRHdfcN3d1JrpxpAwCwE0ERAMDS9F+TvDrJl2fKjuvuu5Nk3B87ypcnuWum3pZRtnxszy0HAJiXoAgAYImpqpclube7P7DQJvOU9W7K53vOdVW1qao2bdu2bYFPCwAcbARFAABLzwuTfHdV3ZHkqiTfXlW/meSeMZ0s4/7eUX9LkhNm2q9IsnWUr5infCfdfXl3r+ruVcuWLduX5wIAPIYIigAAlpjuvri7V3T3iZkWqf6j7n5FkmuSrB3V1ia5emxfk2RNVR1RVSdlWrT6xjE97f6qOmP82tl5M20AAHZy+GJ3AACABXttko1VdX6SO5OcmyTdfXNVbUzysSQPJrmwux8abS5IckWSI5NcO24AAPMSFAEALGHd/c4k7xzbn0py5i7qrU+yfp7yTUlO3X89BAAOJqaeAQAAAJBEUAQAAADAICgCAAAAIImgCAAAAIBBUAQAAABAEkERAAAAAIOgCAAAAIAkgiIAAAAABkERAAAAAEkERQAAAAAMgiIAAAAAkgiKAAAAABgERQAAAAAkERQBAAAAMAiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAAAGQREAAAAASQRFAAAAAAyCIgAAAACSCIoAAAAAGARFAAAAACQRFAEAAAAwCIoAAAAASCIoAgAAAGAQFAEAAACQRFAEAAAAwCAoAgAAACCJoAgAAACAQVAEAAAAQBJBEQAAAACDoAgAAACAJIIiAAAAAAZBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJBEUAQAAADAIigAAAABIIigCAAAAYBAUAQAAAJBEUAQAAADAICgCAAAAIMkCgqKqemJV3VhVf1ZVN1fVz43yY6rquqq6bdwfPdPm4qraXFW3VtVZM+WnVdVNY98lVVX757QAAAAA2FsLGVH0QJJv7+7nJnlektVVdUaSi5Jc390rk1w/HqeqTk6yJskpSVYnubSqDhvHuizJuiQrx231vjsVAAAAAB6NPQZFPfn8ePj4ceskZyfZMMo3JDlnbJ+d5KrufqC7b0+yOcnpVXV8kqO6+4bu7iRXzrQBAAAAYJEtaI2iqjqsqj6c5N4k13X3+5Ic1913J8m4P3ZUX57krpnmW0bZ8rE9t3y+51tXVZuqatO2bdv24nQAAAAAeKQWFBR190Pd/bwkKzKNDjp1N9XnW3eod1M+3/Nd3t2runvVsmXLFtJFAAAAAB6lvfrVs+6+L8k7M60tdM+YTpZxf++otiXJCTPNViTZOspXzFMOAAAAwBKwkF89W1ZVTxvbRyb5jiQfT3JNkrWj2tokV4/ta5KsqaojquqkTItW3zimp91fVWeMXzs7b6YNAAAAAIvs8AXUOT7JhvHLZY9LsrG7315VNyTZWFXnJ7kzyblJ0t03V9XGJB9L8mCSC7v7oXGsC5JckeTIJNeOGwAAAABLwB6Dou7+SJLnz1P+qSRn7qLN+iTr5ynflGR36xsBAAAAsEj2ao0iAAAAAA5egiIAAAAAkgiKAAAAABgERQAAAAAkERQBAAAAMAiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAAAGQREAAAAASQRFAAAAAAyCIgAAAACSCIoAAAAAGARFAAAAACQRFAEAAAAwCIoAAAAASCIoAgAAAGAQFAEAAACQRFAEAAAAwCAoAgAAACCJoAgAAACAQVAEAAAAQBJBEQAAAACDoAgAAACAJIIiAAAAAAZBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJBEUAQAAADAIigAAAABIIigCAAAAYBAUAQAAAJBEUAQAAADAICgCAAAAIImgCAAAAIBBUAQAAABAEkERAAAAAIOgCAAAAIAkgiIAAAAABkERAAAAAEkERQAAAAAMgiIAAAAAkgiKAAAAABgERQAAAAAkERQBAAAAMAiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAAAGQREAAAAASQRFAAAAAAyCIgAAAACSLCAoqqoTquqPq+qWqrq5ql41yo+pquuq6rZxf/RMm4uranNV3VpVZ82Un1ZVN419l1RV7Z/TAgAAAGBvLWRE0YNJfqq7vy7JGUkurKqTk1yU5PruXpnk+vE4Y9+aJKckWZ3k0qo6bBzrsiTrkqwct9X78FwAAAAAeBT2GBR1993d/cGxfX+SW5IsT3J2kg2j2oYk54zts5Nc1d0PdPftSTYnOb2qjk9yVHff0N2d5MqZNgAAAAAssr1ao6iqTkzy/CTvS3Jcd9+dTGFSkmNHteVJ7ppptmWULR/bc8sBAAAAWAIWHBRV1VOS/M8kP97dn9td1XnKejfl8z3XuqraVFWbtm3bttAuAgAAAPAoLCgoqqrHZwqJ3tzdvzuK7xnTyTLu7x3lW5KcMNN8RZKto3zFPOU76e7Lu3tVd69atmzZQs8FAAAAgEdhIb96VknekOSW7n7dzK5rkqwd22uTXD1TvqaqjqiqkzItWn3jmJ52f1WdMY553kwbAAAAABbZ4Quo88Ik35/kpqr68Cj72SSvTbKxqs5PcmeSc5Oku2+uqo1JPpbpF9Mu7O6HRrsLklyR5Mgk144bAAAAAEvAHoOi7n5P5l9fKEnO3EWb9UnWz1O+Kcmpe9NBAIBDUVWdkOlXYr8yyZeTXN7dv1pVxyT57SQnJrkjycu7+zOjzcVJzk/yUJIf6+4/HOWn5eEv634/yavGr9ACAOxgr371DACAA+bBJD/V3V+X5IwkF1bVyUkuSnJ9d69Mcv14nLFvTZJTkqxOcmlVHTaOdVmSdZmWBFg59gMA7ERQBACwBHX33d39wbF9f5JbkixPcnaSDaPahiTnjO2zk1zV3Q909+1JNic5ffzoyFHdfcMYRXTlTBsAgB0IigAAlriqOjHJ85O8L8lx40dCMu6PHdWWJ7lrptmWUbZ8bM8tBwDYiaAIAGAJq6qnJPmfSX68uz+3u6rzlPVuyuc+z7qq2lRVm7Zt2/bIOgsAPOYJigAAlqiqenymkOjN3f27o/ieMZ0s4/7eUb4lyQkzzVck2TrKV8xTvoPuvry7V3X3qmXLlu3bEwEAHjMERQAAS1BVVZI3JLmlu183s+uaJGvH9tokV8+Ur6mqI6rqpEyLVt84pqfdX1VnjGOeN9MGAGAHhy92BwAAmNcLk3x/kpuq6sOj7GeTvDbJxqo6P8mdSc5Nku6+uao2JvlYpl9Mu7C7HxrtLkhyRZIjk1w7bgAAOxEUAQAsQd39nsy/vlCSnLmLNuuTrJ+nfFOSU/dd7wCAg5WpZwAAAAAkERQBAAAAMAiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAAAGQREAAAAASQRFAAAAAAyCIgAAAACSCIoAAAAAGARFAAAAACQRFAEAAAAwCIoAAAAASCIoAgAAAGAQFAEAAACQRFAEAAAAwCAoAgAAACCJoAgAAACAQVAEAAAAQBJBEQAAAACDoAgAAACAJIIiAAAAAAZBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJBEUAQAAADAIigAAAABIIigCAAAAYBAUAQAAAJBEUAQAAADAICgCAAAAIImgCAAAAIBBUAQAAABAEkERAAAAAIOgCAAAAIAkgiIAAAAABkERAAAAAEkERQAAAAAMgiIAAAAAkgiKAAAAABgERQAAAAAkERQBAAAAMAiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCQLCIqq6o1VdW9VfXSm7Jiquq6qbhv3R8/su7iqNlfVrVV11kz5aVV109h3SVXVvj8dAAAAAB6phYwouiLJ6jllFyW5vrtXJrl+PE5VnZxkTZJTRptLq+qw0eayJOuSrBy3uccEAAAAYBHtMSjq7ncn+fSc4rOTbBjbG5KcM1N+VXc/0N23J9mc5PSqOj7JUd19Q3d3kitn2gAAAACwBDzSNYqO6+67k2TcHzvKlye5a6bellG2fGzPLZ9XVa2rqk1VtWnbtm2PsIsAAAAA7I19vZj1fOsO9W7K59Xdl3f3qu5etWzZsn3WOQAAAAB27ZEGRfeM6WQZ9/eO8i1JTpiptyLJ1lG+Yp5yAAAAAJaIRxoUXZNk7dhem+TqmfI1VXVEVZ2UadHqG8f0tPur6ozxa2fnzbQBAAAAYAk4fE8VquotSb41yTOqakuS1yR5bZKNVXV+kjuTnJsk3X1zVW1M8rEkDya5sLsfGoe6INMvqB2Z5NpxAwAAAGCJ2GNQ1N3fs4tdZ+6i/vok6+cp35Tk1L3qHQAAAAAHzL5ezBoAAACAxyhBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJBEUAQAAADAIigAAAABIIigCAAAAYBAUAQAAAJBEUAQAAADAICgCAAAAIImgCAAAAIBBUAQAAABAEkERAAAAAIOgCAAAAIAkgiIAAAAABkERAAAAAEkERQAAAAAMgiIAAAAAkgiKAAAAABgERQAAAAAkERQBAAAAMAiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAAAGQREAAAAASQRFAAAAAAyCIgAAAACSCIoAAAAAGARFAAAAACQRFAEAAAAwCIoAAAAASCIoAgAAAGAQFAEAAACQRFAEAAAAwCAoAgAAACCJoAgAAACAQVAEAAAAQBJBEQAAAACDoAgAAACAJIIiAAAAAAZBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJBEUAQAAADAIigAAAABIIigCAAAAYBAUAQAAAJBEUAQAAADAICgCAAAAIImgCAAAAIBBUAQAAABAEkERAAAAAIOgCAAAAIAkgiIAAAAABkERAAAAAEkERQAAAAAMBzwoqqrVVXVrVW2uqosO9PMDAByKXIMBAAtxQIOiqjosya8leUmSk5N8T1WdfCD7AABwqHENBgAs1IEeUXR6ks3d/Ynu/lKSq5KcfYD7AABwqHENBgAsyOEH+PmWJ7lr5vGWJN80t1JVrUuybjz8fFXdegD6xtLzjCR/vdidWAz1C4vdA1gUh+zf+eSQ/3v/VYvdgUPAHq/BXH8x+LcYDj2H7N97f+fnvwY70EFRzVPWOxV0X57k8v3fHZayqtrU3asWux/AgeHvPOxXe7wGc/1F4t9iOBT5e89cB3rq2ZYkJ8w8XpFk6wHuAwDAocY1GACwIAc6KHp/kpVVdVJVPSHJmiTXHOA+AAAcalyDAQALckCnnnX3g1X1I0n+MMlhSd7Y3TcfyD7wmGL4Oxxa/J2H/cQ1GHvBv8Vw6PH3nh1U905LBAEAAABwCDrQU88AAAAAWKIERQAAAAAkERQBAAAAMBzQxaxhIarqqCTd3fcvdl8AAAAOJlX1nCRnJ1mepJNsTXJNd9+yqB1jyTCiiCWjqlZV1U1JPpLko1X1Z1V12mL3C9h/quqfVdVtVfXZqvpcVd1fVZ9b7H4BHOqq6gcXuw/AvldV/ybJVUkqyY1J3j+231JVFy1m31g6/OoZS0ZVfSTJhd39J+PxtyS5tLu/YXF7BuwvVbU5yXf5BgtgaamqO7v7WYvdD2Dfqqo/T3JKd//dnPInJLm5u1cuTs9YSkw9Yym5f3tIlCTd/Z6qMv0MDm73CIkAFsf4km7eXUmOO5B9AQ6YLyd5ZpJPzik/fuwDQRFLyo1V9etJ3pJpruy/TPLOqvrGJOnuDy5m54D9YlNV/XaS/5Xkge2F3f27i9YjgEPHcUnOSvKZOeWV5L0HvjvAAfDjSa6vqtuS3DXKnpXk2Ul+ZLE6xdJi6hlLRlX98djc/oeyxnZlWtz62xelY8B+U1Vvmqe4u/uHDnhnAA4xVfWGJG/q7vfMs++3uvt7F6FbwH5WVY9LcnqmxawryZYk7+/uhxa1YywZgiKWjKp6zZyiTpLu/g+L0B3gAKiqJ3b33y52PwAAgImpZywln5/ZfmKSlyWxdgkc3D5aVfck+ZMk707yp9392UXuEwAAHLKMKGLJqqojklzT3Wctdl+A/aeqnpXkRUlemOSfJLmvu5+3qJ0CAIBDlBFFLGVPSvLVi90JYP+pqhWZAqIXJXlukpuT7LRWBgAAcGAIilgyquqmPLyQ9WFJliWxPhEc3O5M8v4k/7m7X7nYnQEAgEOdqWcsGVX1VTMPH0xyT3c/uFj9Afa/qnpukm9J8uJMP816W5J3dfcbFrVjAABwiBIUAbCoquopmcKiFyV5RZLu7hMXtVMAAHCIMvUMgEVTVZuSHJHkvZnWJnpxd39ycXsFAACHLiOKAFg0VbWsu7ctdj8AAIDJ4xa7AwAc0r5UVa+rqk3j9stV9RWL3SkAADhUCYoAWExvTHJ/kpeP2+eSvGlRewQAAIcwU88AWDRV9eHuft6eygAAgAPDiCIAFtMXq+pbtj+oqhcm+eIi9gcAAA5pRhQBsGiq6rlJrkyyfV2izyRZ290fWbxeAQDAoUtQBMABV1U/OfswyZPH9heSdHe/7sD3CgAAOHyxOwDAIemp4/5rk/zDJFdnCoxekeTdi9UpAAA41BlRBMCiqap3JPnn3X3/ePzUJL/T3asXt2cAAHBospg1AIvpWUm+NPP4S0lOXJyuAAAApp4BsJh+I8mNVfW2JJ3knybZsLhdAgCAQ5epZwAsqqr6xiQvGg/f3d0fWsz+AADAoUxQBAAAAEASaxQBAAAAMAiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMDw/wMPWdnXNWIgXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT OF THE BTC PRICE\n",
    "fig, ax = plt.subplots(nrows=2)\n",
    "\n",
    "_ = df['close'].plot(ax=ax[0], title='BTC price')\n",
    "_ = df['close'].diff().plot(ax=ax[1], title='BTC movement')\n",
    "_ = plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 2 labels: up/down\n",
    "price_mov = df['close'].diff().dropna()\n",
    "price_mov_class = price_mov.apply(lambda x: 'up' if x>=0 else 'down')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "_ = price_mov_class.value_counts().plot(kind='bar', title='Up/Down directions count', ax=ax[0])\n",
    "\n",
    "# Same/Different trend as previous one\n",
    "price_trend = (price_mov_class == price_mov_class.shift(1)).dropna()\n",
    "price_trend = price_trend.map({True: 0, False: 1})\n",
    "\n",
    "_ = price_trend.value_counts().plot(kind='bar', title='Keep(0)/Change(1) Trend direction count', ax=ax[1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "iB7Wkeqc_IOp",
    "outputId": "52f29b4c-a0db-4fd5-ed00-a2d3cda5dac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n",
      "2018-10-08 20:00:00    1\n",
      "2018-10-08 21:00:00    1\n",
      "2018-10-08 22:00:00    1\n",
      "2018-10-08 23:00:00    1\n",
      "2018-10-09 00:00:00    0\n",
      "                      ..\n",
      "2020-08-05 07:00:00    1\n",
      "2020-08-05 08:00:00    0\n",
      "2020-08-05 09:00:00    0\n",
      "2020-08-05 10:00:00    0\n",
      "2020-08-05 11:00:00    0\n",
      "Name: close, Length: 15995, dtype: int64\n",
      "{1: 8684, 0: 7311}\n"
     ]
    }
   ],
   "source": [
    "target = price_trend\n",
    "class_weights = price_trend.value_counts().to_dict()\n",
    "print(target)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NmQYMLxN_IOt"
   },
   "source": [
    "## Features Selection, Splitting\n",
    "Kbest with f_classif criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "DniAY3qR_IOt",
    "outputId": "99e71705-fcc0-4e72-9897-169a96aa369e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\damien\\pycharmprojects\\btc_repo\\testvenv2\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass k=400 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15970 entries, 2018-10-09 21:00:00 to 2020-08-05 11:00:00\n",
      "Columns: 400 entries, volumefrom to volumeto_mov24H.MMax12H.diff.Squared\n",
      "dtypes: float64(400)\n",
      "memory usage: 48.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Align the features & Target indexes\n",
    "feats_df['target'] = target\n",
    "feats_df.dropna(inplace=True)\n",
    "target = feats_df['target']\n",
    "feats_df.drop(columns=['target'], inplace=True)\n",
    "\n",
    "# Keep the 400 most relevant features\n",
    "n_best = 400\n",
    "kbest_selector = SelectKBest(f_classif, n_best)\n",
    "\n",
    "# Fit on data\n",
    "kbest_values = kbest_selector.fit_transform(feats_df, target)\n",
    "kbest_df = pd.DataFrame(kbest_values,\n",
    "                        index=feats_df.index,\n",
    "                        columns=feats_df.loc[:, kbest_selector.get_support().tolist()].columns)\n",
    "\n",
    "kbest_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "mklpiAZp_IOw",
    "outputId": "c0988243-a5ae-4edc-9ec2-e999c29d2607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- compute lag 6\n",
      "- compute lag 5\n",
      "- compute lag 4\n",
      "- compute lag 3\n",
      "- compute lag 2\n",
      "- compute lag 1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15964 entries, 2018-10-10 03:00:00 to 2020-08-05 11:00:00\n",
      "Columns: 2800 entries, volumefrom(t6) to volumeto_mov24H.MMax12H.diff.Squared\n",
      "dtypes: float64(2800)\n",
      "memory usage: 341.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Add the 3rd dimension for the lags\n",
    "look_back = 6\n",
    "\n",
    "lagged = []\n",
    "labels = []\n",
    "\n",
    "# Add Lagged Features (from last to newest)\n",
    "for l in range(look_back, 0, -1):\n",
    "    print('- compute lag {}'.format(l))\n",
    "    lagged.append(kbest_df.shift(l))\n",
    "    labels += ['{}(t{})'.format(col, l) for col in kbest_df.columns]\n",
    "\n",
    "# Add actual features dataframe (no lag)\n",
    "lagged.append(kbest_df)\n",
    "labels += kbest_df.columns.tolist()\n",
    "\n",
    "# Put together into DF\n",
    "third_df = pd.concat(lagged, axis=1)\n",
    "third_df.columns = labels\n",
    "\n",
    "\n",
    "# Align the features & Target indexes\n",
    "third_df['target'] = target\n",
    "third_df.dropna(inplace=True)\n",
    "target = third_df['target']\n",
    "third_df.drop(columns=['target'], inplace=True)\n",
    "\n",
    "\n",
    "third_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "gDqREiNu_IOy",
    "outputId": "f6e6d981-f39e-455e-b8ea-6b40ee57aa16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15164\n",
      "473\n",
      "Train: 15136, Test:640, Validation:160\n",
      "- Features arrays shapes: (15964, 2800) (15136, 2800) (640, 2800) (160, 2800)\n",
      "- Features arrays shapes: (15136, 7, 400) (640, 7, 400) (160, 7, 400)\n",
      "- Target arrays shapes: (15136,) (640,) (160,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data - validation on 1 week\n",
    "batch_size = 32\n",
    "n_test = 20 * batch_size\n",
    "n_val = 5 * batch_size\n",
    "\n",
    "# Number of obs to keep in train set to have a round number of batches\n",
    "n_train = int((len(third_df) -n_test-n_val) / batch_size) * batch_size\n",
    "print(len(third_df)-n_test-n_val)\n",
    "print(int((len(third_df) -n_test-n_val) / batch_size))\n",
    "\n",
    "print('Train: {}, Test:{}, Validation:{}'.format(n_train, n_test, n_val))\n",
    "\n",
    "# Features splitting & Scaling\n",
    "X_all = third_df.values\n",
    "X_train = X_all[-n_train-n_test-n_val:-n_test-n_val, :]\n",
    "X_test = X_all[-n_test-n_val:-n_val, :]\n",
    "X_val = X_all[-n_val:, :]\n",
    "\n",
    "print('- Features arrays shapes: {} {} {} {}'.format(X_all.shape, X_train.shape, X_test.shape, X_val.shape))\n",
    "\n",
    "# Scale the values between [-1,1]\n",
    "X_scaler = MinMaxScaler((-1,1))\n",
    "\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "X_val = X_scaler.transform(X_val)\n",
    "\n",
    "# Reshape\n",
    "X_train = X_train.reshape(n_train, look_back+1, n_best)\n",
    "X_test = X_test.reshape(n_test, look_back+1, n_best)\n",
    "X_val = X_val.reshape(n_val, look_back+1, n_best)\n",
    "\n",
    "print('- Features arrays shapes: {} {} {}'.format(X_train.shape, X_test.shape, X_val.shape))\n",
    "\n",
    "# Targets\n",
    "y_all = target.values\n",
    "y_train = y_all[-n_train-n_test-n_val:-n_test-n_val]\n",
    "y_test = y_all[-n_test-n_val:-n_val]\n",
    "y_val = y_all[-n_val:]\n",
    "\n",
    "print('- Target arrays shapes: {} {} {}'.format(y_train.shape, y_test.shape, y_val.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XE9_MEZL_IO1"
   },
   "source": [
    "## Model: LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qx6_dFSNeNVd"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "activation = 'tanh'\n",
    "dropout_rate = 0\n",
    "lr = 1e-5\n",
    "n_epochs = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vHO8_IS7_IO4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (32, 7, 300)              841200    \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (32, 20)                  25680     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (32, 1)                   21        \n",
      "=================================================================\n",
      "Total params: 866,901\n",
      "Trainable params: 866,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Network Architecture\n",
    "lstm = Sequential()\n",
    "\n",
    "\n",
    "lstm.add(LSTM(300, activation=activation, stateful=True,\n",
    "              batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "              return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate))\n",
    "\n",
    "lstm.add(SpatialDropout1D(0.1))\n",
    "\n",
    "#lstm.add(LSTM(200, activation=activation, stateful=True,\n",
    "#              batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "#              return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate))\n",
    "\n",
    "#lstm.add(LSTM(100, activation=activation, stateful=True,\n",
    "#              batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "#              return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate))\n",
    "\n",
    "lstm.add(LSTM(20, activation=activation, stateful=True,\n",
    "              batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "              return_sequences=False, dropout=dropout_rate, recurrent_dropout=dropout_rate))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "print(lstm.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM\n",
    "forward_layer = LSTM(200, activation=activation, stateful=True,\n",
    "                     batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "                     return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate)\n",
    "\n",
    "backward_layer = LSTM(200, activation=activation, stateful=True,\n",
    "                     batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "                     return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate,\n",
    "                      go_backwards=True)\n",
    "\n",
    "lstm.add(Bidirectional(layer=forward_layer, \n",
    "                       #backward_layer=backward_layer, \n",
    "                       merge_mode='concat'))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "lstm.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "\n",
    "\n",
    "#print(lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uG5txqXv_IO9",
    "outputId": "dcf83e5f-de31-463d-afa6-33ea8916dfc4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** epoch 1/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 93s 6ms/step - loss: 5503.1092 - acc: 0.5422 - val_loss: 0.6900 - val_acc: 0.5563\n",
      "** epoch 2/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5482.0190 - acc: 0.5421 - val_loss: 0.6898 - val_acc: 0.5563\n",
      "** epoch 3/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5483.8240 - acc: 0.5422 - val_loss: 0.6898 - val_acc: 0.5563\n",
      "** epoch 4/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5477.6605 - acc: 0.5429 - val_loss: 0.6892 - val_acc: 0.5563\n",
      "** epoch 5/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5472.8044 - acc: 0.5426 - val_loss: 0.6890 - val_acc: 0.5563\n",
      "** epoch 6/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5471.4805 - acc: 0.5429 - val_loss: 0.6886 - val_acc: 0.5563\n",
      "** epoch 7/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5471.9194 - acc: 0.5428 - val_loss: 0.6885 - val_acc: 0.5563\n",
      "** epoch 8/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5469.5540 - acc: 0.5429 - val_loss: 0.6887 - val_acc: 0.5563\n",
      "** epoch 9/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5466.7284 - acc: 0.5427 - val_loss: 0.6887 - val_acc: 0.5563\n",
      "** epoch 10/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5466.6281 - acc: 0.5429 - val_loss: 0.6882 - val_acc: 0.5563\n",
      "** epoch 11/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5464.1224 - acc: 0.5429 - val_loss: 0.6880 - val_acc: 0.5563\n",
      "** epoch 12/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5464.3090 - acc: 0.5429 - val_loss: 0.6880 - val_acc: 0.5563\n",
      "** epoch 13/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5461.1860 - acc: 0.5430 - val_loss: 0.6881 - val_acc: 0.5563\n",
      "** epoch 14/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5464.5772 - acc: 0.5429 - val_loss: 0.6879 - val_acc: 0.5563\n",
      "** epoch 15/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5462.0131 - acc: 0.5428 - val_loss: 0.6877 - val_acc: 0.5563\n",
      "** epoch 16/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5461.2438 - acc: 0.5430 - val_loss: 0.6877 - val_acc: 0.5563\n",
      "** epoch 17/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5458.3143 - acc: 0.5433 - val_loss: 0.6878 - val_acc: 0.5563\n",
      "** epoch 18/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5462.8975 - acc: 0.5431 - val_loss: 0.6875 - val_acc: 0.5563\n",
      "** epoch 19/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5460.5224 - acc: 0.5432 - val_loss: 0.6876 - val_acc: 0.5563\n",
      "** epoch 20/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5459.9399 - acc: 0.5436 - val_loss: 0.6875 - val_acc: 0.5563\n",
      "** epoch 21/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5454.8766 - acc: 0.5439 - val_loss: 0.6877 - val_acc: 0.5563\n",
      "** epoch 22/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5456.7827 - acc: 0.5437 - val_loss: 0.6875 - val_acc: 0.5578\n",
      "** epoch 23/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5456.5273 - acc: 0.5440 - val_loss: 0.6873 - val_acc: 0.5578\n",
      "** epoch 24/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5459.3896 - acc: 0.5441 - val_loss: 0.6871 - val_acc: 0.5578\n",
      "** epoch 25/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5455.2949 - acc: 0.5438 - val_loss: 0.6873 - val_acc: 0.5578\n",
      "** epoch 26/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5456.3724 - acc: 0.5444 - val_loss: 0.6871 - val_acc: 0.5563\n",
      "** epoch 27/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5452.6505 - acc: 0.5443 - val_loss: 0.6870 - val_acc: 0.5578cc\n",
      "** epoch 28/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5452.3048 - acc: 0.5448 - val_loss: 0.6869 - val_acc: 0.5578\n",
      "** epoch 29/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5453.0378 - acc: 0.5453 - val_loss: 0.6868 - val_acc: 0.5578\n",
      "** epoch 30/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5452.4641 - acc: 0.5450 - val_loss: 0.6868 - val_acc: 0.5578\n",
      "** epoch 31/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5452.8472 - acc: 0.5451 - val_loss: 0.6866 - val_acc: 0.5578\n",
      "** epoch 32/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5449.8168 - acc: 0.5454 - val_loss: 0.6864 - val_acc: 0.5578\n",
      "** epoch 33/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5452.2054 - acc: 0.5456 - val_loss: 0.6862 - val_acc: 0.5578\n",
      "** epoch 34/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5449.1073 - acc: 0.5455 - val_loss: 0.6863 - val_acc: 0.5578\n",
      "** epoch 35/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5447.9306 - acc: 0.5455 - val_loss: 0.6860 - val_acc: 0.5578\n",
      "** epoch 36/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5448.6147 - acc: 0.5457 - val_loss: 0.6859 - val_acc: 0.5578 a\n",
      "** epoch 37/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5443.7406 - acc: 0.5462 - val_loss: 0.6859 - val_acc: 0.5578\n",
      "** epoch 38/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5447.1311 - acc: 0.5466 - val_loss: 0.6858 - val_acc: 0.5578\n",
      "** epoch 39/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5445.1839 - acc: 0.5466 - val_loss: 0.6858 - val_acc: 0.5594\n",
      "** epoch 40/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5443.2520 - acc: 0.5464 - val_loss: 0.6855 - val_acc: 0.5594\n",
      "** epoch 41/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5444.8011 - acc: 0.5474 - val_loss: 0.6856 - val_acc: 0.5594\n",
      "** epoch 42/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 5440.2245 - acc: 0.5472 - val_loss: 0.6854 - val_acc: 0.5594\n",
      "** epoch 43/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5441.2615 - acc: 0.5476 - val_loss: 0.6852 - val_acc: 0.5594\n",
      "** epoch 44/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5438.7191 - acc: 0.5480 - val_loss: 0.6852 - val_acc: 0.5594\n",
      "** epoch 45/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5439.2339 - acc: 0.5479 - val_loss: 0.6852 - val_acc: 0.5594\n",
      "** epoch 46/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5443.0767 - acc: 0.5476 - val_loss: 0.6850 - val_acc: 0.5609\n",
      "** epoch 47/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5439.5586 - acc: 0.5489 - val_loss: 0.6849 - val_acc: 0.5609\n",
      "** epoch 48/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5438.6543 - acc: 0.5474 - val_loss: 0.6847 - val_acc: 0.5594\n",
      "** epoch 49/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5439.1437 - acc: 0.5488 - val_loss: 0.6845 - val_acc: 0.5594\n",
      "** epoch 50/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5441.3663 - acc: 0.5494 - val_loss: 0.6845 - val_acc: 0.5594\n",
      "** epoch 51/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5435.0635 - acc: 0.5496 - val_loss: 0.6845 - val_acc: 0.5609\n",
      "** epoch 52/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5437.0143 - acc: 0.5507 - val_loss: 0.6843 - val_acc: 0.5625\n",
      "** epoch 53/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5437.3393 - acc: 0.5501 - val_loss: 0.6842 - val_acc: 0.5625\n",
      "** epoch 54/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5435.2804 - acc: 0.5509 - val_loss: 0.6843 - val_acc: 0.5625\n",
      "** epoch 55/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5431.6896 - acc: 0.5506 - val_loss: 0.6840 - val_acc: 0.5641\n",
      "** epoch 56/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5430.9015 - acc: 0.5511 - val_loss: 0.6840 - val_acc: 0.5641\n",
      "** epoch 57/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5435.4407 - acc: 0.5517 - val_loss: 0.6838 - val_acc: 0.5641\n",
      "** epoch 58/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5432.9102 - acc: 0.5517 - val_loss: 0.6837 - val_acc: 0.5641\n",
      "** epoch 59/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5431.8332 - acc: 0.5522 - val_loss: 0.6837 - val_acc: 0.5656\n",
      "** epoch 60/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5431.0458 - acc: 0.5517 - val_loss: 0.6835 - val_acc: 0.5656\n",
      "** epoch 61/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5429.8572 - acc: 0.5511 - val_loss: 0.6833 - val_acc: 0.5672\n",
      "** epoch 62/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5431.2610 - acc: 0.5531 - val_loss: 0.6832 - val_acc: 0.5672\n",
      "** epoch 63/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5427.8265 - acc: 0.5527 - val_loss: 0.6829 - val_acc: 0.5672\n",
      "** epoch 64/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5425.7597 - acc: 0.5536 - val_loss: 0.6829 - val_acc: 0.5672\n",
      "** epoch 65/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5425.3443 - acc: 0.5536 - val_loss: 0.6826 - val_acc: 0.5672\n",
      "** epoch 66/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5422.0021 - acc: 0.5540 - val_loss: 0.6826 - val_acc: 0.5672\n",
      "** epoch 67/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5421.2680 - acc: 0.5543 - val_loss: 0.6824 - val_acc: 0.5656\n",
      "** epoch 68/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5424.4789 - acc: 0.5544 - val_loss: 0.6822 - val_acc: 0.5656\n",
      "** epoch 69/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5422.1521 - acc: 0.5542 - val_loss: 0.6821 - val_acc: 0.5641\n",
      "** epoch 70/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5420.4872 - acc: 0.5541 - val_loss: 0.6819 - val_acc: 0.5641\n",
      "** epoch 71/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5422.1497 - acc: 0.5542 - val_loss: 0.6818 - val_acc: 0.5641\n",
      "** epoch 72/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5418.8592 - acc: 0.5550 - val_loss: 0.6816 - val_acc: 0.5641\n",
      "** epoch 73/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5423.6924 - acc: 0.5550 - val_loss: 0.6817 - val_acc: 0.5641\n",
      "** epoch 74/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5423.4681 - acc: 0.5564 - val_loss: 0.6816 - val_acc: 0.5641\n",
      "** epoch 75/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5418.8561 - acc: 0.5555 - val_loss: 0.6813 - val_acc: 0.5656\n",
      "** epoch 76/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5415.9407 - acc: 0.5562 - val_loss: 0.6812 - val_acc: 0.5656\n",
      "** epoch 77/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5418.8586 - acc: 0.5565 - val_loss: 0.6810 - val_acc: 0.5625\n",
      "** epoch 78/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5416.6315 - acc: 0.5568 - val_loss: 0.6810 - val_acc: 0.5625\n",
      "** epoch 79/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5419.2864 - acc: 0.5571 - val_loss: 0.6808 - val_acc: 0.5625\n",
      "** epoch 80/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5419.1470 - acc: 0.5556 - val_loss: 0.6809 - val_acc: 0.5625\n",
      "** epoch 81/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5414.1664 - acc: 0.5565 - val_loss: 0.6807 - val_acc: 0.5625\n",
      "** epoch 82/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5414.2031 - acc: 0.5579 - val_loss: 0.6806 - val_acc: 0.5656\n",
      "** epoch 83/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5414.1434 - acc: 0.5566 - val_loss: 0.6805 - val_acc: 0.5656\n",
      "** epoch 84/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5413.1683 - acc: 0.5565 - val_loss: 0.6804 - val_acc: 0.5672\n",
      "** epoch 85/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5407.3375 - acc: 0.5584 - val_loss: 0.6801 - val_acc: 0.5672\n",
      "** epoch 86/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5413.7963 - acc: 0.5566 - val_loss: 0.6802 - val_acc: 0.5672\n",
      "** epoch 87/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5414.5825 - acc: 0.5567 - val_loss: 0.6803 - val_acc: 0.5672\n",
      "** epoch 88/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5410.7046 - acc: 0.5581 - val_loss: 0.6802 - val_acc: 0.5672\n",
      "** epoch 89/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5408.5429 - acc: 0.5583 - val_loss: 0.6800 - val_acc: 0.5672\n",
      "** epoch 90/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5410.3480 - acc: 0.5573 - val_loss: 0.6799 - val_acc: 0.5672\n",
      "** epoch 91/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5413.8979 - acc: 0.5576 - val_loss: 0.6799 - val_acc: 0.5672\n",
      "** epoch 92/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5406.9461 - acc: 0.5587 - val_loss: 0.6798 - val_acc: 0.5687\n",
      "** epoch 93/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5407.8587 - acc: 0.5581 - val_loss: 0.6795 - val_acc: 0.5687\n",
      "** epoch 94/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5404.3350 - acc: 0.5595 - val_loss: 0.6793 - val_acc: 0.5687\n",
      "** epoch 95/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5404.6450 - acc: 0.5584 - val_loss: 0.6793 - val_acc: 0.5687\n",
      "** epoch 96/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5406.3091 - acc: 0.5593 - val_loss: 0.6792 - val_acc: 0.5687\n",
      "** epoch 97/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5408.8134 - acc: 0.5597 - val_loss: 0.6790 - val_acc: 0.5687\n",
      "** epoch 98/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5401.9743 - acc: 0.5594 - val_loss: 0.6790 - val_acc: 0.5687\n",
      "** epoch 99/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5407.1497 - acc: 0.5583 - val_loss: 0.6791 - val_acc: 0.5687\n",
      "** epoch 100/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5400.7023 - acc: 0.5589 - val_loss: 0.6790 - val_acc: 0.5672\n",
      "** epoch 101/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5400.8597 - acc: 0.5605 - val_loss: 0.6787 - val_acc: 0.5703\n",
      "** epoch 102/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5405.2487 - acc: 0.5591 - val_loss: 0.6787 - val_acc: 0.5703\n",
      "** epoch 103/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5402.4861 - acc: 0.5597 - val_loss: 0.6786 - val_acc: 0.5703\n",
      "** epoch 104/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5404.4151 - acc: 0.5601 - val_loss: 0.6787 - val_acc: 0.5703\n",
      "** epoch 105/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5401.4260 - acc: 0.5610 - val_loss: 0.6784 - val_acc: 0.5703\n",
      "** epoch 106/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5400.1131 - acc: 0.5605 - val_loss: 0.6783 - val_acc: 0.5703\n",
      "** epoch 107/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5402.3556 - acc: 0.5605 - val_loss: 0.6782 - val_acc: 0.5703\n",
      "** epoch 108/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5398.3993 - acc: 0.5611 - val_loss: 0.6782 - val_acc: 0.5703\n",
      "** epoch 109/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5402.1626 - acc: 0.5597 - val_loss: 0.6781 - val_acc: 0.5719\n",
      "** epoch 110/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5399.4884 - acc: 0.5608 - val_loss: 0.6780 - val_acc: 0.5719\n",
      "** epoch 111/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 87s 6ms/step - loss: 5400.2343 - acc: 0.5622 - val_loss: 0.6779 - val_acc: 0.5719\n",
      "** epoch 112/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5400.3654 - acc: 0.5609 - val_loss: 0.6778 - val_acc: 0.5719\n",
      "** epoch 113/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5396.3398 - acc: 0.5607 - val_loss: 0.6777 - val_acc: 0.5719\n",
      "** epoch 114/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5398.0780 - acc: 0.5611 - val_loss: 0.6775 - val_acc: 0.5719\n",
      "** epoch 115/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5399.1883 - acc: 0.5621 - val_loss: 0.6776 - val_acc: 0.5719\n",
      "** epoch 116/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5397.9318 - acc: 0.5616 - val_loss: 0.6776 - val_acc: 0.5719\n",
      "** epoch 117/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5397.6949 - acc: 0.5624 - val_loss: 0.6777 - val_acc: 0.5719\n",
      "** epoch 118/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5394.2260 - acc: 0.5624 - val_loss: 0.6776 - val_acc: 0.5719\n",
      "** epoch 119/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5398.9635 - acc: 0.5628 - val_loss: 0.6776 - val_acc: 0.5719\n",
      "** epoch 120/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5395.2505 - acc: 0.5614 - val_loss: 0.6776 - val_acc: 0.5719\n",
      "** epoch 121/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5393.2298 - acc: 0.5625 - val_loss: 0.6774 - val_acc: 0.5719\n",
      "** epoch 122/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5392.9303 - acc: 0.5620 - val_loss: 0.6774 - val_acc: 0.5719\n",
      "** epoch 123/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5392.3749 - acc: 0.5628 - val_loss: 0.6774 - val_acc: 0.5703\n",
      "** epoch 124/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5392.1805 - acc: 0.5645 - val_loss: 0.6772 - val_acc: 0.5703\n",
      "** epoch 125/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5393.1788 - acc: 0.5632 - val_loss: 0.6773 - val_acc: 0.5703\n",
      "** epoch 126/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5387.6348 - acc: 0.5643 - val_loss: 0.6772 - val_acc: 0.5703\n",
      "** epoch 127/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5387.1460 - acc: 0.5642 - val_loss: 0.6773 - val_acc: 0.5703\n",
      "** epoch 128/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5388.4680 - acc: 0.5632 - val_loss: 0.6770 - val_acc: 0.5703\n",
      "** epoch 129/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5389.9156 - acc: 0.5644 - val_loss: 0.6770 - val_acc: 0.5703\n",
      "** epoch 130/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5397.1333 - acc: 0.5649 - val_loss: 0.6768 - val_acc: 0.5703\n",
      "** epoch 131/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5387.7897 - acc: 0.5649 - val_loss: 0.6769 - val_acc: 0.5703\n",
      "** epoch 132/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5392.4053 - acc: 0.5651 - val_loss: 0.6767 - val_acc: 0.5703\n",
      "** epoch 133/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5387.4493 - acc: 0.5643 - val_loss: 0.6765 - val_acc: 0.5687\n",
      "** epoch 134/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5391.4903 - acc: 0.5634 - val_loss: 0.6764 - val_acc: 0.5687\n",
      "** epoch 135/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5394.9741 - acc: 0.5651 - val_loss: 0.6766 - val_acc: 0.5687\n",
      "** epoch 136/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5382.0498 - acc: 0.5646 - val_loss: 0.6764 - val_acc: 0.5687\n",
      "** epoch 137/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5386.9136 - acc: 0.5649 - val_loss: 0.6764 - val_acc: 0.5687\n",
      "** epoch 138/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5388.7203 - acc: 0.5640 - val_loss: 0.6764 - val_acc: 0.5687\n",
      "** epoch 139/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5383.6615 - acc: 0.5647 - val_loss: 0.6763 - val_acc: 0.5703\n",
      "** epoch 140/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5382.5352 - acc: 0.5649 - val_loss: 0.6763 - val_acc: 0.5703\n",
      "** epoch 141/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5387.6615 - acc: 0.5644 - val_loss: 0.6761 - val_acc: 0.5703\n",
      "** epoch 142/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5380.6158 - acc: 0.5655 - val_loss: 0.6760 - val_acc: 0.5719\n",
      "** epoch 143/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5379.7476 - acc: 0.5660 - val_loss: 0.6760 - val_acc: 0.5719\n",
      "** epoch 144/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5379.2346 - acc: 0.5645 - val_loss: 0.6760 - val_acc: 0.5719\n",
      "** epoch 145/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5378.5763 - acc: 0.5661 - val_loss: 0.6760 - val_acc: 0.5719\n",
      "** epoch 146/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5386.4661 - acc: 0.5650 - val_loss: 0.6759 - val_acc: 0.5719\n",
      "** epoch 147/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5380.5318 - acc: 0.5665 - val_loss: 0.6757 - val_acc: 0.5719\n",
      "** epoch 148/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5380.3865 - acc: 0.5657 - val_loss: 0.6755 - val_acc: 0.5719\n",
      "** epoch 149/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5375.2463 - acc: 0.5661 - val_loss: 0.6753 - val_acc: 0.5719\n",
      "** epoch 150/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5385.5037 - acc: 0.5672 - val_loss: 0.6754 - val_acc: 0.5719\n",
      "** epoch 151/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5381.8640 - acc: 0.5679 - val_loss: 0.6758 - val_acc: 0.5734\n",
      "** epoch 152/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5373.5171 - acc: 0.5677 - val_loss: 0.6756 - val_acc: 0.5719\n",
      "** epoch 153/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5381.9219 - acc: 0.5645 - val_loss: 0.6755 - val_acc: 0.5719\n",
      "** epoch 154/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5378.1633 - acc: 0.5667 - val_loss: 0.6757 - val_acc: 0.5719\n",
      "** epoch 155/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5375.0423 - acc: 0.5675 - val_loss: 0.6753 - val_acc: 0.5719\n",
      "** epoch 156/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 89s 6ms/step - loss: 5382.3760 - acc: 0.5673 - val_loss: 0.6753 - val_acc: 0.5719\n",
      "** epoch 157/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5376.2616 - acc: 0.5678 - val_loss: 0.6752 - val_acc: 0.5719\n",
      "** epoch 158/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5376.5636 - acc: 0.5670 - val_loss: 0.6752 - val_acc: 0.5734\n",
      "** epoch 159/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5375.6014 - acc: 0.5671 - val_loss: 0.6751 - val_acc: 0.5719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** epoch 160/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5370.9121 - acc: 0.5665 - val_loss: 0.6750 - val_acc: 0.5719\n",
      "** epoch 161/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5376.5179 - acc: 0.5663 - val_loss: 0.6750 - val_acc: 0.5719\n",
      "** epoch 162/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5372.9016 - acc: 0.5674 - val_loss: 0.6749 - val_acc: 0.5750\n",
      "** epoch 163/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5375.4237 - acc: 0.5679 - val_loss: 0.6747 - val_acc: 0.5750\n",
      "** epoch 164/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5373.0331 - acc: 0.5676 - val_loss: 0.6749 - val_acc: 0.5750\n",
      "** epoch 165/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5370.4466 - acc: 0.5674 - val_loss: 0.6750 - val_acc: 0.5734\n",
      "** epoch 166/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5368.0550 - acc: 0.5688 - val_loss: 0.6746 - val_acc: 0.5750\n",
      "** epoch 167/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5371.5382 - acc: 0.5679 - val_loss: 0.6746 - val_acc: 0.5750\n",
      "** epoch 168/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5370.2146 - acc: 0.5680 - val_loss: 0.6747 - val_acc: 0.5750\n",
      "** epoch 169/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5366.3684 - acc: 0.5694 - val_loss: 0.6745 - val_acc: 0.5734\n",
      "** epoch 170/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5376.4989 - acc: 0.5682 - val_loss: 0.6745 - val_acc: 0.5734\n",
      "** epoch 171/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5364.1662 - acc: 0.5704 - val_loss: 0.6747 - val_acc: 0.5734\n",
      "** epoch 172/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5369.8882 - acc: 0.5684 - val_loss: 0.6744 - val_acc: 0.5734\n",
      "** epoch 173/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5370.4051 - acc: 0.5675 - val_loss: 0.6744 - val_acc: 0.5719\n",
      "** epoch 174/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5363.2256 - acc: 0.5698 - val_loss: 0.6741 - val_acc: 0.5719\n",
      "** epoch 175/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5364.4279 - acc: 0.5706 - val_loss: 0.6741 - val_acc: 0.5719\n",
      "** epoch 176/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5362.0325 - acc: 0.5695 - val_loss: 0.6740 - val_acc: 0.5719\n",
      "** epoch 177/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5360.3960 - acc: 0.5686 - val_loss: 0.6741 - val_acc: 0.5719: 1s - loss: 535\n",
      "** epoch 178/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5364.7252 - acc: 0.5700 - val_loss: 0.6739 - val_acc: 0.5719\n",
      "** epoch 179/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5362.3651 - acc: 0.5692 - val_loss: 0.6738 - val_acc: 0.5703\n",
      "** epoch 180/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5365.3724 - acc: 0.5695 - val_loss: 0.6739 - val_acc: 0.5719\n",
      "** epoch 181/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5362.5054 - acc: 0.5696 - val_loss: 0.6734 - val_acc: 0.5719\n",
      "** epoch 182/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5364.2199 - acc: 0.5690 - val_loss: 0.6736 - val_acc: 0.5703\n",
      "** epoch 183/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5367.6760 - acc: 0.5694 - val_loss: 0.6737 - val_acc: 0.5703\n",
      "** epoch 184/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5357.6163 - acc: 0.5720 - val_loss: 0.6734 - val_acc: 0.5703\n",
      "** epoch 185/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5365.3478 - acc: 0.5701 - val_loss: 0.6734 - val_acc: 0.5703\n",
      "** epoch 186/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5366.3457 - acc: 0.5684 - val_loss: 0.6735 - val_acc: 0.5703\n",
      "** epoch 187/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5365.5454 - acc: 0.5698 - val_loss: 0.6732 - val_acc: 0.5703\n",
      "** epoch 188/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5361.2421 - acc: 0.5713 - val_loss: 0.6732 - val_acc: 0.5703\n",
      "** epoch 189/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5363.2118 - acc: 0.5704 - val_loss: 0.6733 - val_acc: 0.5687\n",
      "** epoch 190/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5359.0057 - acc: 0.5698 - val_loss: 0.6732 - val_acc: 0.5703\n",
      "** epoch 191/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5357.0231 - acc: 0.5705 - val_loss: 0.6730 - val_acc: 0.5703\n",
      "** epoch 192/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5360.3069 - acc: 0.5710 - val_loss: 0.6733 - val_acc: 0.5703\n",
      "** epoch 193/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5358.6374 - acc: 0.5723 - val_loss: 0.6731 - val_acc: 0.5703\n",
      "** epoch 194/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5352.0707 - acc: 0.5717 - val_loss: 0.6731 - val_acc: 0.5703\n",
      "** epoch 195/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5352.6203 - acc: 0.5712 - val_loss: 0.6727 - val_acc: 0.5719\n",
      "** epoch 196/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5358.1683 - acc: 0.5714 - val_loss: 0.6726 - val_acc: 0.5734\n",
      "** epoch 197/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5355.8039 - acc: 0.5729 - val_loss: 0.6726 - val_acc: 0.5719\n",
      "** epoch 198/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5356.7020 - acc: 0.5713 - val_loss: 0.6724 - val_acc: 0.5734\n",
      "** epoch 199/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5356.7205 - acc: 0.5717 - val_loss: 0.6726 - val_acc: 0.5703\n",
      "** epoch 200/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5358.7005 - acc: 0.5731 - val_loss: 0.6726 - val_acc: 0.5719\n",
      "** epoch 201/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5351.5816 - acc: 0.5717 - val_loss: 0.6724 - val_acc: 0.5703\n",
      "** epoch 202/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5350.3706 - acc: 0.5727 - val_loss: 0.6720 - val_acc: 0.5750\n",
      "** epoch 203/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5354.5935 - acc: 0.5719 - val_loss: 0.6722 - val_acc: 0.5734\n",
      "** epoch 204/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5354.5255 - acc: 0.5730 - val_loss: 0.6722 - val_acc: 0.5719\n",
      "** epoch 205/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5349.8886 - acc: 0.5712 - val_loss: 0.6718 - val_acc: 0.5797\n",
      "** epoch 206/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5349.3725 - acc: 0.5751 - val_loss: 0.6718 - val_acc: 0.5781\n",
      "** epoch 207/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5345.9093 - acc: 0.5729 - val_loss: 0.6718 - val_acc: 0.5781\n",
      "** epoch 208/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5354.9469 - acc: 0.5733 - val_loss: 0.6719 - val_acc: 0.5766\n",
      "** epoch 209/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5347.8897 - acc: 0.5739 - val_loss: 0.6715 - val_acc: 0.5797\n",
      "** epoch 210/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5350.2943 - acc: 0.5727 - val_loss: 0.6713 - val_acc: 0.5797\n",
      "** epoch 211/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5346.5979 - acc: 0.5738 - val_loss: 0.6713 - val_acc: 0.5797\n",
      "** epoch 212/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5351.9452 - acc: 0.5729 - val_loss: 0.6715 - val_acc: 0.5781\n",
      "** epoch 213/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5342.6349 - acc: 0.5760 - val_loss: 0.6713 - val_acc: 0.5797\n",
      "** epoch 214/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5345.7918 - acc: 0.5737 - val_loss: 0.6712 - val_acc: 0.5781\n",
      "** epoch 215/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5340.1115 - acc: 0.5752 - val_loss: 0.6712 - val_acc: 0.5781\n",
      "** epoch 216/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5345.4763 - acc: 0.5726 - val_loss: 0.6713 - val_acc: 0.5781\n",
      "** epoch 217/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5346.5430 - acc: 0.5739 - val_loss: 0.6712 - val_acc: 0.5781\n",
      "** epoch 218/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5353.0287 - acc: 0.5725 - val_loss: 0.6713 - val_acc: 0.5781\n",
      "** epoch 219/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5337.8373 - acc: 0.5764 - val_loss: 0.6714 - val_acc: 0.5781\n",
      "** epoch 220/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5341.4820 - acc: 0.5745 - val_loss: 0.6712 - val_acc: 0.5781\n",
      "** epoch 221/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5344.0765 - acc: 0.5733 - val_loss: 0.6711 - val_acc: 0.5781\n",
      "** epoch 222/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5344.4343 - acc: 0.5732 - val_loss: 0.6712 - val_acc: 0.5781\n",
      "** epoch 223/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5344.6083 - acc: 0.5752 - val_loss: 0.6709 - val_acc: 0.5781\n",
      "** epoch 224/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5341.6850 - acc: 0.5746 - val_loss: 0.6706 - val_acc: 0.5813\n",
      "** epoch 225/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5343.8930 - acc: 0.5736 - val_loss: 0.6707 - val_acc: 0.5797\n",
      "** epoch 226/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5338.1078 - acc: 0.5740 - val_loss: 0.6706 - val_acc: 0.5797\n",
      "** epoch 227/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5334.4324 - acc: 0.5757 - val_loss: 0.6704 - val_acc: 0.5813\n",
      "** epoch 228/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5338.2599 - acc: 0.5760 - val_loss: 0.6702 - val_acc: 0.5813\n",
      "** epoch 229/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5337.9900 - acc: 0.5788 - val_loss: 0.6703 - val_acc: 0.5813\n",
      "** epoch 230/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5338.1370 - acc: 0.5756 - val_loss: 0.6704 - val_acc: 0.5813\n",
      "** epoch 231/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5334.3492 - acc: 0.5764 - val_loss: 0.6703 - val_acc: 0.5813\n",
      "** epoch 232/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5331.7465 - acc: 0.5770 - val_loss: 0.6703 - val_acc: 0.5813\n",
      "** epoch 233/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5338.7328 - acc: 0.5753 - val_loss: 0.6701 - val_acc: 0.5813\n",
      "** epoch 234/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5333.5536 - acc: 0.5743 - val_loss: 0.6702 - val_acc: 0.5813\n",
      "** epoch 235/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5327.9490 - acc: 0.5761 - val_loss: 0.6701 - val_acc: 0.5828\n",
      "** epoch 236/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5333.3056 - acc: 0.5760 - val_loss: 0.6699 - val_acc: 0.5828\n",
      "** epoch 237/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5335.7015 - acc: 0.5761 - val_loss: 0.6698 - val_acc: 0.5828\n",
      "** epoch 238/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 76s 5ms/step - loss: 5333.6229 - acc: 0.5787 - val_loss: 0.6699 - val_acc: 0.5828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** epoch 239/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 78s 5ms/step - loss: 5335.5125 - acc: 0.5764 - val_loss: 0.6698 - val_acc: 0.5828\n",
      "** epoch 240/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 5339.7726 - acc: 0.5778 - val_loss: 0.6701 - val_acc: 0.5828\n",
      "** epoch 241/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5337.7255 - acc: 0.5763 - val_loss: 0.6701 - val_acc: 0.5828\n",
      "** epoch 242/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5327.4464 - acc: 0.5777 - val_loss: 0.6697 - val_acc: 0.5828\n",
      "** epoch 243/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5336.7426 - acc: 0.5766 - val_loss: 0.6699 - val_acc: 0.5828\n",
      "** epoch 244/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5335.0089 - acc: 0.5779 - val_loss: 0.6696 - val_acc: 0.5828\n",
      "** epoch 245/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5331.3766 - acc: 0.5766 - val_loss: 0.6695 - val_acc: 0.5828\n",
      "** epoch 246/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5328.3256 - acc: 0.5778 - val_loss: 0.6695 - val_acc: 0.5828\n",
      "** epoch 247/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 5327.4530 - acc: 0.5770 - val_loss: 0.6693 - val_acc: 0.5828\n",
      "** epoch 248/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5333.4069 - acc: 0.5769 - val_loss: 0.6695 - val_acc: 0.5828\n",
      "** epoch 249/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5325.6886 - acc: 0.5779 - val_loss: 0.6693 - val_acc: 0.5828\n",
      "** epoch 250/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5326.4278 - acc: 0.5780 - val_loss: 0.6690 - val_acc: 0.5828\n",
      "** epoch 251/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5328.8673 - acc: 0.5782 - val_loss: 0.6693 - val_acc: 0.5828\n",
      "** epoch 252/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5329.0462 - acc: 0.5781 - val_loss: 0.6691 - val_acc: 0.5828\n",
      "** epoch 253/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5320.4801 - acc: 0.5778 - val_loss: 0.6693 - val_acc: 0.5828\n",
      "** epoch 254/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5332.2852 - acc: 0.5777 - val_loss: 0.6689 - val_acc: 0.5844\n",
      "** epoch 255/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5323.7882 - acc: 0.5784 - val_loss: 0.6688 - val_acc: 0.5844\n",
      "** epoch 256/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5327.2812 - acc: 0.5788 - val_loss: 0.6683 - val_acc: 0.5844\n",
      "** epoch 257/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5321.4023 - acc: 0.5764 - val_loss: 0.6686 - val_acc: 0.5828\n",
      "** epoch 258/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5317.8610 - acc: 0.5774 - val_loss: 0.6685 - val_acc: 0.5828\n",
      "** epoch 259/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5325.4726 - acc: 0.5790 - val_loss: 0.6686 - val_acc: 0.5828\n",
      "** epoch 260/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5320.6218 - acc: 0.5804 - val_loss: 0.6685 - val_acc: 0.5828\n",
      "** epoch 261/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5329.3097 - acc: 0.5796 - val_loss: 0.6685 - val_acc: 0.5828\n",
      "** epoch 262/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5323.3885 - acc: 0.5807 - val_loss: 0.6682 - val_acc: 0.5828\n",
      "** epoch 263/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5326.7792 - acc: 0.5766 - val_loss: 0.6683 - val_acc: 0.5828\n",
      "** epoch 264/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5316.5529 - acc: 0.5790 - val_loss: 0.6682 - val_acc: 0.5828\n",
      "** epoch 265/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5320.1592 - acc: 0.5796 - val_loss: 0.6682 - val_acc: 0.5828\n",
      "** epoch 266/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5316.2107 - acc: 0.5807 - val_loss: 0.6679 - val_acc: 0.5844\n",
      "** epoch 267/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5319.3396 - acc: 0.5801 - val_loss: 0.6677 - val_acc: 0.5859\n",
      "** epoch 268/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5313.8881 - acc: 0.5802 - val_loss: 0.6679 - val_acc: 0.5813\n",
      "** epoch 269/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5311.9133 - acc: 0.5803 - val_loss: 0.6676 - val_acc: 0.5828\n",
      "** epoch 270/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 5317.5123 - acc: 0.5793 - val_loss: 0.6681 - val_acc: 0.5813\n",
      "** epoch 271/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5321.8889 - acc: 0.5790 - val_loss: 0.6680 - val_acc: 0.5828\n",
      "** epoch 272/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5317.1630 - acc: 0.5830 - val_loss: 0.6680 - val_acc: 0.5828\n",
      "** epoch 273/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5315.1881 - acc: 0.5826 - val_loss: 0.6674 - val_acc: 0.5875\n",
      "** epoch 274/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5318.2197 - acc: 0.5810 - val_loss: 0.6674 - val_acc: 0.5859\n",
      "** epoch 275/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5316.4519 - acc: 0.5821 - val_loss: 0.6673 - val_acc: 0.5891\n",
      "** epoch 276/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5320.3904 - acc: 0.5790 - val_loss: 0.6674 - val_acc: 0.5875\n",
      "** epoch 277/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5314.0734 - acc: 0.5803 - val_loss: 0.6674 - val_acc: 0.5859\n",
      "** epoch 278/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5310.1738 - acc: 0.5816 - val_loss: 0.6673 - val_acc: 0.5875\n",
      "** epoch 279/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5309.8025 - acc: 0.5807 - val_loss: 0.6671 - val_acc: 0.5875\n",
      "** epoch 280/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5308.4112 - acc: 0.5797 - val_loss: 0.6669 - val_acc: 0.5906\n",
      "** epoch 281/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 5313.5513 - acc: 0.5817 - val_loss: 0.6673 - val_acc: 0.5875\n",
      "** epoch 282/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5314.7708 - acc: 0.5799 - val_loss: 0.6671 - val_acc: 0.5859\n",
      "** epoch 283/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 5309.9499 - acc: 0.5811 - val_loss: 0.6671 - val_acc: 0.5875\n",
      "** epoch 284/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5308.1127 - acc: 0.5828 - val_loss: 0.6668 - val_acc: 0.5906\n",
      "** epoch 285/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5313.7138 - acc: 0.5816 - val_loss: 0.6667 - val_acc: 0.5906\n",
      "** epoch 286/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5316.3627 - acc: 0.5821 - val_loss: 0.6668 - val_acc: 0.5891\n",
      "** epoch 287/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5310.1011 - acc: 0.5846 - val_loss: 0.6670 - val_acc: 0.5875\n",
      "** epoch 288/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5304.6331 - acc: 0.5798 - val_loss: 0.6669 - val_acc: 0.5875\n",
      "** epoch 289/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5306.0374 - acc: 0.5821 - val_loss: 0.6668 - val_acc: 0.5906\n",
      "** epoch 290/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5307.5089 - acc: 0.5811 - val_loss: 0.6668 - val_acc: 0.5906TA: 1s - loss: 5307.40\n",
      "** epoch 291/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5304.0828 - acc: 0.5834 - val_loss: 0.6669 - val_acc: 0.5891\n",
      "** epoch 292/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5295.7988 - acc: 0.5844 - val_loss: 0.6667 - val_acc: 0.5906\n",
      "** epoch 293/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5313.4174 - acc: 0.5835 - val_loss: 0.6668 - val_acc: 0.5906\n",
      "** epoch 294/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 91s 6ms/step - loss: 5301.1360 - acc: 0.5843 - val_loss: 0.6663 - val_acc: 0.5922\n",
      "** epoch 295/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5306.4821 - acc: 0.5817 - val_loss: 0.6663 - val_acc: 0.5906\n",
      "** epoch 296/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5303.9861 - acc: 0.5827 - val_loss: 0.6661 - val_acc: 0.5906\n",
      "** epoch 297/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 5302.7368 - acc: 0.5834 - val_loss: 0.6663 - val_acc: 0.5891\n",
      "** epoch 298/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5307.9285 - acc: 0.5810 - val_loss: 0.6666 - val_acc: 0.5906\n",
      "** epoch 299/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5295.3368 - acc: 0.5838 - val_loss: 0.6665 - val_acc: 0.5922\n",
      "** epoch 300/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5307.9552 - acc: 0.5826 - val_loss: 0.6667 - val_acc: 0.5891\n",
      "** epoch 301/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5299.3114 - acc: 0.5836 - val_loss: 0.6665 - val_acc: 0.5906\n",
      "** epoch 302/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5301.0705 - acc: 0.5850 - val_loss: 0.6662 - val_acc: 0.5906\n",
      "** epoch 303/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5305.2065 - acc: 0.5819 - val_loss: 0.6660 - val_acc: 0.5891\n",
      "** epoch 304/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5290.3033 - acc: 0.5860 - val_loss: 0.6659 - val_acc: 0.5906\n",
      "** epoch 305/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5303.0583 - acc: 0.5830 - val_loss: 0.6662 - val_acc: 0.5906\n",
      "** epoch 306/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5301.1713 - acc: 0.5827 - val_loss: 0.6660 - val_acc: 0.5875\n",
      "** epoch 307/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5300.2517 - acc: 0.5852 - val_loss: 0.6662 - val_acc: 0.5906\n",
      "** epoch 308/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5300.5790 - acc: 0.5851 - val_loss: 0.6658 - val_acc: 0.5938\n",
      "** epoch 309/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5295.5869 - acc: 0.5862 - val_loss: 0.6660 - val_acc: 0.5891\n",
      "** epoch 310/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5299.5020 - acc: 0.5828 - val_loss: 0.6662 - val_acc: 0.5906\n",
      "** epoch 311/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5303.2011 - acc: 0.5829 - val_loss: 0.6660 - val_acc: 0.5922\n",
      "** epoch 312/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5298.8590 - acc: 0.5832 - val_loss: 0.6660 - val_acc: 0.5891\n",
      "** epoch 313/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5294.6892 - acc: 0.5841 - val_loss: 0.6657 - val_acc: 0.5922\n",
      "** epoch 314/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5294.7412 - acc: 0.5837 - val_loss: 0.6658 - val_acc: 0.5906\n",
      "** epoch 315/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5294.8234 - acc: 0.5847 - val_loss: 0.6662 - val_acc: 0.5875\n",
      "** epoch 316/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5295.0872 - acc: 0.5848 - val_loss: 0.6659 - val_acc: 0.5891\n",
      "** epoch 317/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5305.1370 - acc: 0.5842 - val_loss: 0.6659 - val_acc: 0.5891\n",
      "** epoch 318/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5295.5040 - acc: 0.5852 - val_loss: 0.6657 - val_acc: 0.59064.0919\n",
      "** epoch 319/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5290.8651 - acc: 0.5833 - val_loss: 0.6652 - val_acc: 0.5922\n",
      "** epoch 320/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5289.2625 - acc: 0.5846 - val_loss: 0.6656 - val_acc: 0.5906\n",
      "** epoch 321/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5295.8873 - acc: 0.5842 - val_loss: 0.6655 - val_acc: 0.5906\n",
      "** epoch 322/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5298.3642 - acc: 0.5830 - val_loss: 0.6657 - val_acc: 0.5891\n",
      "** epoch 323/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5290.4791 - acc: 0.5860 - val_loss: 0.6655 - val_acc: 0.5922\n",
      "** epoch 324/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5293.4224 - acc: 0.5860 - val_loss: 0.6652 - val_acc: 0.5922\n",
      "** epoch 325/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5286.7029 - acc: 0.5869 - val_loss: 0.6656 - val_acc: 0.5906\n",
      "** epoch 326/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5292.5912 - acc: 0.5867 - val_loss: 0.6657 - val_acc: 0.5906\n",
      "** epoch 327/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5296.4235 - acc: 0.5860 - val_loss: 0.6654 - val_acc: 0.5953\n",
      "** epoch 328/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5291.8751 - acc: 0.5856 - val_loss: 0.6654 - val_acc: 0.5938\n",
      "** epoch 329/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5287.4255 - acc: 0.5867 - val_loss: 0.6651 - val_acc: 0.5969\n",
      "** epoch 330/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5292.5151 - acc: 0.5834 - val_loss: 0.6652 - val_acc: 0.5953\n",
      "** epoch 331/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5293.8992 - acc: 0.5856 - val_loss: 0.6651 - val_acc: 0.5922\n",
      "** epoch 332/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5286.5564 - acc: 0.5844 - val_loss: 0.6650 - val_acc: 0.5922\n",
      "** epoch 333/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5290.0129 - acc: 0.5856 - val_loss: 0.6647 - val_acc: 0.5969\n",
      "** epoch 334/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5290.5894 - acc: 0.5842 - val_loss: 0.6651 - val_acc: 0.5938\n",
      "** epoch 335/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5289.5161 - acc: 0.5844 - val_loss: 0.6650 - val_acc: 0.5953\n",
      "** epoch 336/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5283.4111 - acc: 0.5874 - val_loss: 0.6647 - val_acc: 0.5969\n",
      "** epoch 337/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5290.4129 - acc: 0.5852 - val_loss: 0.6650 - val_acc: 0.5938\n",
      "** epoch 338/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5285.8411 - acc: 0.5852 - val_loss: 0.6646 - val_acc: 0.5969\n",
      "** epoch 339/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5280.8153 - acc: 0.5875 - val_loss: 0.6645 - val_acc: 0.5969\n",
      "** epoch 340/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5286.2917 - acc: 0.5866 - val_loss: 0.6646 - val_acc: 0.5969\n",
      "** epoch 341/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5281.6633 - acc: 0.5853 - val_loss: 0.6644 - val_acc: 0.6000\n",
      "** epoch 342/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5284.5120 - acc: 0.5872 - val_loss: 0.6642 - val_acc: 0.6000\n",
      "** epoch 343/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5283.5389 - acc: 0.5883 - val_loss: 0.6645 - val_acc: 0.5969\n",
      "** epoch 344/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5283.4920 - acc: 0.5862 - val_loss: 0.6645 - val_acc: 0.5969\n",
      "** epoch 345/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5275.9714 - acc: 0.5875 - val_loss: 0.6644 - val_acc: 0.5969\n",
      "** epoch 346/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5284.1531 - acc: 0.5875 - val_loss: 0.6645 - val_acc: 0.5969\n",
      "** epoch 347/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5277.3682 - acc: 0.5886 - val_loss: 0.6647 - val_acc: 0.5953\n",
      "** epoch 348/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5275.8531 - acc: 0.5896 - val_loss: 0.6640 - val_acc: 0.6000\n",
      "** epoch 349/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5286.4351 - acc: 0.5879 - val_loss: 0.6645 - val_acc: 0.5969\n",
      "** epoch 350/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5283.9614 - acc: 0.5877 - val_loss: 0.6646 - val_acc: 0.5953\n",
      "** epoch 351/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5278.2561 - acc: 0.5901 - val_loss: 0.6646 - val_acc: 0.5969\n",
      "** epoch 352/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5274.8463 - acc: 0.5877 - val_loss: 0.6643 - val_acc: 0.5953\n",
      "** epoch 353/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5276.5380 - acc: 0.5892 - val_loss: 0.6645 - val_acc: 0.5953\n",
      "** epoch 354/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5274.4449 - acc: 0.5887 - val_loss: 0.6643 - val_acc: 0.5953\n",
      "** epoch 355/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5285.4529 - acc: 0.5881 - val_loss: 0.6644 - val_acc: 0.5984\n",
      "** epoch 356/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5277.7229 - acc: 0.5883 - val_loss: 0.6643 - val_acc: 0.5984\n",
      "** epoch 357/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5281.0044 - acc: 0.5885 - val_loss: 0.6642 - val_acc: 0.6000\n",
      "** epoch 358/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5276.9452 - acc: 0.5890 - val_loss: 0.6640 - val_acc: 0.60001s - loss: 527\n",
      "** epoch 359/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5278.9042 - acc: 0.5882 - val_loss: 0.6638 - val_acc: 0.6000\n",
      "** epoch 360/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5279.4294 - acc: 0.5866 - val_loss: 0.6642 - val_acc: 0.5984\n",
      "** epoch 361/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5268.3234 - acc: 0.5886 - val_loss: 0.6639 - val_acc: 0.6000\n",
      "** epoch 362/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5276.7665 - acc: 0.5859 - val_loss: 0.6636 - val_acc: 0.6000\n",
      "** epoch 363/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5280.2024 - acc: 0.5901 - val_loss: 0.6640 - val_acc: 0.6000\n",
      "** epoch 364/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5280.1040 - acc: 0.5858 - val_loss: 0.6638 - val_acc: 0.6016\n",
      "** epoch 365/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5276.0835 - acc: 0.5870 - val_loss: 0.6643 - val_acc: 0.6000\n",
      "** epoch 366/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5274.2080 - acc: 0.5867 - val_loss: 0.6639 - val_acc: 0.6016\n",
      "** epoch 367/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5272.8765 - acc: 0.5898 - val_loss: 0.6639 - val_acc: 0.6000\n",
      "** epoch 368/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5274.5819 - acc: 0.5893 - val_loss: 0.6636 - val_acc: 0.6016\n",
      "** epoch 369/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5275.6888 - acc: 0.5884 - val_loss: 0.6634 - val_acc: 0.6000\n",
      "** epoch 370/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5262.0017 - acc: 0.5916 - val_loss: 0.6637 - val_acc: 0.6016\n",
      "** epoch 371/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5266.6836 - acc: 0.5899 - val_loss: 0.6636 - val_acc: 0.6000\n",
      "** epoch 372/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5272.8493 - acc: 0.5903 - val_loss: 0.6634 - val_acc: 0.6016\n",
      "** epoch 373/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5277.7286 - acc: 0.5926 - val_loss: 0.6637 - val_acc: 0.6016\n",
      "** epoch 374/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5267.7657 - acc: 0.5902 - val_loss: 0.6634 - val_acc: 0.6016\n",
      "** epoch 375/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5272.6231 - acc: 0.5917 - val_loss: 0.6632 - val_acc: 0.6000\n",
      "** epoch 376/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5268.3329 - acc: 0.5882 - val_loss: 0.6628 - val_acc: 0.6047\n",
      "** epoch 377/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5272.7234 - acc: 0.5888 - val_loss: 0.6638 - val_acc: 0.6016\n",
      "** epoch 378/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5267.7050 - acc: 0.5880 - val_loss: 0.6633 - val_acc: 0.6016\n",
      "** epoch 379/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5265.8994 - acc: 0.5889 - val_loss: 0.6635 - val_acc: 0.6016\n",
      "** epoch 380/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5277.2179 - acc: 0.5888 - val_loss: 0.6634 - val_acc: 0.6000\n",
      "** epoch 381/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5271.9439 - acc: 0.5897 - val_loss: 0.6632 - val_acc: 0.5984\n",
      "** epoch 382/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 5265.6477 - acc: 0.5907 - val_loss: 0.6630 - val_acc: 0.6016\n",
      "** epoch 383/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5262.0579 - acc: 0.5905 - val_loss: 0.6628 - val_acc: 0.6016\n",
      "** epoch 384/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5261.2053 - acc: 0.5916 - val_loss: 0.6628 - val_acc: 0.6016\n",
      "** epoch 385/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5276.5921 - acc: 0.5895 - val_loss: 0.6627 - val_acc: 0.6031\n",
      "** epoch 386/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5256.7347 - acc: 0.5891 - val_loss: 0.6626 - val_acc: 0.6031\n",
      "** epoch 387/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5264.9626 - acc: 0.5885 - val_loss: 0.6632 - val_acc: 0.6016\n",
      "** epoch 388/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5276.2825 - acc: 0.5882 - val_loss: 0.6629 - val_acc: 0.6016\n",
      "** epoch 389/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5267.7483 - acc: 0.5888 - val_loss: 0.6630 - val_acc: 0.6016\n",
      "** epoch 390/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5266.0073 - acc: 0.5868 - val_loss: 0.6629 - val_acc: 0.6016\n",
      "** epoch 391/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5261.4915 - acc: 0.5916 - val_loss: 0.6626 - val_acc: 0.6031\n",
      "** epoch 392/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5262.6159 - acc: 0.5916 - val_loss: 0.6627 - val_acc: 0.6016\n",
      "** epoch 393/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5259.8984 - acc: 0.5904 - val_loss: 0.6631 - val_acc: 0.6016\n",
      "** epoch 394/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5255.3052 - acc: 0.5909 - val_loss: 0.6626 - val_acc: 0.6016\n",
      "** epoch 395/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5254.4504 - acc: 0.5887 - val_loss: 0.6620 - val_acc: 0.6047\n",
      "** epoch 396/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5260.6821 - acc: 0.5917 - val_loss: 0.6622 - val_acc: 0.6062\n",
      "** epoch 397/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5265.1100 - acc: 0.5907 - val_loss: 0.6625 - val_acc: 0.6047\n",
      "** epoch 398/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5258.3268 - acc: 0.5901 - val_loss: 0.6631 - val_acc: 0.6016\n",
      "** epoch 399/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5254.0001 - acc: 0.5910 - val_loss: 0.6627 - val_acc: 0.6031\n",
      "** epoch 400/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5265.1060 - acc: 0.5920 - val_loss: 0.6625 - val_acc: 0.6047\n",
      "** epoch 401/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5247.0653 - acc: 0.5953 - val_loss: 0.6619 - val_acc: 0.6062\n",
      "** epoch 402/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5263.0731 - acc: 0.5906 - val_loss: 0.6625 - val_acc: 0.6062\n",
      "** epoch 403/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5255.4962 - acc: 0.5936 - val_loss: 0.6622 - val_acc: 0.6047\n",
      "** epoch 404/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5248.6835 - acc: 0.5901 - val_loss: 0.6621 - val_acc: 0.6031\n",
      "** epoch 405/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5248.9394 - acc: 0.5918 - val_loss: 0.6620 - val_acc: 0.6047\n",
      "** epoch 406/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5254.3619 - acc: 0.5961 - val_loss: 0.6622 - val_acc: 0.6047\n",
      "** epoch 407/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5252.7425 - acc: 0.5944 - val_loss: 0.6625 - val_acc: 0.6031\n",
      "** epoch 408/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5252.9887 - acc: 0.5924 - val_loss: 0.6623 - val_acc: 0.6031\n",
      "** epoch 409/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5245.8570 - acc: 0.5942 - val_loss: 0.6620 - val_acc: 0.6047\n",
      "** epoch 410/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5256.8717 - acc: 0.5920 - val_loss: 0.6620 - val_acc: 0.6078\n",
      "** epoch 411/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5256.7022 - acc: 0.5929 - val_loss: 0.6621 - val_acc: 0.6047\n",
      "** epoch 412/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5255.4899 - acc: 0.5933 - val_loss: 0.6619 - val_acc: 0.6047\n",
      "** epoch 413/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5253.3447 - acc: 0.5933 - val_loss: 0.6623 - val_acc: 0.604717 - acc: 0.584 - ETA: 25s \n",
      "** epoch 414/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5258.6161 - acc: 0.5915 - val_loss: 0.6623 - val_acc: 0.6047\n",
      "** epoch 415/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5251.0691 - acc: 0.5911 - val_loss: 0.6614 - val_acc: 0.6062\n",
      "** epoch 416/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5255.5961 - acc: 0.5899 - val_loss: 0.6619 - val_acc: 0.6047\n",
      "** epoch 417/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5256.4183 - acc: 0.5903 - val_loss: 0.6626 - val_acc: 0.5984\n",
      "** epoch 418/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5248.7675 - acc: 0.5926 - val_loss: 0.6618 - val_acc: 0.6062\n",
      "** epoch 419/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5249.3062 - acc: 0.5945 - val_loss: 0.6622 - val_acc: 0.6062\n",
      "** epoch 420/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5257.0201 - acc: 0.5910 - val_loss: 0.6626 - val_acc: 0.5984\n",
      "** epoch 421/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5248.5100 - acc: 0.5898 - val_loss: 0.6623 - val_acc: 0.5984\n",
      "** epoch 422/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5248.3437 - acc: 0.5913 - val_loss: 0.6622 - val_acc: 0.6031\n",
      "** epoch 423/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5251.9534 - acc: 0.5932 - val_loss: 0.6618 - val_acc: 0.6078\n",
      "** epoch 424/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5238.5797 - acc: 0.5951 - val_loss: 0.6615 - val_acc: 0.6062\n",
      "** epoch 425/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5238.8759 - acc: 0.5945 - val_loss: 0.6621 - val_acc: 0.6000\n",
      "** epoch 426/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5246.6232 - acc: 0.5910 - val_loss: 0.6620 - val_acc: 0.6047\n",
      "** epoch 427/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5253.9434 - acc: 0.5916 - val_loss: 0.6615 - val_acc: 0.6062\n",
      "** epoch 428/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5243.2756 - acc: 0.5912 - val_loss: 0.6618 - val_acc: 0.6016\n",
      "** epoch 429/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5245.8512 - acc: 0.5929 - val_loss: 0.6619 - val_acc: 0.6016\n",
      "** epoch 430/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5242.4836 - acc: 0.5940 - val_loss: 0.6615 - val_acc: 0.6047\n",
      "** epoch 431/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5240.1765 - acc: 0.5938 - val_loss: 0.6618 - val_acc: 0.6047\n",
      "** epoch 432/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5242.9129 - acc: 0.5935 - val_loss: 0.6617 - val_acc: 0.6047\n",
      "** epoch 433/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5241.8612 - acc: 0.5943 - val_loss: 0.6611 - val_acc: 0.6047\n",
      "** epoch 434/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5249.0571 - acc: 0.5918 - val_loss: 0.6618 - val_acc: 0.6016\n",
      "** epoch 435/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5243.3810 - acc: 0.5915 - val_loss: 0.6608 - val_acc: 0.6078\n",
      "** epoch 436/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5246.8220 - acc: 0.5927 - val_loss: 0.6612 - val_acc: 0.6062\n",
      "** epoch 437/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5230.3087 - acc: 0.5959 - val_loss: 0.6611 - val_acc: 0.6016\n",
      "** epoch 438/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5232.5104 - acc: 0.5967 - val_loss: 0.6609 - val_acc: 0.6031\n",
      "** epoch 439/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5241.6161 - acc: 0.5939 - val_loss: 0.6611 - val_acc: 0.6062\n",
      "** epoch 440/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5240.0911 - acc: 0.5928 - val_loss: 0.6609 - val_acc: 0.6047\n",
      "** epoch 441/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5239.0513 - acc: 0.5944 - val_loss: 0.6614 - val_acc: 0.6031\n",
      "** epoch 442/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5237.1380 - acc: 0.5962 - val_loss: 0.6616 - val_acc: 0.6047\n",
      "** epoch 443/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5241.8341 - acc: 0.5948 - val_loss: 0.6614 - val_acc: 0.6062\n",
      "** epoch 444/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5248.3026 - acc: 0.5930 - val_loss: 0.6615 - val_acc: 0.6016\n",
      "** epoch 445/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5244.6259 - acc: 0.5929 - val_loss: 0.6613 - val_acc: 0.6031\n",
      "** epoch 446/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5237.3458 - acc: 0.5942 - val_loss: 0.6618 - val_acc: 0.6000\n",
      "** epoch 447/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5228.6693 - acc: 0.5970 - val_loss: 0.6612 - val_acc: 0.6062\n",
      "** epoch 448/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5226.9119 - acc: 0.5939 - val_loss: 0.6608 - val_acc: 0.6047\n",
      "** epoch 449/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5238.0840 - acc: 0.5939 - val_loss: 0.6613 - val_acc: 0.6016\n",
      "** epoch 450/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5234.7794 - acc: 0.5960 - val_loss: 0.6614 - val_acc: 0.6031\n",
      "** epoch 451/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5232.5191 - acc: 0.5924 - val_loss: 0.6609 - val_acc: 0.6047\n",
      "** epoch 452/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5235.7122 - acc: 0.5920 - val_loss: 0.6609 - val_acc: 0.6047\n",
      "** epoch 453/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5227.7147 - acc: 0.5951 - val_loss: 0.6609 - val_acc: 0.6016\n",
      "** epoch 454/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5235.0124 - acc: 0.5954 - val_loss: 0.6611 - val_acc: 0.6031\n",
      "** epoch 455/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5220.6355 - acc: 0.5982 - val_loss: 0.6605 - val_acc: 0.6047\n",
      "** epoch 456/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5236.3684 - acc: 0.5963 - val_loss: 0.6601 - val_acc: 0.6031\n",
      "** epoch 457/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5235.3225 - acc: 0.5939 - val_loss: 0.6612 - val_acc: 0.6000\n",
      "** epoch 458/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5229.1889 - acc: 0.5971 - val_loss: 0.6610 - val_acc: 0.6031\n",
      "** epoch 459/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5233.6376 - acc: 0.5957 - val_loss: 0.6612 - val_acc: 0.6031\n",
      "** epoch 460/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5236.6796 - acc: 0.5930 - val_loss: 0.6607 - val_acc: 0.6047\n",
      "** epoch 461/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5226.8087 - acc: 0.5957 - val_loss: 0.6609 - val_acc: 0.6016\n",
      "** epoch 462/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5233.7126 - acc: 0.5941 - val_loss: 0.6610 - val_acc: 0.6031\n",
      "** epoch 463/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5226.3774 - acc: 0.5956 - val_loss: 0.6603 - val_acc: 0.6047\n",
      "** epoch 464/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5229.0153 - acc: 0.5947 - val_loss: 0.6605 - val_acc: 0.6047\n",
      "** epoch 465/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5231.5759 - acc: 0.5945 - val_loss: 0.6611 - val_acc: 0.6031\n",
      "** epoch 466/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5220.5889 - acc: 0.5940 - val_loss: 0.6610 - val_acc: 0.6047\n",
      "** epoch 467/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 5221.9707 - acc: 0.5957 - val_loss: 0.6604 - val_acc: 0.6062\n",
      "** epoch 468/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 5227.5010 - acc: 0.5945 - val_loss: 0.6603 - val_acc: 0.6062\n",
      "** epoch 469/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5226.0809 - acc: 0.5963 - val_loss: 0.6605 - val_acc: 0.6078\n",
      "** epoch 470/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5225.9616 - acc: 0.5954 - val_loss: 0.6603 - val_acc: 0.6109\n",
      "** epoch 471/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5229.5800 - acc: 0.5963 - val_loss: 0.6600 - val_acc: 0.6078\n",
      "** epoch 472/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5223.6574 - acc: 0.5961 - val_loss: 0.6601 - val_acc: 0.6078\n",
      "** epoch 473/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5211.0874 - acc: 0.5953 - val_loss: 0.6602 - val_acc: 0.6078\n",
      "** epoch 474/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5226.8167 - acc: 0.5964 - val_loss: 0.6603 - val_acc: 0.6078\n",
      "** epoch 475/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5216.7671 - acc: 0.5953 - val_loss: 0.6603 - val_acc: 0.6078\n",
      "** epoch 476/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5226.4852 - acc: 0.5969 - val_loss: 0.6605 - val_acc: 0.6078\n",
      "** epoch 477/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5222.0877 - acc: 0.5962 - val_loss: 0.6602 - val_acc: 0.6078\n",
      "** epoch 478/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 87s 6ms/step - loss: 5225.2862 - acc: 0.5924 - val_loss: 0.6600 - val_acc: 0.6094\n",
      "** epoch 479/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5222.3426 - acc: 0.5961 - val_loss: 0.6604 - val_acc: 0.6062\n",
      "** epoch 480/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5219.8390 - acc: 0.5982 - val_loss: 0.6597 - val_acc: 0.6109\n",
      "** epoch 481/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5219.6314 - acc: 0.5955 - val_loss: 0.6599 - val_acc: 0.6078\n",
      "** epoch 482/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5219.9921 - acc: 0.5971 - val_loss: 0.6602 - val_acc: 0.6078\n",
      "** epoch 483/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5212.4883 - acc: 0.5947 - val_loss: 0.6599 - val_acc: 0.6094\n",
      "** epoch 484/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5215.1338 - acc: 0.6000 - val_loss: 0.6601 - val_acc: 0.6078\n",
      "** epoch 485/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5217.3259 - acc: 0.5972 - val_loss: 0.6600 - val_acc: 0.6094\n",
      "** epoch 486/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5222.7492 - acc: 0.5945 - val_loss: 0.6605 - val_acc: 0.6062\n",
      "** epoch 487/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5218.7229 - acc: 0.5972 - val_loss: 0.6600 - val_acc: 0.6094\n",
      "** epoch 488/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5217.8363 - acc: 0.5984 - val_loss: 0.6601 - val_acc: 0.6078\n",
      "** epoch 489/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5209.6669 - acc: 0.5986 - val_loss: 0.6601 - val_acc: 0.6078\n",
      "** epoch 490/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5215.5734 - acc: 0.5973 - val_loss: 0.6605 - val_acc: 0.6062\n",
      "** epoch 491/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5210.9538 - acc: 0.5992 - val_loss: 0.6599 - val_acc: 0.6094\n",
      "** epoch 492/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5219.0588 - acc: 0.5980 - val_loss: 0.6597 - val_acc: 0.6078\n",
      "** epoch 493/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5224.5311 - acc: 0.6006 - val_loss: 0.6601 - val_acc: 0.6094\n",
      "** epoch 494/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5213.1103 - acc: 0.5977 - val_loss: 0.6594 - val_acc: 0.6078\n",
      "** epoch 495/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5207.5745 - acc: 0.6018 - val_loss: 0.6597 - val_acc: 0.6094\n",
      "** epoch 496/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5209.3125 - acc: 0.5982 - val_loss: 0.6594 - val_acc: 0.6109\n",
      "** epoch 497/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5203.3126 - acc: 0.6006 - val_loss: 0.6597 - val_acc: 0.6078\n",
      "** epoch 498/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5204.1800 - acc: 0.6004 - val_loss: 0.6590 - val_acc: 0.6109\n",
      "** epoch 499/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5214.4788 - acc: 0.5987 - val_loss: 0.6597 - val_acc: 0.6078\n",
      "** epoch 500/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5213.0383 - acc: 0.5973 - val_loss: 0.6590 - val_acc: 0.6109\n",
      "** epoch 501/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5214.0140 - acc: 0.5978 - val_loss: 0.6591 - val_acc: 0.6109\n",
      "** epoch 502/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5215.4792 - acc: 0.5978 - val_loss: 0.6598 - val_acc: 0.6047\n",
      "** epoch 503/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5202.0789 - acc: 0.6009 - val_loss: 0.6599 - val_acc: 0.6047\n",
      "** epoch 504/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5205.6701 - acc: 0.5992 - val_loss: 0.6597 - val_acc: 0.6062\n",
      "** epoch 505/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5206.3012 - acc: 0.5973 - val_loss: 0.6600 - val_acc: 0.6062\n",
      "** epoch 506/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5205.3096 - acc: 0.5984 - val_loss: 0.6597 - val_acc: 0.6031\n",
      "** epoch 507/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5209.8747 - acc: 0.5986 - val_loss: 0.6600 - val_acc: 0.6062\n",
      "** epoch 508/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5212.1609 - acc: 0.5994 - val_loss: 0.6599 - val_acc: 0.6062\n",
      "** epoch 509/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5211.1342 - acc: 0.5980 - val_loss: 0.6594 - val_acc: 0.6062\n",
      "** epoch 510/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5207.3489 - acc: 0.5967 - val_loss: 0.6593 - val_acc: 0.6078\n",
      "** epoch 511/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5210.0879 - acc: 0.5978 - val_loss: 0.6597 - val_acc: 0.6062\n",
      "** epoch 512/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5203.7382 - acc: 0.6002 - val_loss: 0.6593 - val_acc: 0.6062\n",
      "** epoch 513/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5197.8103 - acc: 0.5988 - val_loss: 0.6591 - val_acc: 0.6078\n",
      "** epoch 514/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5210.6906 - acc: 0.5979 - val_loss: 0.6596 - val_acc: 0.6078\n",
      "** epoch 515/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5196.1060 - acc: 0.5978 - val_loss: 0.6594 - val_acc: 0.6062\n",
      "** epoch 516/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5201.8989 - acc: 0.5992 - val_loss: 0.6593 - val_acc: 0.6062\n",
      "** epoch 517/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5209.5047 - acc: 0.5965 - val_loss: 0.6592 - val_acc: 0.6062\n",
      "** epoch 518/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5214.8636 - acc: 0.5991 - val_loss: 0.6594 - val_acc: 0.6062\n",
      "** epoch 519/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5204.4890 - acc: 0.5982 - val_loss: 0.6590 - val_acc: 0.6062\n",
      "** epoch 520/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5200.6720 - acc: 0.6000 - val_loss: 0.6581 - val_acc: 0.6125\n",
      "** epoch 521/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5199.9240 - acc: 0.6008 - val_loss: 0.6589 - val_acc: 0.6109\n",
      "** epoch 522/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5196.8744 - acc: 0.6002 - val_loss: 0.6590 - val_acc: 0.6078\n",
      "** epoch 523/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5196.2905 - acc: 0.6017 - val_loss: 0.6586 - val_acc: 0.6078\n",
      "** epoch 524/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5205.6381 - acc: 0.5992 - val_loss: 0.6598 - val_acc: 0.6047\n",
      "** epoch 525/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5193.7362 - acc: 0.6008 - val_loss: 0.6586 - val_acc: 0.6109\n",
      "** epoch 526/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5201.9377 - acc: 0.6001 - val_loss: 0.6590 - val_acc: 0.6062\n",
      "** epoch 527/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5203.2281 - acc: 0.5996 - val_loss: 0.6595 - val_acc: 0.6078\n",
      "** epoch 528/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5199.8314 - acc: 0.5943 - val_loss: 0.6591 - val_acc: 0.6062\n",
      "** epoch 529/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5196.8179 - acc: 0.5996 - val_loss: 0.6587 - val_acc: 0.6078\n",
      "** epoch 530/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5198.9891 - acc: 0.5991 - val_loss: 0.6588 - val_acc: 0.6078\n",
      "** epoch 531/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5209.8122 - acc: 0.5998 - val_loss: 0.6595 - val_acc: 0.6062\n",
      "** epoch 532/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5199.1979 - acc: 0.6016 - val_loss: 0.6590 - val_acc: 0.6047\n",
      "** epoch 533/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5193.6496 - acc: 0.6006 - val_loss: 0.6584 - val_acc: 0.6094\n",
      "** epoch 534/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5189.0449 - acc: 0.6002 - val_loss: 0.6585 - val_acc: 0.6062\n",
      "** epoch 535/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5191.9231 - acc: 0.6025 - val_loss: 0.6587 - val_acc: 0.6078\n",
      "** epoch 536/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5187.3671 - acc: 0.6025 - val_loss: 0.6591 - val_acc: 0.6047\n",
      "** epoch 537/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5201.6633 - acc: 0.5992 - val_loss: 0.6587 - val_acc: 0.6094\n",
      "** epoch 538/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5201.6483 - acc: 0.5994 - val_loss: 0.6585 - val_acc: 0.6094\n",
      "** epoch 539/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5184.4000 - acc: 0.6052 - val_loss: 0.6579 - val_acc: 0.6094\n",
      "** epoch 540/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5191.3820 - acc: 0.6002 - val_loss: 0.6587 - val_acc: 0.6078\n",
      "** epoch 541/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5181.2091 - acc: 0.6027 - val_loss: 0.6583 - val_acc: 0.6094\n",
      "** epoch 542/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5208.7977 - acc: 0.6016 - val_loss: 0.6583 - val_acc: 0.6062\n",
      "** epoch 543/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5191.0758 - acc: 0.6005 - val_loss: 0.6587 - val_acc: 0.6062\n",
      "** epoch 544/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5183.8985 - acc: 0.6025 - val_loss: 0.6580 - val_acc: 0.6109\n",
      "** epoch 545/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5190.0407 - acc: 0.6014 - val_loss: 0.6587 - val_acc: 0.6078\n",
      "** epoch 546/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5187.0686 - acc: 0.6035 - val_loss: 0.6584 - val_acc: 0.6078\n",
      "** epoch 547/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5185.6806 - acc: 0.6006 - val_loss: 0.6581 - val_acc: 0.6094\n",
      "** epoch 548/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5199.7103 - acc: 0.6018 - val_loss: 0.6583 - val_acc: 0.6078\n",
      "** epoch 549/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5192.5669 - acc: 0.5990 - val_loss: 0.6591 - val_acc: 0.6078\n",
      "** epoch 550/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5193.6339 - acc: 0.6013 - val_loss: 0.6582 - val_acc: 0.6078\n",
      "** epoch 551/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5189.3838 - acc: 0.6003 - val_loss: 0.6575 - val_acc: 0.6078\n",
      "** epoch 552/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5186.7064 - acc: 0.6025 - val_loss: 0.6582 - val_acc: 0.6062\n",
      "** epoch 553/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 81s 5ms/step - loss: 5181.1064 - acc: 0.6038 - val_loss: 0.6578 - val_acc: 0.6094\n",
      "** epoch 554/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5186.0662 - acc: 0.6024 - val_loss: 0.6580 - val_acc: 0.6094\n",
      "** epoch 555/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5186.6847 - acc: 0.6026 - val_loss: 0.6587 - val_acc: 0.6062\n",
      "** epoch 556/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5179.2058 - acc: 0.6017 - val_loss: 0.6578 - val_acc: 0.6078\n",
      "** epoch 557/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5185.1168 - acc: 0.5998 - val_loss: 0.6571 - val_acc: 0.6094\n",
      "** epoch 558/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5182.0966 - acc: 0.6017 - val_loss: 0.6583 - val_acc: 0.6047\n",
      "** epoch 559/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5173.3587 - acc: 0.6039 - val_loss: 0.6576 - val_acc: 0.6078\n",
      "** epoch 560/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5185.2826 - acc: 0.6002 - val_loss: 0.6580 - val_acc: 0.6062\n",
      "** epoch 561/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5179.8047 - acc: 0.6038 - val_loss: 0.6577 - val_acc: 0.6078\n",
      "** epoch 562/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5182.9143 - acc: 0.6022 - val_loss: 0.6573 - val_acc: 0.6094\n",
      "** epoch 563/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5183.3955 - acc: 0.6004 - val_loss: 0.6577 - val_acc: 0.6109\n",
      "** epoch 564/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5188.3399 - acc: 0.6000 - val_loss: 0.6571 - val_acc: 0.6109\n",
      "** epoch 565/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5182.6305 - acc: 0.6009 - val_loss: 0.6584 - val_acc: 0.6062\n",
      "** epoch 566/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5179.3185 - acc: 0.6026 - val_loss: 0.6577 - val_acc: 0.6094\n",
      "** epoch 567/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5179.0329 - acc: 0.6002 - val_loss: 0.6574 - val_acc: 0.6125\n",
      "** epoch 568/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5183.7340 - acc: 0.5996 - val_loss: 0.6570 - val_acc: 0.6109\n",
      "** epoch 569/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5183.2356 - acc: 0.6004 - val_loss: 0.6575 - val_acc: 0.6109\n",
      "** epoch 570/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5176.7021 - acc: 0.6028 - val_loss: 0.6579 - val_acc: 0.6078\n",
      "** epoch 571/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5175.0898 - acc: 0.6017 - val_loss: 0.6578 - val_acc: 0.6062\n",
      "** epoch 572/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5182.4934 - acc: 0.6011 - val_loss: 0.6576 - val_acc: 0.6078\n",
      "** epoch 573/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5179.0814 - acc: 0.6032 - val_loss: 0.6575 - val_acc: 0.6094\n",
      "** epoch 574/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5177.0852 - acc: 0.6017 - val_loss: 0.6567 - val_acc: 0.6094\n",
      "** epoch 575/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5174.5993 - acc: 0.6033 - val_loss: 0.6567 - val_acc: 0.6109\n",
      "** epoch 576/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5189.1586 - acc: 0.5988 - val_loss: 0.6565 - val_acc: 0.6125\n",
      "** epoch 577/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5163.6564 - acc: 0.6040 - val_loss: 0.6569 - val_acc: 0.6109\n",
      "** epoch 578/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5168.8265 - acc: 0.6014 - val_loss: 0.6565 - val_acc: 0.6109\n",
      "** epoch 579/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5170.5385 - acc: 0.6041 - val_loss: 0.6575 - val_acc: 0.6094\n",
      "** epoch 580/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5174.0229 - acc: 0.6041 - val_loss: 0.6568 - val_acc: 0.6094\n",
      "** epoch 581/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5179.0467 - acc: 0.6036 - val_loss: 0.6573 - val_acc: 0.6078\n",
      "** epoch 582/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5172.9422 - acc: 0.6032 - val_loss: 0.6575 - val_acc: 0.6062\n",
      "** epoch 583/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5169.2625 - acc: 0.6017 - val_loss: 0.6574 - val_acc: 0.6109\n",
      "** epoch 584/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5170.3613 - acc: 0.6019 - val_loss: 0.6570 - val_acc: 0.6109\n",
      "** epoch 585/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5174.4991 - acc: 0.6049 - val_loss: 0.6571 - val_acc: 0.6125\n",
      "** epoch 586/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5162.7751 - acc: 0.6064 - val_loss: 0.6571 - val_acc: 0.6094\n",
      "** epoch 587/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5186.0278 - acc: 0.6041 - val_loss: 0.6578 - val_acc: 0.6047\n",
      "** epoch 588/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5174.4339 - acc: 0.6054 - val_loss: 0.6573 - val_acc: 0.6078\n",
      "** epoch 589/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5168.0967 - acc: 0.6054 - val_loss: 0.6578 - val_acc: 0.6109\n",
      "** epoch 590/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5164.0942 - acc: 0.6033 - val_loss: 0.6567 - val_acc: 0.6094\n",
      "** epoch 591/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5165.8641 - acc: 0.6042 - val_loss: 0.6565 - val_acc: 0.6109\n",
      "** epoch 592/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5161.0674 - acc: 0.6025 - val_loss: 0.6570 - val_acc: 0.6094\n",
      "** epoch 593/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5164.5337 - acc: 0.6048 - val_loss: 0.6573 - val_acc: 0.6078\n",
      "** epoch 594/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5163.1849 - acc: 0.6052 - val_loss: 0.6569 - val_acc: 0.6094\n",
      "** epoch 595/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5168.4870 - acc: 0.6037 - val_loss: 0.6567 - val_acc: 0.6125\n",
      "** epoch 596/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5164.1316 - acc: 0.6050 - val_loss: 0.6570 - val_acc: 0.6109\n",
      "** epoch 597/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5173.0622 - acc: 0.6019 - val_loss: 0.6561 - val_acc: 0.6109\n",
      "** epoch 598/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5164.6495 - acc: 0.6055 - val_loss: 0.6567 - val_acc: 0.6078\n",
      "** epoch 599/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5156.8447 - acc: 0.6116 - val_loss: 0.6558 - val_acc: 0.6125\n",
      "** epoch 600/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5164.1804 - acc: 0.6046 - val_loss: 0.6552 - val_acc: 0.6109\n",
      "** epoch 601/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5146.3578 - acc: 0.6069 - val_loss: 0.6564 - val_acc: 0.6109\n",
      "** epoch 602/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5162.7572 - acc: 0.6045 - val_loss: 0.6559 - val_acc: 0.6141\n",
      "** epoch 603/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5165.9438 - acc: 0.6023 - val_loss: 0.6571 - val_acc: 0.6094\n",
      "** epoch 604/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5153.3118 - acc: 0.6046 - val_loss: 0.6552 - val_acc: 0.6141\n",
      "** epoch 605/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5156.7074 - acc: 0.6068 - val_loss: 0.6556 - val_acc: 0.6141\n",
      "** epoch 606/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5168.4929 - acc: 0.6055 - val_loss: 0.6561 - val_acc: 0.6141\n",
      "** epoch 607/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5156.0492 - acc: 0.6048 - val_loss: 0.6558 - val_acc: 0.6125\n",
      "** epoch 608/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5161.4703 - acc: 0.6031 - val_loss: 0.6552 - val_acc: 0.6125\n",
      "** epoch 609/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5162.3113 - acc: 0.6014 - val_loss: 0.6549 - val_acc: 0.6125\n",
      "** epoch 610/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5165.9672 - acc: 0.6039 - val_loss: 0.6558 - val_acc: 0.6109\n",
      "** epoch 611/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5158.8255 - acc: 0.6029 - val_loss: 0.6561 - val_acc: 0.6141\n",
      "** epoch 612/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5162.1157 - acc: 0.6065 - val_loss: 0.6555 - val_acc: 0.6141\n",
      "** epoch 613/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5161.0185 - acc: 0.6056 - val_loss: 0.6557 - val_acc: 0.6078\n",
      "** epoch 614/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5162.5695 - acc: 0.6036 - val_loss: 0.6554 - val_acc: 0.6109\n",
      "** epoch 615/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5163.0309 - acc: 0.6075 - val_loss: 0.6551 - val_acc: 0.6109\n",
      "** epoch 616/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5166.6798 - acc: 0.6034 - val_loss: 0.6556 - val_acc: 0.6078\n",
      "** epoch 617/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5141.0608 - acc: 0.6062 - val_loss: 0.6545 - val_acc: 0.6141\n",
      "** epoch 618/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5155.9710 - acc: 0.6090 - val_loss: 0.6552 - val_acc: 0.6109\n",
      "** epoch 619/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5154.4865 - acc: 0.6036 - val_loss: 0.6552 - val_acc: 0.6094\n",
      "** epoch 620/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5163.1323 - acc: 0.6048 - val_loss: 0.6550 - val_acc: 0.6109\n",
      "** epoch 621/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5144.9860 - acc: 0.6048 - val_loss: 0.6557 - val_acc: 0.6094\n",
      "** epoch 622/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5149.4246 - acc: 0.6063 - val_loss: 0.6559 - val_acc: 0.6109\n",
      "** epoch 623/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5159.7878 - acc: 0.6056 - val_loss: 0.6548 - val_acc: 0.6094\n",
      "** epoch 624/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5158.3508 - acc: 0.6050 - val_loss: 0.6551 - val_acc: 0.6141\n",
      "** epoch 625/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5150.6377 - acc: 0.6064 - val_loss: 0.6544 - val_acc: 0.6141\n",
      "** epoch 626/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5139.1726 - acc: 0.6075 - val_loss: 0.6544 - val_acc: 0.6156\n",
      "** epoch 627/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5149.1766 - acc: 0.6061 - val_loss: 0.6554 - val_acc: 0.6125\n",
      "** epoch 628/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5148.0067 - acc: 0.6080 - val_loss: 0.6555 - val_acc: 0.6125\n",
      "** epoch 629/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5147.9410 - acc: 0.6066 - val_loss: 0.6552 - val_acc: 0.6125\n",
      "** epoch 630/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5150.2555 - acc: 0.6058 - val_loss: 0.6553 - val_acc: 0.6109\n",
      "** epoch 631/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5152.7409 - acc: 0.6052 - val_loss: 0.6553 - val_acc: 0.6125\n",
      "** epoch 632/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5151.5290 - acc: 0.6016 - val_loss: 0.6551 - val_acc: 0.6078\n",
      "** epoch 633/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5162.0155 - acc: 0.6057 - val_loss: 0.6552 - val_acc: 0.6109\n",
      "** epoch 634/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5148.3951 - acc: 0.6052 - val_loss: 0.6552 - val_acc: 0.6094\n",
      "** epoch 635/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5154.1306 - acc: 0.6076 - val_loss: 0.6559 - val_acc: 0.6094: 0.60\n",
      "** epoch 636/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5141.0749 - acc: 0.6074 - val_loss: 0.6548 - val_acc: 0.6062\n",
      "** epoch 637/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5147.4439 - acc: 0.6041 - val_loss: 0.6542 - val_acc: 0.6125\n",
      "** epoch 638/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 5152.1425 - acc: 0.6039 - val_loss: 0.6558 - val_acc: 0.6094\n",
      "** epoch 639/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5145.6883 - acc: 0.6056 - val_loss: 0.6547 - val_acc: 0.6109\n",
      "** epoch 640/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5149.4665 - acc: 0.6062 - val_loss: 0.6542 - val_acc: 0.6156\n",
      "** epoch 641/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5149.0057 - acc: 0.6085 - val_loss: 0.6542 - val_acc: 0.6109\n",
      "** epoch 642/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5139.5400 - acc: 0.6087 - val_loss: 0.6549 - val_acc: 0.6094\n",
      "** epoch 643/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5154.1348 - acc: 0.6056 - val_loss: 0.6549 - val_acc: 0.6078\n",
      "** epoch 644/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5138.9842 - acc: 0.6061 - val_loss: 0.6541 - val_acc: 0.6078\n",
      "** epoch 645/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5150.5760 - acc: 0.6080 - val_loss: 0.6566 - val_acc: 0.6078\n",
      "** epoch 646/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5145.3590 - acc: 0.6029 - val_loss: 0.6546 - val_acc: 0.6109\n",
      "** epoch 647/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5149.9416 - acc: 0.6062 - val_loss: 0.6541 - val_acc: 0.6141\n",
      "** epoch 648/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5143.2592 - acc: 0.6091 - val_loss: 0.6544 - val_acc: 0.6125\n",
      "** epoch 649/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5134.0259 - acc: 0.6068 - val_loss: 0.6525 - val_acc: 0.6203\n",
      "** epoch 650/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5145.9306 - acc: 0.6076 - val_loss: 0.6535 - val_acc: 0.6125\n",
      "** epoch 651/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5144.8155 - acc: 0.6038 - val_loss: 0.6544 - val_acc: 0.6125\n",
      "** epoch 652/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5132.2603 - acc: 0.6115 - val_loss: 0.6536 - val_acc: 0.6125\n",
      "** epoch 653/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5147.6080 - acc: 0.6078 - val_loss: 0.6549 - val_acc: 0.6094\n",
      "** epoch 654/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5143.6643 - acc: 0.6068 - val_loss: 0.6538 - val_acc: 0.6109\n",
      "** epoch 655/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5143.1365 - acc: 0.6050 - val_loss: 0.6536 - val_acc: 0.6141\n",
      "** epoch 656/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5137.4113 - acc: 0.6093 - val_loss: 0.6537 - val_acc: 0.6156\n",
      "** epoch 657/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5145.3000 - acc: 0.6066 - val_loss: 0.6543 - val_acc: 0.6109\n",
      "** epoch 658/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5143.9846 - acc: 0.6047 - val_loss: 0.6542 - val_acc: 0.6141\n",
      "** epoch 659/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5143.2087 - acc: 0.6064 - val_loss: 0.6532 - val_acc: 0.6141\n",
      "** epoch 660/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5143.6020 - acc: 0.6113 - val_loss: 0.6538 - val_acc: 0.6156\n",
      "** epoch 661/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5143.7736 - acc: 0.6095 - val_loss: 0.6545 - val_acc: 0.6125\n",
      "** epoch 662/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5143.1959 - acc: 0.6048 - val_loss: 0.6536 - val_acc: 0.6172\n",
      "** epoch 663/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5145.2568 - acc: 0.6040 - val_loss: 0.6539 - val_acc: 0.6156\n",
      "** epoch 664/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5133.9156 - acc: 0.6097 - val_loss: 0.6533 - val_acc: 0.6188\n",
      "** epoch 665/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5126.4831 - acc: 0.6100 - val_loss: 0.6533 - val_acc: 0.6172\n",
      "** epoch 666/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5133.0253 - acc: 0.6091 - val_loss: 0.6534 - val_acc: 0.6156\n",
      "** epoch 667/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5135.8486 - acc: 0.6080 - val_loss: 0.6521 - val_acc: 0.6172\n",
      "** epoch 668/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5129.6580 - acc: 0.6087 - val_loss: 0.6535 - val_acc: 0.6172\n",
      "** epoch 669/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5130.0227 - acc: 0.6101 - val_loss: 0.6532 - val_acc: 0.6188\n",
      "** epoch 670/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5129.5457 - acc: 0.6074 - val_loss: 0.6537 - val_acc: 0.6141\n",
      "** epoch 671/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5121.0713 - acc: 0.6072 - val_loss: 0.6529 - val_acc: 0.6156\n",
      "** epoch 672/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5123.4800 - acc: 0.6074 - val_loss: 0.6527 - val_acc: 0.6141\n",
      "** epoch 673/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5117.4283 - acc: 0.6101 - val_loss: 0.6533 - val_acc: 0.6156\n",
      "** epoch 674/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5137.4195 - acc: 0.6093 - val_loss: 0.6528 - val_acc: 0.6109\n",
      "** epoch 675/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5132.6108 - acc: 0.6103 - val_loss: 0.6534 - val_acc: 0.6141\n",
      "** epoch 676/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5141.4978 - acc: 0.6076 - val_loss: 0.6528 - val_acc: 0.6156\n",
      "** epoch 677/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5126.3810 - acc: 0.6107 - val_loss: 0.6524 - val_acc: 0.6141\n",
      "** epoch 678/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5138.3794 - acc: 0.6076 - val_loss: 0.6528 - val_acc: 0.6141\n",
      "** epoch 679/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5126.0785 - acc: 0.6084 - val_loss: 0.6525 - val_acc: 0.6125\n",
      "** epoch 680/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5130.6282 - acc: 0.6074 - val_loss: 0.6528 - val_acc: 0.6094\n",
      "** epoch 681/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5134.1741 - acc: 0.6060 - val_loss: 0.6535 - val_acc: 0.6109\n",
      "** epoch 682/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5120.0945 - acc: 0.6076 - val_loss: 0.6536 - val_acc: 0.6109\n",
      "** epoch 683/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5122.0392 - acc: 0.6119 - val_loss: 0.6533 - val_acc: 0.6156\n",
      "** epoch 684/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5131.1240 - acc: 0.6059 - val_loss: 0.6538 - val_acc: 0.6125\n",
      "** epoch 685/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5140.3734 - acc: 0.6061 - val_loss: 0.6539 - val_acc: 0.6141\n",
      "** epoch 686/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5120.7778 - acc: 0.6121 - val_loss: 0.6531 - val_acc: 0.6141\n",
      "** epoch 687/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5124.1044 - acc: 0.6071 - val_loss: 0.6524 - val_acc: 0.6141\n",
      "** epoch 688/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5116.9029 - acc: 0.6079 - val_loss: 0.6531 - val_acc: 0.6141\n",
      "** epoch 689/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5126.7948 - acc: 0.6098 - val_loss: 0.6534 - val_acc: 0.6109\n",
      "** epoch 690/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5108.9649 - acc: 0.6130 - val_loss: 0.6537 - val_acc: 0.6125\n",
      "** epoch 691/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5124.3468 - acc: 0.6088 - val_loss: 0.6538 - val_acc: 0.6141\n",
      "** epoch 692/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5128.9829 - acc: 0.6104 - val_loss: 0.6525 - val_acc: 0.6125\n",
      "** epoch 693/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5117.7938 - acc: 0.6096 - val_loss: 0.6528 - val_acc: 0.6141\n",
      "** epoch 694/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5112.6701 - acc: 0.6108 - val_loss: 0.6533 - val_acc: 0.6156\n",
      "** epoch 695/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5125.0376 - acc: 0.6098 - val_loss: 0.6538 - val_acc: 0.6141\n",
      "** epoch 696/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5132.2590 - acc: 0.6096 - val_loss: 0.6524 - val_acc: 0.6094\n",
      "** epoch 697/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5131.4537 - acc: 0.6091 - val_loss: 0.6536 - val_acc: 0.6156\n",
      "** epoch 698/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5115.3528 - acc: 0.6121 - val_loss: 0.6531 - val_acc: 0.6156\n",
      "** epoch 699/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5118.5411 - acc: 0.6089 - val_loss: 0.6527 - val_acc: 0.6141\n",
      "** epoch 700/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5130.6423 - acc: 0.6103 - val_loss: 0.6534 - val_acc: 0.6125\n",
      "** epoch 701/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5127.5853 - acc: 0.6067 - val_loss: 0.6537 - val_acc: 0.6094\n",
      "** epoch 702/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5120.0095 - acc: 0.6115 - val_loss: 0.6532 - val_acc: 0.6172\n",
      "** epoch 703/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5096.7501 - acc: 0.6128 - val_loss: 0.6528 - val_acc: 0.6109\n",
      "** epoch 704/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5131.7356 - acc: 0.6040 - val_loss: 0.6538 - val_acc: 0.6094\n",
      "** epoch 705/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5112.6019 - acc: 0.6074 - val_loss: 0.6530 - val_acc: 0.6141\n",
      "** epoch 706/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5126.4009 - acc: 0.6087 - val_loss: 0.6530 - val_acc: 0.6188\n",
      "** epoch 707/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5127.0818 - acc: 0.6070 - val_loss: 0.6521 - val_acc: 0.6172\n",
      "** epoch 708/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5128.3583 - acc: 0.6082 - val_loss: 0.6525 - val_acc: 0.6062\n",
      "** epoch 709/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5101.7627 - acc: 0.6082 - val_loss: 0.6522 - val_acc: 0.6094\n",
      "** epoch 710/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5118.6081 - acc: 0.6091 - val_loss: 0.6520 - val_acc: 0.6094\n",
      "** epoch 711/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5112.5771 - acc: 0.6137 - val_loss: 0.6531 - val_acc: 0.6141\n",
      "** epoch 712/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5116.5681 - acc: 0.6106 - val_loss: 0.6521 - val_acc: 0.6125\n",
      "** epoch 713/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5095.7042 - acc: 0.6103 - val_loss: 0.6516 - val_acc: 0.610941 - a\n",
      "** epoch 714/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 76s 5ms/step - loss: 5125.2760 - acc: 0.6093 - val_loss: 0.6525 - val_acc: 0.6125\n",
      "** epoch 715/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 75s 5ms/step - loss: 5093.1103 - acc: 0.6103 - val_loss: 0.6520 - val_acc: 0.6156\n",
      "** epoch 716/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 79s 5ms/step - loss: 5109.5040 - acc: 0.6117 - val_loss: 0.6527 - val_acc: 0.6188\n",
      "** epoch 717/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5111.0186 - acc: 0.6110 - val_loss: 0.6523 - val_acc: 0.6078\n",
      "** epoch 718/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5107.5604 - acc: 0.6107 - val_loss: 0.6529 - val_acc: 0.6156\n",
      "** epoch 719/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5115.2306 - acc: 0.6146 - val_loss: 0.6520 - val_acc: 0.6141\n",
      "** epoch 720/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5123.8204 - acc: 0.6099 - val_loss: 0.6528 - val_acc: 0.6156\n",
      "** epoch 721/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5110.7054 - acc: 0.6110 - val_loss: 0.6524 - val_acc: 0.6062\n",
      "** epoch 722/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5109.2315 - acc: 0.6130 - val_loss: 0.6529 - val_acc: 0.6109\n",
      "** epoch 723/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 5124.6708 - acc: 0.6078 - val_loss: 0.6528 - val_acc: 0.6172\n",
      "** epoch 724/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 77s 5ms/step - loss: 5105.4518 - acc: 0.6125 - val_loss: 0.6513 - val_acc: 0.6172\n",
      "** epoch 725/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 75s 5ms/step - loss: 5095.3739 - acc: 0.6144 - val_loss: 0.6545 - val_acc: 0.6078\n",
      "** epoch 726/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 76s 5ms/step - loss: 5108.7524 - acc: 0.6118 - val_loss: 0.6511 - val_acc: 0.6156\n",
      "** epoch 727/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5109.9136 - acc: 0.6106 - val_loss: 0.6530 - val_acc: 0.6203\n",
      "** epoch 728/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5108.2490 - acc: 0.6113 - val_loss: 0.6525 - val_acc: 0.6125\n",
      "** epoch 729/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5112.3984 - acc: 0.6133 - val_loss: 0.6533 - val_acc: 0.6141\n",
      "** epoch 730/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5107.6103 - acc: 0.6128 - val_loss: 0.6518 - val_acc: 0.6156\n",
      "** epoch 731/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5113.6660 - acc: 0.6081 - val_loss: 0.6539 - val_acc: 0.6094\n",
      "** epoch 732/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5115.5267 - acc: 0.6095 - val_loss: 0.6532 - val_acc: 0.6109\n",
      "** epoch 733/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5086.6064 - acc: 0.6161 - val_loss: 0.6521 - val_acc: 0.6094\n",
      "** epoch 734/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5110.5917 - acc: 0.6087 - val_loss: 0.6518 - val_acc: 0.6172\n",
      "** epoch 735/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 81s 5ms/step - loss: 5107.3000 - acc: 0.6126 - val_loss: 0.6531 - val_acc: 0.6094\n",
      "** epoch 736/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 75s 5ms/step - loss: 5116.7455 - acc: 0.6122 - val_loss: 0.6540 - val_acc: 0.6109\n",
      "** epoch 737/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 75s 5ms/step - loss: 5082.6297 - acc: 0.6152 - val_loss: 0.6523 - val_acc: 0.6141\n",
      "** epoch 738/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 5102.2376 - acc: 0.6114 - val_loss: 0.6528 - val_acc: 0.6109\n",
      "** epoch 739/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5105.5506 - acc: 0.6126 - val_loss: 0.6520 - val_acc: 0.6156\n",
      "** epoch 740/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5101.2290 - acc: 0.6094 - val_loss: 0.6520 - val_acc: 0.6094\n",
      "** epoch 741/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5112.3145 - acc: 0.6116 - val_loss: 0.6521 - val_acc: 0.6141\n",
      "** epoch 742/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5103.8556 - acc: 0.6104 - val_loss: 0.6531 - val_acc: 0.6109\n",
      "** epoch 743/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 75s 5ms/step - loss: 5095.7201 - acc: 0.6131 - val_loss: 0.6514 - val_acc: 0.6094\n",
      "** epoch 744/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 75s 5ms/step - loss: 5097.9920 - acc: 0.6144 - val_loss: 0.6532 - val_acc: 0.6094\n",
      "** epoch 745/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 80s 5ms/step - loss: 5112.4809 - acc: 0.6094 - val_loss: 0.6523 - val_acc: 0.6203\n",
      "** epoch 746/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5097.5177 - acc: 0.6128 - val_loss: 0.6521 - val_acc: 0.6125\n",
      "** epoch 747/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5104.5114 - acc: 0.6118 - val_loss: 0.6524 - val_acc: 0.6141\n",
      "** epoch 748/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5094.6042 - acc: 0.6140 - val_loss: 0.6534 - val_acc: 0.6109\n",
      "** epoch 749/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5093.6287 - acc: 0.6150 - val_loss: 0.6523 - val_acc: 0.6172\n",
      "** epoch 750/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5103.8678 - acc: 0.6120 - val_loss: 0.6530 - val_acc: 0.6109\n",
      "** epoch 751/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5096.7388 - acc: 0.6130 - val_loss: 0.6519 - val_acc: 0.6203\n",
      "** epoch 752/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5086.7795 - acc: 0.6135 - val_loss: 0.6510 - val_acc: 0.6094\n",
      "** epoch 753/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5104.7153 - acc: 0.6115 - val_loss: 0.6520 - val_acc: 0.6125\n",
      "** epoch 754/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5116.2150 - acc: 0.6097 - val_loss: 0.6541 - val_acc: 0.6156\n",
      "** epoch 755/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5086.0466 - acc: 0.6119 - val_loss: 0.6516 - val_acc: 0.6109\n",
      "** epoch 756/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5084.9627 - acc: 0.6153 - val_loss: 0.6521 - val_acc: 0.6141\n",
      "** epoch 757/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5099.0876 - acc: 0.6142 - val_loss: 0.6507 - val_acc: 0.6125\n",
      "** epoch 758/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5096.5974 - acc: 0.6143 - val_loss: 0.6508 - val_acc: 0.6141\n",
      "** epoch 759/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5081.1189 - acc: 0.6163 - val_loss: 0.6516 - val_acc: 0.6141\n",
      "** epoch 760/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5102.9720 - acc: 0.6103 - val_loss: 0.6526 - val_acc: 0.6125\n",
      "** epoch 761/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5085.1198 - acc: 0.6144 - val_loss: 0.6523 - val_acc: 0.6156\n",
      "** epoch 762/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5108.5871 - acc: 0.6103 - val_loss: 0.6515 - val_acc: 0.6156\n",
      "** epoch 763/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5096.1077 - acc: 0.6128 - val_loss: 0.6522 - val_acc: 0.6094\n",
      "** epoch 764/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5085.5172 - acc: 0.6148 - val_loss: 0.6524 - val_acc: 0.6109\n",
      "** epoch 765/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5096.1257 - acc: 0.6145 - val_loss: 0.6516 - val_acc: 0.6156\n",
      "** epoch 766/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5087.8724 - acc: 0.6128 - val_loss: 0.6519 - val_acc: 0.6109\n",
      "** epoch 767/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5099.1053 - acc: 0.6119 - val_loss: 0.6536 - val_acc: 0.6125\n",
      "** epoch 768/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5071.6122 - acc: 0.6148 - val_loss: 0.6535 - val_acc: 0.6109\n",
      "** epoch 769/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5083.0129 - acc: 0.6118 - val_loss: 0.6524 - val_acc: 0.6062\n",
      "** epoch 770/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5094.9312 - acc: 0.6122 - val_loss: 0.6527 - val_acc: 0.6078\n",
      "** epoch 771/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5083.3460 - acc: 0.6138 - val_loss: 0.6533 - val_acc: 0.6109\n",
      "** epoch 772/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5083.3043 - acc: 0.6151 - val_loss: 0.6522 - val_acc: 0.6125\n",
      "** epoch 773/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5089.2892 - acc: 0.6114 - val_loss: 0.6510 - val_acc: 0.6125\n",
      "** epoch 774/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5087.1984 - acc: 0.6102 - val_loss: 0.6504 - val_acc: 0.6141\n",
      "** epoch 775/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5097.6419 - acc: 0.6127 - val_loss: 0.6513 - val_acc: 0.6141\n",
      "** epoch 776/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5084.2701 - acc: 0.6152 - val_loss: 0.6510 - val_acc: 0.6188\n",
      "** epoch 777/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5091.9915 - acc: 0.6115 - val_loss: 0.6513 - val_acc: 0.6125\n",
      "** epoch 778/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5098.4960 - acc: 0.6081 - val_loss: 0.6518 - val_acc: 0.6109\n",
      "** epoch 779/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5080.0977 - acc: 0.6141 - val_loss: 0.6522 - val_acc: 0.6094\n",
      "** epoch 780/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5080.6422 - acc: 0.6157 - val_loss: 0.6513 - val_acc: 0.6156\n",
      "** epoch 781/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5072.4845 - acc: 0.6148 - val_loss: 0.6498 - val_acc: 0.6156\n",
      "** epoch 782/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5072.8242 - acc: 0.6168 - val_loss: 0.6516 - val_acc: 0.6078\n",
      "** epoch 783/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5090.7016 - acc: 0.6084 - val_loss: 0.6506 - val_acc: 0.6172\n",
      "** epoch 784/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5084.0549 - acc: 0.6146 - val_loss: 0.6518 - val_acc: 0.6109\n",
      "** epoch 785/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5095.9481 - acc: 0.6122 - val_loss: 0.6511 - val_acc: 0.6109\n",
      "** epoch 786/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5083.8550 - acc: 0.6138 - val_loss: 0.6501 - val_acc: 0.6156\n",
      "** epoch 787/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5099.1904 - acc: 0.6130 - val_loss: 0.6511 - val_acc: 0.6156\n",
      "** epoch 788/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5071.9731 - acc: 0.6147 - val_loss: 0.6515 - val_acc: 0.6109\n",
      "** epoch 789/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5102.6420 - acc: 0.6092 - val_loss: 0.6517 - val_acc: 0.6109\n",
      "** epoch 790/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5076.0136 - acc: 0.6152 - val_loss: 0.6508 - val_acc: 0.6156\n",
      "** epoch 791/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5083.7779 - acc: 0.6132 - val_loss: 0.6502 - val_acc: 0.6125\n",
      "** epoch 792/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5080.8012 - acc: 0.6124 - val_loss: 0.6509 - val_acc: 0.6156\n",
      "** epoch 793/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5076.4060 - acc: 0.6151 - val_loss: 0.6504 - val_acc: 0.6156\n",
      "** epoch 794/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5074.5654 - acc: 0.6163 - val_loss: 0.6508 - val_acc: 0.6141\n",
      "** epoch 795/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5074.6476 - acc: 0.6132 - val_loss: 0.6512 - val_acc: 0.6109\n",
      "** epoch 796/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5087.7161 - acc: 0.6123 - val_loss: 0.6521 - val_acc: 0.6078\n",
      "** epoch 797/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5082.0055 - acc: 0.6152 - val_loss: 0.6523 - val_acc: 0.6094\n",
      "** epoch 798/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5086.3499 - acc: 0.6148 - val_loss: 0.6505 - val_acc: 0.6109\n",
      "** epoch 799/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5073.4769 - acc: 0.6166 - val_loss: 0.6517 - val_acc: 0.6156\n",
      "** epoch 800/800 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5075.8274 - acc: 0.6154 - val_loss: 0.6504 - val_acc: 0.6156\n"
     ]
    }
   ],
   "source": [
    "# Compiling Optimizer\n",
    "rmsprop = RMSprop(lr=lr, rho=0.9, epsilon=None, decay=0.0)\n",
    "lstm.compile(loss='binary_crossentropy', optimizer=rmsprop, \n",
    "             metrics=['accuracy'\n",
    "                      #AUC(name='AUC', multi_label=False, label_weights=class_weights))\n",
    "                     ])\n",
    "\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=10, min_lr=1e-9)]\n",
    "\n",
    "# Loss arrays\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "counter = 1\n",
    "\n",
    "for n in range(n_epochs):\n",
    "    print('** epoch {}/{} **'.format(counter, n_epochs))\n",
    "\n",
    "    history = lstm.fit(x=X_train, y=y_train, epochs=1, validation_data=(X_test, y_test),\n",
    "                       batch_size=batch_size, shuffle=False, callbacks=callbacks,\n",
    "                      class_weight=class_weights,\n",
    "                      use_multiprocessing=True)\n",
    "\n",
    "    # Append the list to follow the evolution of loss on train and test sets\n",
    "    train_loss_list.append(history.history['loss'][0])\n",
    "    train_acc_list.append(history.history['acc'][0])\n",
    "\n",
    "    test_loss_list.append(history.history['val_loss'][0])\n",
    "    test_acc_list.append(history.history['val_acc'][0])\n",
    "\n",
    "\n",
    "    # Reset the cell states (required for stateful)\n",
    "    lstm.reset_states()\n",
    "\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "fljPqNVX_IPA",
    "outputId": "12f63d7e-a607-4227-9d61-c941f8e4f764"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the errors\n",
    "fig, ax = plt.subplots(nrows=4)\n",
    "_ = ax[0].plot(range(1, counter), train_loss_list)\n",
    "_ = ax[0].set_title('Binary Crossentropy Loss on train set')\n",
    "\n",
    "_ = ax[1].plot(range(1, counter), train_acc_list) \n",
    "_ = ax[1].set_title('Accuracy Loss on train set')\n",
    "\n",
    "_ = ax[2].plot(range(1, counter), test_loss_list)\n",
    "_ = ax[2].set_title('Binary Crossentropy Loss on test set')\n",
    "\n",
    "_ = ax[3].plot(range(1, counter), test_acc_list)\n",
    "_ = ax[3].set_title('Accuracy Loss on test set')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SMzjsoHIqo-f"
   },
   "outputs": [],
   "source": [
    "path = \"Trained/BTC_LSTM_{}ep.h5\".format(n_epochs) \n",
    "lstm.save(path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XLS-ttUK_IPC",
    "outputId": "9bd5c79d-d566-4276-ed1e-e598a1f38a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 801/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5088.0004 - acc: 0.6124 - val_loss: 0.6516 - val_acc: 0.6094\n",
      "epoch 802/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5082.1247 - acc: 0.6109 - val_loss: 0.6510 - val_acc: 0.6156\n",
      "epoch 803/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5073.4873 - acc: 0.6171 - val_loss: 0.6518 - val_acc: 0.6094\n",
      "epoch 804/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5073.3905 - acc: 0.6154 - val_loss: 0.6507 - val_acc: 0.6188\n",
      "epoch 805/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5075.6087 - acc: 0.6161 - val_loss: 0.6512 - val_acc: 0.6141\n",
      "epoch 806/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5066.1656 - acc: 0.6175 - val_loss: 0.6502 - val_acc: 0.6156\n",
      "epoch 807/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5085.3198 - acc: 0.6120 - val_loss: 0.6511 - val_acc: 0.6141\n",
      "epoch 808/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5075.0774 - acc: 0.6142 - val_loss: 0.6507 - val_acc: 0.6141\n",
      "epoch 809/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5066.8199 - acc: 0.6175 - val_loss: 0.6506 - val_acc: 0.6156\n",
      "epoch 810/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5058.0988 - acc: 0.6148 - val_loss: 0.6511 - val_acc: 0.6141\n",
      "epoch 811/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5083.9757 - acc: 0.6157 - val_loss: 0.6509 - val_acc: 0.6125\n",
      "epoch 812/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5093.6921 - acc: 0.6070 - val_loss: 0.6512 - val_acc: 0.6125\n",
      "epoch 813/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5076.4977 - acc: 0.6138 - val_loss: 0.6509 - val_acc: 0.6141\n",
      "epoch 814/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5061.4992 - acc: 0.6169 - val_loss: 0.6506 - val_acc: 0.6188\n",
      "epoch 815/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5075.3892 - acc: 0.6149 - val_loss: 0.6524 - val_acc: 0.6109\n",
      "epoch 816/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5080.3487 - acc: 0.6124 - val_loss: 0.6524 - val_acc: 0.6141\n",
      "epoch 817/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5072.7951 - acc: 0.6143 - val_loss: 0.6510 - val_acc: 0.6172\n",
      "epoch 818/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5063.8984 - acc: 0.6156 - val_loss: 0.6511 - val_acc: 0.6156\n",
      "epoch 819/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5075.6913 - acc: 0.6137 - val_loss: 0.6510 - val_acc: 0.6125\n",
      "epoch 820/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5066.7611 - acc: 0.6161 - val_loss: 0.6524 - val_acc: 0.6125\n",
      "epoch 821/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5078.3278 - acc: 0.6119 - val_loss: 0.6526 - val_acc: 0.6156\n",
      "epoch 822/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5080.0335 - acc: 0.6167 - val_loss: 0.6519 - val_acc: 0.6188\n",
      "epoch 823/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5047.9169 - acc: 0.6146 - val_loss: 0.6507 - val_acc: 0.6141\n",
      "epoch 824/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5069.7914 - acc: 0.6142 - val_loss: 0.6504 - val_acc: 0.6172\n",
      "epoch 825/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5065.6920 - acc: 0.6156 - val_loss: 0.6502 - val_acc: 0.6203\n",
      "epoch 826/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5058.4703 - acc: 0.6158 - val_loss: 0.6512 - val_acc: 0.6156\n",
      "epoch 827/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5065.4784 - acc: 0.6161 - val_loss: 0.6503 - val_acc: 0.6172\n",
      "epoch 828/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5066.1497 - acc: 0.6200 - val_loss: 0.6506 - val_acc: 0.6141\n",
      "epoch 829/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5066.3654 - acc: 0.6184 - val_loss: 0.6520 - val_acc: 0.6156\n",
      "epoch 830/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5052.0876 - acc: 0.6146 - val_loss: 0.6514 - val_acc: 0.6172\n",
      "epoch 831/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5080.0659 - acc: 0.6148 - val_loss: 0.6505 - val_acc: 0.6141\n",
      "epoch 832/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5070.1552 - acc: 0.6122 - val_loss: 0.6524 - val_acc: 0.6156\n",
      "epoch 833/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5056.2427 - acc: 0.6176 - val_loss: 0.6512 - val_acc: 0.6109\n",
      "epoch 834/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5066.6511 - acc: 0.6158 - val_loss: 0.6515 - val_acc: 0.6109\n",
      "epoch 835/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5044.0825 - acc: 0.6121 - val_loss: 0.6515 - val_acc: 0.6156\n",
      "epoch 836/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5052.4500 - acc: 0.6174 - val_loss: 0.6508 - val_acc: 0.6172\n",
      "epoch 837/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5066.0961 - acc: 0.6132 - val_loss: 0.6518 - val_acc: 0.6094\n",
      "epoch 838/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5052.3270 - acc: 0.6178 - val_loss: 0.6514 - val_acc: 0.6141\n",
      "epoch 839/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5075.6126 - acc: 0.6136 - val_loss: 0.6520 - val_acc: 0.6047\n",
      "epoch 840/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5067.1696 - acc: 0.6146 - val_loss: 0.6515 - val_acc: 0.6094\n",
      "epoch 841/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5067.2221 - acc: 0.6154 - val_loss: 0.6512 - val_acc: 0.6125\n",
      "epoch 842/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5066.1739 - acc: 0.6173 - val_loss: 0.6521 - val_acc: 0.6109\n",
      "epoch 843/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5073.6219 - acc: 0.6128 - val_loss: 0.6523 - val_acc: 0.6109\n",
      "epoch 844/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5066.9596 - acc: 0.6130 - val_loss: 0.6522 - val_acc: 0.6094\n",
      "epoch 845/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5054.8917 - acc: 0.6201 - val_loss: 0.6506 - val_acc: 0.6141\n",
      "epoch 846/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5080.5863 - acc: 0.6125 - val_loss: 0.6521 - val_acc: 0.6094\n",
      "epoch 847/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5065.4861 - acc: 0.6175 - val_loss: 0.6507 - val_acc: 0.6141\n",
      "epoch 848/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5066.7524 - acc: 0.6141 - val_loss: 0.6510 - val_acc: 0.6156A: 12s - loss: 5 - ETA: 9s - loss: 507\n",
      "epoch 849/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5061.1418 - acc: 0.6136 - val_loss: 0.6511 - val_acc: 0.6141\n",
      "epoch 850/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5055.6089 - acc: 0.6191 - val_loss: 0.6503 - val_acc: 0.6109\n",
      "epoch 851/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5064.1296 - acc: 0.6128 - val_loss: 0.6517 - val_acc: 0.6109\n",
      "epoch 852/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5060.0414 - acc: 0.6171 - val_loss: 0.6514 - val_acc: 0.6125\n",
      "epoch 853/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5065.7254 - acc: 0.6167 - val_loss: 0.6526 - val_acc: 0.6062\n",
      "epoch 854/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5050.1114 - acc: 0.6173 - val_loss: 0.6512 - val_acc: 0.6156\n",
      "epoch 855/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5049.4790 - acc: 0.6142 - val_loss: 0.6502 - val_acc: 0.6172\n",
      "epoch 856/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5050.7922 - acc: 0.6180 - val_loss: 0.6515 - val_acc: 0.6188\n",
      "epoch 857/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5075.2122 - acc: 0.6127 - val_loss: 0.6516 - val_acc: 0.6172\n",
      "epoch 858/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5036.8020 - acc: 0.6224 - val_loss: 0.6525 - val_acc: 0.6125\n",
      "epoch 859/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5065.7731 - acc: 0.6157 - val_loss: 0.6510 - val_acc: 0.6141\n",
      "epoch 860/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5057.3902 - acc: 0.6154 - val_loss: 0.6511 - val_acc: 0.6125\n",
      "epoch 861/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5062.7120 - acc: 0.6158 - val_loss: 0.6523 - val_acc: 0.6109\n",
      "epoch 862/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5064.2244 - acc: 0.6134 - val_loss: 0.6516 - val_acc: 0.6125\n",
      "epoch 863/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5051.9702 - acc: 0.6146 - val_loss: 0.6513 - val_acc: 0.6125\n",
      "epoch 864/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5062.0761 - acc: 0.6141 - val_loss: 0.6517 - val_acc: 0.6125\n",
      "epoch 865/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5064.5861 - acc: 0.6126 - val_loss: 0.6506 - val_acc: 0.6125\n",
      "epoch 866/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5049.5665 - acc: 0.6188 - val_loss: 0.6521 - val_acc: 0.6125\n",
      "epoch 867/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5060.0795 - acc: 0.6191 - val_loss: 0.6509 - val_acc: 0.6172\n",
      "epoch 868/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5049.4463 - acc: 0.6215 - val_loss: 0.6509 - val_acc: 0.6172\n",
      "epoch 869/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5054.6040 - acc: 0.6150 - val_loss: 0.6508 - val_acc: 0.6141\n",
      "epoch 870/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5037.7565 - acc: 0.6199 - val_loss: 0.6518 - val_acc: 0.6078\n",
      "epoch 871/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5066.0302 - acc: 0.6144 - val_loss: 0.6524 - val_acc: 0.6062\n",
      "epoch 872/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 81s 5ms/step - loss: 5055.2566 - acc: 0.6148 - val_loss: 0.6500 - val_acc: 0.6125\n",
      "epoch 873/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5057.6726 - acc: 0.6176 - val_loss: 0.6509 - val_acc: 0.6125\n",
      "epoch 874/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5060.1020 - acc: 0.6175 - val_loss: 0.6510 - val_acc: 0.6125\n",
      "epoch 875/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5051.2893 - acc: 0.6181 - val_loss: 0.6521 - val_acc: 0.6078\n",
      "epoch 876/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5054.9057 - acc: 0.6126 - val_loss: 0.6515 - val_acc: 0.6141\n",
      "epoch 877/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5049.5532 - acc: 0.6175 - val_loss: 0.6506 - val_acc: 0.6109\n",
      "epoch 878/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5040.3592 - acc: 0.6183 - val_loss: 0.6517 - val_acc: 0.6109\n",
      "epoch 879/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5046.8094 - acc: 0.6214 - val_loss: 0.6514 - val_acc: 0.6125\n",
      "epoch 880/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5037.8910 - acc: 0.6187 - val_loss: 0.6508 - val_acc: 0.6109\n",
      "epoch 881/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5042.5145 - acc: 0.6206 - val_loss: 0.6513 - val_acc: 0.6172\n",
      "epoch 882/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5046.4997 - acc: 0.6185 - val_loss: 0.6507 - val_acc: 0.6141\n",
      "epoch 883/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5035.4425 - acc: 0.6182 - val_loss: 0.6514 - val_acc: 0.6156\n",
      "epoch 884/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5042.3809 - acc: 0.6202 - val_loss: 0.6513 - val_acc: 0.6125\n",
      "epoch 885/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5051.1002 - acc: 0.6142 - val_loss: 0.6513 - val_acc: 0.6156\n",
      "epoch 886/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5044.3555 - acc: 0.6161 - val_loss: 0.6516 - val_acc: 0.6141\n",
      "epoch 887/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5036.3916 - acc: 0.6163 - val_loss: 0.6520 - val_acc: 0.6078\n",
      "epoch 888/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5046.6314 - acc: 0.6185 - val_loss: 0.6516 - val_acc: 0.6094\n",
      "epoch 889/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5052.8404 - acc: 0.6155 - val_loss: 0.6520 - val_acc: 0.6078\n",
      "epoch 890/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5045.6062 - acc: 0.6173 - val_loss: 0.6511 - val_acc: 0.6094\n",
      "epoch 891/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5048.5844 - acc: 0.6175 - val_loss: 0.6510 - val_acc: 0.6125\n",
      "epoch 892/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5043.2476 - acc: 0.6173 - val_loss: 0.6521 - val_acc: 0.6047\n",
      "epoch 893/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5026.1785 - acc: 0.6196 - val_loss: 0.6516 - val_acc: 0.6109\n",
      "epoch 894/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5050.1772 - acc: 0.6200 - val_loss: 0.6508 - val_acc: 0.6125\n",
      "epoch 895/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5043.9944 - acc: 0.6180 - val_loss: 0.6516 - val_acc: 0.6141\n",
      "epoch 896/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5046.3559 - acc: 0.6198 - val_loss: 0.6513 - val_acc: 0.6141\n",
      "epoch 897/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5043.2024 - acc: 0.6163 - val_loss: 0.6515 - val_acc: 0.6141\n",
      "epoch 898/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5041.8263 - acc: 0.6173 - val_loss: 0.6527 - val_acc: 0.6094\n",
      "epoch 899/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5043.4412 - acc: 0.6205 - val_loss: 0.6513 - val_acc: 0.6141\n",
      "epoch 900/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5046.1446 - acc: 0.6192 - val_loss: 0.6517 - val_acc: 0.6156\n",
      "epoch 901/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5022.8610 - acc: 0.6189 - val_loss: 0.6529 - val_acc: 0.6109\n",
      "epoch 902/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5019.8330 - acc: 0.6220 - val_loss: 0.6512 - val_acc: 0.6156\n",
      "epoch 903/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5033.1252 - acc: 0.6201 - val_loss: 0.6519 - val_acc: 0.6125\n",
      "epoch 904/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5045.0908 - acc: 0.6198 - val_loss: 0.6514 - val_acc: 0.6125\n",
      "epoch 905/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5054.7433 - acc: 0.6161 - val_loss: 0.6510 - val_acc: 0.6109\n",
      "epoch 906/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 87s 6ms/step - loss: 5046.0245 - acc: 0.6206 - val_loss: 0.6510 - val_acc: 0.6125\n",
      "epoch 907/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5018.2363 - acc: 0.6226 - val_loss: 0.6510 - val_acc: 0.6125\n",
      "epoch 908/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5047.8727 - acc: 0.6155 - val_loss: 0.6523 - val_acc: 0.6109\n",
      "epoch 909/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5030.8931 - acc: 0.6175 - val_loss: 0.6522 - val_acc: 0.6109\n",
      "epoch 910/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5019.0732 - acc: 0.6204 - val_loss: 0.6523 - val_acc: 0.6141\n",
      "epoch 911/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5042.3863 - acc: 0.6155 - val_loss: 0.6526 - val_acc: 0.6094\n",
      "epoch 912/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5033.1274 - acc: 0.6196 - val_loss: 0.6517 - val_acc: 0.6062\n",
      "epoch 913/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5027.9961 - acc: 0.6190 - val_loss: 0.6526 - val_acc: 0.6078\n",
      "epoch 914/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5030.3565 - acc: 0.6187 - val_loss: 0.6527 - val_acc: 0.6062\n",
      "epoch 915/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5021.5713 - acc: 0.6213 - val_loss: 0.6518 - val_acc: 0.6094\n",
      "epoch 916/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5041.8129 - acc: 0.6163 - val_loss: 0.6513 - val_acc: 0.6109\n",
      "epoch 917/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5022.2653 - acc: 0.6218 - val_loss: 0.6513 - val_acc: 0.6156\n",
      "epoch 918/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5021.4217 - acc: 0.6181 - val_loss: 0.6512 - val_acc: 0.6125\n",
      "epoch 919/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5044.3483 - acc: 0.6183 - val_loss: 0.6521 - val_acc: 0.6172\n",
      "epoch 920/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5036.5155 - acc: 0.6177 - val_loss: 0.6520 - val_acc: 0.6062\n",
      "epoch 921/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5020.0847 - acc: 0.6228 - val_loss: 0.6516 - val_acc: 0.6125\n",
      "epoch 922/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5018.3200 - acc: 0.6217 - val_loss: 0.6534 - val_acc: 0.6047\n",
      "epoch 923/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5019.7818 - acc: 0.6196 - val_loss: 0.6538 - val_acc: 0.6078\n",
      "epoch 924/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5026.9223 - acc: 0.6218 - val_loss: 0.6509 - val_acc: 0.6094\n",
      "epoch 925/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5016.6738 - acc: 0.6226 - val_loss: 0.6520 - val_acc: 0.6078\n",
      "epoch 926/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5032.0345 - acc: 0.6208 - val_loss: 0.6519 - val_acc: 0.6047\n",
      "epoch 927/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5033.5388 - acc: 0.6161 - val_loss: 0.6518 - val_acc: 0.6078\n",
      "epoch 928/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5056.9222 - acc: 0.6130 - val_loss: 0.6517 - val_acc: 0.6125\n",
      "epoch 929/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5025.2487 - acc: 0.6189 - val_loss: 0.6514 - val_acc: 0.6078\n",
      "epoch 930/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5024.4713 - acc: 0.6188 - val_loss: 0.6514 - val_acc: 0.6125\n",
      "epoch 931/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4998.0035 - acc: 0.6227 - val_loss: 0.6509 - val_acc: 0.6047\n",
      "epoch 932/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5012.0973 - acc: 0.6213 - val_loss: 0.6504 - val_acc: 0.6125\n",
      "epoch 933/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5036.9705 - acc: 0.6140 - val_loss: 0.6512 - val_acc: 0.6094\n",
      "epoch 934/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5033.0851 - acc: 0.6194 - val_loss: 0.6529 - val_acc: 0.6078\n",
      "epoch 935/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5029.7652 - acc: 0.6170 - val_loss: 0.6508 - val_acc: 0.6156\n",
      "epoch 936/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5027.8910 - acc: 0.6194 - val_loss: 0.6522 - val_acc: 0.6094\n",
      "epoch 937/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5021.5806 - acc: 0.6222 - val_loss: 0.6522 - val_acc: 0.6094\n",
      "epoch 938/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5022.5509 - acc: 0.6187 - val_loss: 0.6523 - val_acc: 0.6047\n",
      "epoch 939/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5016.2004 - acc: 0.6233 - val_loss: 0.6521 - val_acc: 0.6094\n",
      "epoch 940/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5014.2957 - acc: 0.6246 - val_loss: 0.6529 - val_acc: 0.6062\n",
      "epoch 941/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5019.7875 - acc: 0.6193 - val_loss: 0.6526 - val_acc: 0.6078\n",
      "epoch 942/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5015.3743 - acc: 0.6233 - val_loss: 0.6528 - val_acc: 0.6078\n",
      "epoch 943/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5015.4157 - acc: 0.6216 - val_loss: 0.6510 - val_acc: 0.6125\n",
      "epoch 944/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5016.0356 - acc: 0.6228 - val_loss: 0.6514 - val_acc: 0.6078\n",
      "epoch 945/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5025.0831 - acc: 0.6200 - val_loss: 0.6527 - val_acc: 0.6094\n",
      "epoch 946/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5027.6921 - acc: 0.6176 - val_loss: 0.6513 - val_acc: 0.6125\n",
      "epoch 947/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5027.9874 - acc: 0.6175 - val_loss: 0.6522 - val_acc: 0.6094\n",
      "epoch 948/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5019.9787 - acc: 0.6181 - val_loss: 0.6512 - val_acc: 0.6078\n",
      "epoch 949/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5020.6860 - acc: 0.6183 - val_loss: 0.6520 - val_acc: 0.6125\n",
      "epoch 950/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5014.2553 - acc: 0.6230 - val_loss: 0.6517 - val_acc: 0.6062\n",
      "epoch 951/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5019.0280 - acc: 0.6238 - val_loss: 0.6505 - val_acc: 0.6109\n",
      "epoch 952/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5018.5083 - acc: 0.6204 - val_loss: 0.6511 - val_acc: 0.6125\n",
      "epoch 953/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5025.9292 - acc: 0.6189 - val_loss: 0.6494 - val_acc: 0.6156\n",
      "epoch 954/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5032.7145 - acc: 0.6211 - val_loss: 0.6523 - val_acc: 0.6078\n",
      "epoch 955/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5035.3517 - acc: 0.6213 - val_loss: 0.6519 - val_acc: 0.6109\n",
      "epoch 956/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5021.3285 - acc: 0.6202 - val_loss: 0.6514 - val_acc: 0.6094\n",
      "epoch 957/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 81s 5ms/step - loss: 5023.9308 - acc: 0.6175 - val_loss: 0.6521 - val_acc: 0.6078\n",
      "epoch 958/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5007.3035 - acc: 0.6210 - val_loss: 0.6524 - val_acc: 0.6078\n",
      "epoch 959/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5020.7786 - acc: 0.6219 - val_loss: 0.6518 - val_acc: 0.6094\n",
      "epoch 960/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5019.3450 - acc: 0.6200 - val_loss: 0.6514 - val_acc: 0.6094\n",
      "epoch 961/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5021.7897 - acc: 0.6201 - val_loss: 0.6513 - val_acc: 0.6062\n",
      "epoch 962/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5022.1033 - acc: 0.6202 - val_loss: 0.6511 - val_acc: 0.6109\n",
      "epoch 963/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5010.3989 - acc: 0.6214 - val_loss: 0.6513 - val_acc: 0.6094\n",
      "epoch 964/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5002.1175 - acc: 0.6255 - val_loss: 0.6511 - val_acc: 0.6094\n",
      "epoch 965/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5012.6828 - acc: 0.6195 - val_loss: 0.6523 - val_acc: 0.6094\n",
      "epoch 966/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5021.4339 - acc: 0.6201 - val_loss: 0.6523 - val_acc: 0.6109\n",
      "epoch 967/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5012.9782 - acc: 0.6208 - val_loss: 0.6518 - val_acc: 0.6078\n",
      "epoch 968/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5031.1519 - acc: 0.6177 - val_loss: 0.6519 - val_acc: 0.6141\n",
      "epoch 969/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4993.9556 - acc: 0.6249 - val_loss: 0.6522 - val_acc: 0.6109\n",
      "epoch 970/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5010.7036 - acc: 0.6218 - val_loss: 0.6510 - val_acc: 0.6094\n",
      "epoch 971/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5000.7856 - acc: 0.6207 - val_loss: 0.6518 - val_acc: 0.6094\n",
      "epoch 972/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5000.7689 - acc: 0.6206 - val_loss: 0.6520 - val_acc: 0.6094\n",
      "epoch 973/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5013.4403 - acc: 0.6222 - val_loss: 0.6512 - val_acc: 0.6125\n",
      "epoch 974/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5007.7185 - acc: 0.6208 - val_loss: 0.6499 - val_acc: 0.6109\n",
      "epoch 975/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5004.2397 - acc: 0.6223 - val_loss: 0.6521 - val_acc: 0.6078\n",
      "epoch 976/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5002.0973 - acc: 0.6237 - val_loss: 0.6509 - val_acc: 0.6078\n",
      "epoch 977/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5016.4592 - acc: 0.6214 - val_loss: 0.6527 - val_acc: 0.6062\n",
      "epoch 978/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5017.3952 - acc: 0.6214 - val_loss: 0.6503 - val_acc: 0.6078\n",
      "epoch 979/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5018.5269 - acc: 0.6237 - val_loss: 0.6522 - val_acc: 0.6078\n",
      "epoch 980/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5008.9363 - acc: 0.6279 - val_loss: 0.6517 - val_acc: 0.6141\n",
      "epoch 981/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5010.8061 - acc: 0.6211 - val_loss: 0.6518 - val_acc: 0.6109\n",
      "epoch 982/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4991.4825 - acc: 0.6231 - val_loss: 0.6508 - val_acc: 0.6109\n",
      "epoch 983/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5019.2246 - acc: 0.6202 - val_loss: 0.6523 - val_acc: 0.6094\n",
      "epoch 984/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4999.1535 - acc: 0.6247 - val_loss: 0.6520 - val_acc: 0.6125\n",
      "epoch 985/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 81s 5ms/step - loss: 5005.9967 - acc: 0.6237 - val_loss: 0.6514 - val_acc: 0.6094\n",
      "epoch 986/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5005.7398 - acc: 0.6207 - val_loss: 0.6517 - val_acc: 0.6078\n",
      "epoch 987/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5010.6736 - acc: 0.6222 - val_loss: 0.6527 - val_acc: 0.6078\n",
      "epoch 988/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5008.1899 - acc: 0.6201 - val_loss: 0.6524 - val_acc: 0.6047\n",
      "epoch 989/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5022.2688 - acc: 0.6183 - val_loss: 0.6503 - val_acc: 0.6094\n",
      "epoch 990/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4999.1336 - acc: 0.6233 - val_loss: 0.6519 - val_acc: 0.6125\n",
      "epoch 991/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4996.5544 - acc: 0.6246 - val_loss: 0.6515 - val_acc: 0.6109\n",
      "epoch 992/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4999.3130 - acc: 0.6245 - val_loss: 0.6516 - val_acc: 0.6094\n",
      "epoch 993/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4997.3109 - acc: 0.6222 - val_loss: 0.6506 - val_acc: 0.6125\n",
      "epoch 994/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4999.4160 - acc: 0.6233 - val_loss: 0.6525 - val_acc: 0.6031\n",
      "epoch 995/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4997.8193 - acc: 0.6241 - val_loss: 0.6534 - val_acc: 0.6031\n",
      "epoch 996/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4996.5224 - acc: 0.6217 - val_loss: 0.6508 - val_acc: 0.6156\n",
      "epoch 997/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 87s 6ms/step - loss: 5011.9815 - acc: 0.6205 - val_loss: 0.6526 - val_acc: 0.6078\n",
      "epoch 998/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 12603s 833ms/step - loss: 5001.3955 - acc: 0.6220 - val_loss: 0.6512 - val_acc: 0.6172\n",
      "epoch 999/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 87s 6ms/step - loss: 4999.5704 - acc: 0.6266 - val_loss: 0.6522 - val_acc: 0.6109\n",
      "epoch 1000/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 86s 6ms/step - loss: 5005.0792 - acc: 0.6224 - val_loss: 0.6521 - val_acc: 0.6109\n",
      "epoch 1001/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5002.0886 - acc: 0.6236 - val_loss: 0.6523 - val_acc: 0.6109\n",
      "epoch 1002/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4995.6174 - acc: 0.6232 - val_loss: 0.6534 - val_acc: 0.6062\n",
      "epoch 1003/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5001.7220 - acc: 0.6247 - val_loss: 0.6535 - val_acc: 0.6047\n",
      "epoch 1004/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4996.1156 - acc: 0.6243 - val_loss: 0.6529 - val_acc: 0.6109\n",
      "epoch 1005/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4995.6643 - acc: 0.6236 - val_loss: 0.6527 - val_acc: 0.6109\n",
      "epoch 1006/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4991.9403 - acc: 0.6240 - val_loss: 0.6531 - val_acc: 0.6094\n",
      "epoch 1007/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 87s 6ms/step - loss: 4986.3436 - acc: 0.6248 - val_loss: 0.6527 - val_acc: 0.6094\n",
      "epoch 1008/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4987.3596 - acc: 0.6263 - val_loss: 0.6526 - val_acc: 0.6109\n",
      "epoch 1009/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5017.2357 - acc: 0.6196 - val_loss: 0.6520 - val_acc: 0.6094\n",
      "epoch 1010/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4994.1431 - acc: 0.6231 - val_loss: 0.6524 - val_acc: 0.6141\n",
      "epoch 1011/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4997.6975 - acc: 0.6200 - val_loss: 0.6524 - val_acc: 0.6094\n",
      "epoch 1012/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4998.8917 - acc: 0.6226 - val_loss: 0.6518 - val_acc: 0.6094\n",
      "epoch 1013/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5001.9990 - acc: 0.6198 - val_loss: 0.6541 - val_acc: 0.6078\n",
      "epoch 1014/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 5004.0882 - acc: 0.6265 - val_loss: 0.6529 - val_acc: 0.6062\n",
      "epoch 1015/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4996.7410 - acc: 0.6191 - val_loss: 0.6524 - val_acc: 0.6094\n",
      "epoch 1016/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5006.5808 - acc: 0.6233 - val_loss: 0.6522 - val_acc: 0.6062\n",
      "epoch 1017/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 5000.1147 - acc: 0.6210 - val_loss: 0.6508 - val_acc: 0.6125\n",
      "epoch 1018/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4976.3721 - acc: 0.6234 - val_loss: 0.6516 - val_acc: 0.6094\n",
      "epoch 1019/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4993.0377 - acc: 0.6239 - val_loss: 0.6531 - val_acc: 0.6094\n",
      "epoch 1020/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5004.5388 - acc: 0.6234 - val_loss: 0.6523 - val_acc: 0.6078\n",
      "epoch 1021/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4994.0579 - acc: 0.6234 - val_loss: 0.6530 - val_acc: 0.6125\n",
      "epoch 1022/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4994.5887 - acc: 0.6224 - val_loss: 0.6533 - val_acc: 0.6109\n",
      "epoch 1023/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5000.0300 - acc: 0.6230 - val_loss: 0.6530 - val_acc: 0.6062\n",
      "epoch 1024/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5001.7336 - acc: 0.6222 - val_loss: 0.6536 - val_acc: 0.6047\n",
      "epoch 1025/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4979.6833 - acc: 0.6222 - val_loss: 0.6526 - val_acc: 0.6094\n",
      "epoch 1026/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4980.9663 - acc: 0.6232 - val_loss: 0.6541 - val_acc: 0.6062\n",
      "epoch 1027/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4987.4222 - acc: 0.6253 - val_loss: 0.6525 - val_acc: 0.6078\n",
      "epoch 1028/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4991.2163 - acc: 0.6242 - val_loss: 0.6528 - val_acc: 0.6031\n",
      "epoch 1029/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4974.2209 - acc: 0.6292 - val_loss: 0.6529 - val_acc: 0.6016\n",
      "epoch 1030/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4987.9982 - acc: 0.6267 - val_loss: 0.6528 - val_acc: 0.6109\n",
      "epoch 1031/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4973.2753 - acc: 0.6290 - val_loss: 0.6522 - val_acc: 0.6094\n",
      "epoch 1032/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 5005.1590 - acc: 0.6270 - val_loss: 0.6525 - val_acc: 0.6047\n",
      "epoch 1033/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4973.4702 - acc: 0.6239 - val_loss: 0.6537 - val_acc: 0.6062\n",
      "epoch 1034/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4979.5420 - acc: 0.6257 - val_loss: 0.6537 - val_acc: 0.6062\n",
      "epoch 1035/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4996.0424 - acc: 0.6220 - val_loss: 0.6531 - val_acc: 0.6094oss: 4991.3349\n",
      "epoch 1036/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4986.5545 - acc: 0.6209 - val_loss: 0.6518 - val_acc: 0.6078\n",
      "epoch 1037/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4970.2660 - acc: 0.6251 - val_loss: 0.6520 - val_acc: 0.6047\n",
      "epoch 1038/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 5005.9433 - acc: 0.6241 - val_loss: 0.6533 - val_acc: 0.6031\n",
      "epoch 1039/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4997.6475 - acc: 0.6170 - val_loss: 0.6502 - val_acc: 0.6094\n",
      "epoch 1040/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4981.0687 - acc: 0.6215 - val_loss: 0.6518 - val_acc: 0.6094\n",
      "epoch 1041/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4996.4443 - acc: 0.6250 - val_loss: 0.6533 - val_acc: 0.6047\n",
      "epoch 1042/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4973.8951 - acc: 0.6242 - val_loss: 0.6522 - val_acc: 0.6078\n",
      "epoch 1043/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4973.6888 - acc: 0.6251 - val_loss: 0.6518 - val_acc: 0.6094\n",
      "epoch 1044/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4977.8097 - acc: 0.6277 - val_loss: 0.6508 - val_acc: 0.6125\n",
      "epoch 1045/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4994.6866 - acc: 0.6207 - val_loss: 0.6528 - val_acc: 0.6094\n",
      "epoch 1046/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4978.4098 - acc: 0.6247 - val_loss: 0.6510 - val_acc: 0.6141\n",
      "epoch 1047/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4975.0853 - acc: 0.6275 - val_loss: 0.6526 - val_acc: 0.6094\n",
      "epoch 1048/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4974.1563 - acc: 0.6257 - val_loss: 0.6529 - val_acc: 0.6094\n",
      "epoch 1049/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4976.4496 - acc: 0.6223 - val_loss: 0.6524 - val_acc: 0.6062\n",
      "epoch 1050/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4979.8139 - acc: 0.6247 - val_loss: 0.6536 - val_acc: 0.6047\n",
      "epoch 1051/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4981.2612 - acc: 0.6276 - val_loss: 0.6525 - val_acc: 0.6125\n",
      "epoch 1052/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4981.3635 - acc: 0.6251 - val_loss: 0.6525 - val_acc: 0.6000\n",
      "epoch 1053/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4972.2299 - acc: 0.6284 - val_loss: 0.6507 - val_acc: 0.6141\n",
      "epoch 1054/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4989.3411 - acc: 0.6237 - val_loss: 0.6527 - val_acc: 0.5953\n",
      "epoch 1055/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4973.2312 - acc: 0.6283 - val_loss: 0.6521 - val_acc: 0.6047\n",
      "epoch 1056/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4967.7345 - acc: 0.6262 - val_loss: 0.6541 - val_acc: 0.6062\n",
      "epoch 1057/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4979.0496 - acc: 0.6236 - val_loss: 0.6535 - val_acc: 0.6016\n",
      "epoch 1058/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4974.8237 - acc: 0.6278 - val_loss: 0.6529 - val_acc: 0.6031\n",
      "epoch 1059/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4979.8261 - acc: 0.6253 - val_loss: 0.6523 - val_acc: 0.6062\n",
      "epoch 1060/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4982.3240 - acc: 0.6240 - val_loss: 0.6514 - val_acc: 0.6094\n",
      "epoch 1061/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4969.9271 - acc: 0.6217 - val_loss: 0.6525 - val_acc: 0.6016\n",
      "epoch 1062/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4984.3273 - acc: 0.6224 - val_loss: 0.6523 - val_acc: 0.6031\n",
      "epoch 1063/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4980.4171 - acc: 0.6292 - val_loss: 0.6520 - val_acc: 0.6078\n",
      "epoch 1064/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4973.7775 - acc: 0.6280 - val_loss: 0.6528 - val_acc: 0.6094\n",
      "epoch 1065/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4964.3392 - acc: 0.6259 - val_loss: 0.6527 - val_acc: 0.6125\n",
      "epoch 1066/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4974.8328 - acc: 0.6212 - val_loss: 0.6520 - val_acc: 0.6062\n",
      "epoch 1067/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4987.0886 - acc: 0.6229 - val_loss: 0.6509 - val_acc: 0.6141\n",
      "epoch 1068/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4979.7146 - acc: 0.6252 - val_loss: 0.6518 - val_acc: 0.6062\n",
      "epoch 1069/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4957.6858 - acc: 0.6248 - val_loss: 0.6517 - val_acc: 0.6125\n",
      "epoch 1070/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4977.4786 - acc: 0.6257 - val_loss: 0.6515 - val_acc: 0.6125\n",
      "epoch 1071/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4971.6172 - acc: 0.6247 - val_loss: 0.6522 - val_acc: 0.6141\n",
      "epoch 1072/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4965.4616 - acc: 0.6278 - val_loss: 0.6516 - val_acc: 0.6078\n",
      "epoch 1073/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4960.5821 - acc: 0.6284 - val_loss: 0.6526 - val_acc: 0.6078\n",
      "epoch 1074/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4954.4587 - acc: 0.6294 - val_loss: 0.6518 - val_acc: 0.6062\n",
      "epoch 1075/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4956.6488 - acc: 0.6309 - val_loss: 0.6547 - val_acc: 0.6047\n",
      "epoch 1076/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4964.0593 - acc: 0.6255 - val_loss: 0.6521 - val_acc: 0.6109\n",
      "epoch 1077/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4957.9714 - acc: 0.6263 - val_loss: 0.6517 - val_acc: 0.6172\n",
      "epoch 1078/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4956.0190 - acc: 0.6289 - val_loss: 0.6526 - val_acc: 0.6109\n",
      "epoch 1079/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4972.1979 - acc: 0.6258 - val_loss: 0.6532 - val_acc: 0.6062\n",
      "epoch 1080/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4975.9940 - acc: 0.6257 - val_loss: 0.6522 - val_acc: 0.6125\n",
      "epoch 1081/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4960.5998 - acc: 0.6286 - val_loss: 0.6543 - val_acc: 0.6031\n",
      "epoch 1082/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4980.1566 - acc: 0.6233 - val_loss: 0.6535 - val_acc: 0.6062\n",
      "epoch 1083/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4948.7265 - acc: 0.6301 - val_loss: 0.6538 - val_acc: 0.6094\n",
      "epoch 1084/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4978.1538 - acc: 0.6285 - val_loss: 0.6516 - val_acc: 0.6141\n",
      "epoch 1085/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4969.7897 - acc: 0.6243 - val_loss: 0.6521 - val_acc: 0.6109\n",
      "epoch 1086/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4971.6529 - acc: 0.6286 - val_loss: 0.6519 - val_acc: 0.6109\n",
      "epoch 1087/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4973.7740 - acc: 0.6280 - val_loss: 0.6523 - val_acc: 0.6094\n",
      "epoch 1088/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4964.9107 - acc: 0.6263 - val_loss: 0.6532 - val_acc: 0.6016\n",
      "epoch 1089/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4953.8856 - acc: 0.6296 - val_loss: 0.6520 - val_acc: 0.6078\n",
      "epoch 1090/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4963.6209 - acc: 0.6294 - val_loss: 0.6527 - val_acc: 0.6047\n",
      "epoch 1091/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4960.4210 - acc: 0.6276 - val_loss: 0.6535 - val_acc: 0.6062\n",
      "epoch 1092/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4955.1894 - acc: 0.6298 - val_loss: 0.6519 - val_acc: 0.6062\n",
      "epoch 1093/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4951.4295 - acc: 0.6259 - val_loss: 0.6533 - val_acc: 0.6031\n",
      "epoch 1094/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4951.6881 - acc: 0.6338 - val_loss: 0.6530 - val_acc: 0.6000\n",
      "epoch 1095/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4938.0575 - acc: 0.6302 - val_loss: 0.6513 - val_acc: 0.6156\n",
      "epoch 1096/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4954.3226 - acc: 0.6268 - val_loss: 0.6528 - val_acc: 0.6047\n",
      "epoch 1097/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4970.6877 - acc: 0.6237 - val_loss: 0.6532 - val_acc: 0.6016\n",
      "epoch 1098/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4947.9996 - acc: 0.6299 - val_loss: 0.6532 - val_acc: 0.6000\n",
      "epoch 1099/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4955.0552 - acc: 0.6274 - val_loss: 0.6533 - val_acc: 0.6016\n",
      "epoch 1100/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 4958.9195 - acc: 0.6305 - val_loss: 0.6537 - val_acc: 0.6094\n",
      "epoch 1101/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4957.5851 - acc: 0.6249 - val_loss: 0.6526 - val_acc: 0.6062\n",
      "epoch 1102/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4963.6738 - acc: 0.6263 - val_loss: 0.6522 - val_acc: 0.6078\n",
      "epoch 1103/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4959.6511 - acc: 0.6261 - val_loss: 0.6524 - val_acc: 0.6094\n",
      "epoch 1104/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4945.9410 - acc: 0.6267 - val_loss: 0.6513 - val_acc: 0.6125\n",
      "epoch 1105/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4960.2128 - acc: 0.6278 - val_loss: 0.6535 - val_acc: 0.6031\n",
      "epoch 1106/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4956.8498 - acc: 0.6275 - val_loss: 0.6548 - val_acc: 0.6078\n",
      "epoch 1107/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 104s 7ms/step - loss: 4958.9180 - acc: 0.6282 - val_loss: 0.6524 - val_acc: 0.6141\n",
      "epoch 1108/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 109s 7ms/step - loss: 4948.6550 - acc: 0.6282 - val_loss: 0.6531 - val_acc: 0.6031\n",
      "epoch 1109/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 97s 6ms/step - loss: 4961.4590 - acc: 0.6267 - val_loss: 0.6515 - val_acc: 0.6109\n",
      "epoch 1110/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4951.1632 - acc: 0.6299 - val_loss: 0.6504 - val_acc: 0.6141\n",
      "epoch 1111/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4945.3812 - acc: 0.6343 - val_loss: 0.6520 - val_acc: 0.6094\n",
      "epoch 1112/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4960.0311 - acc: 0.6261 - val_loss: 0.6518 - val_acc: 0.6172\n",
      "epoch 1113/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4949.2351 - acc: 0.6331 - val_loss: 0.6515 - val_acc: 0.6125\n",
      "epoch 1114/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4949.9192 - acc: 0.6294 - val_loss: 0.6529 - val_acc: 0.6016\n",
      "epoch 1115/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4948.9485 - acc: 0.6273 - val_loss: 0.6511 - val_acc: 0.6062\n",
      "epoch 1116/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4950.8604 - acc: 0.6254 - val_loss: 0.6527 - val_acc: 0.6000\n",
      "epoch 1117/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4954.3691 - acc: 0.6294 - val_loss: 0.6510 - val_acc: 0.6078\n",
      "epoch 1118/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4967.4558 - acc: 0.6225 - val_loss: 0.6514 - val_acc: 0.6062\n",
      "epoch 1119/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4946.7823 - acc: 0.6305 - val_loss: 0.6515 - val_acc: 0.6062\n",
      "epoch 1120/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4942.7594 - acc: 0.6315 - val_loss: 0.6513 - val_acc: 0.6141\n",
      "epoch 1121/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4947.8201 - acc: 0.6300 - val_loss: 0.6508 - val_acc: 0.6219\n",
      "epoch 1122/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4968.9893 - acc: 0.6285 - val_loss: 0.6521 - val_acc: 0.6062\n",
      "epoch 1123/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4957.1906 - acc: 0.6270 - val_loss: 0.6520 - val_acc: 0.6109\n",
      "epoch 1124/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4931.3409 - acc: 0.6315 - val_loss: 0.6511 - val_acc: 0.6141\n",
      "epoch 1125/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4943.1399 - acc: 0.6302 - val_loss: 0.6527 - val_acc: 0.6125\n",
      "epoch 1126/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4938.4747 - acc: 0.6301 - val_loss: 0.6531 - val_acc: 0.6125\n",
      "epoch 1127/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4962.9878 - acc: 0.6296 - val_loss: 0.6532 - val_acc: 0.6125\n",
      "epoch 1128/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4930.8390 - acc: 0.6319 - val_loss: 0.6535 - val_acc: 0.6047\n",
      "epoch 1129/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4925.5874 - acc: 0.6328 - val_loss: 0.6530 - val_acc: 0.6078\n",
      "epoch 1130/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4951.8977 - acc: 0.6289 - val_loss: 0.6530 - val_acc: 0.6094\n",
      "epoch 1131/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4942.4628 - acc: 0.6319 - val_loss: 0.6516 - val_acc: 0.6156\n",
      "epoch 1132/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4959.7184 - acc: 0.6265 - val_loss: 0.6521 - val_acc: 0.6125\n",
      "epoch 1133/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4943.1541 - acc: 0.6290 - val_loss: 0.6519 - val_acc: 0.6125\n",
      "epoch 1134/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4966.3874 - acc: 0.6242 - val_loss: 0.6520 - val_acc: 0.6125\n",
      "epoch 1135/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4941.5082 - acc: 0.6307 - val_loss: 0.6525 - val_acc: 0.6141\n",
      "epoch 1136/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4939.1841 - acc: 0.6311 - val_loss: 0.6509 - val_acc: 0.6172\n",
      "epoch 1137/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4916.7674 - acc: 0.6368 - val_loss: 0.6513 - val_acc: 0.6156\n",
      "epoch 1138/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4940.4589 - acc: 0.6317 - val_loss: 0.6531 - val_acc: 0.6141\n",
      "epoch 1139/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4976.9449 - acc: 0.6267 - val_loss: 0.6533 - val_acc: 0.6188\n",
      "epoch 1140/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4946.9055 - acc: 0.6294 - val_loss: 0.6534 - val_acc: 0.6172\n",
      "epoch 1141/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4934.9485 - acc: 0.6310 - val_loss: 0.6523 - val_acc: 0.6141\n",
      "epoch 1142/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4946.4088 - acc: 0.6274 - val_loss: 0.6506 - val_acc: 0.6078\n",
      "epoch 1143/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4957.6352 - acc: 0.6313 - val_loss: 0.6512 - val_acc: 0.6125\n",
      "epoch 1144/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4929.7586 - acc: 0.6323 - val_loss: 0.6512 - val_acc: 0.6078\n",
      "epoch 1145/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4942.1841 - acc: 0.6323 - val_loss: 0.6551 - val_acc: 0.6109\n",
      "epoch 1146/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4930.1960 - acc: 0.6294 - val_loss: 0.6504 - val_acc: 0.6125\n",
      "epoch 1147/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4933.1896 - acc: 0.6321 - val_loss: 0.6527 - val_acc: 0.6109\n",
      "epoch 1148/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4924.5095 - acc: 0.6333 - val_loss: 0.6513 - val_acc: 0.6141\n",
      "epoch 1149/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4943.8458 - acc: 0.6292 - val_loss: 0.6507 - val_acc: 0.6125\n",
      "epoch 1150/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4929.7380 - acc: 0.6325 - val_loss: 0.6506 - val_acc: 0.6172\n",
      "epoch 1151/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4928.8534 - acc: 0.6323 - val_loss: 0.6512 - val_acc: 0.6156\n",
      "epoch 1152/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4938.3403 - acc: 0.6331 - val_loss: 0.6515 - val_acc: 0.6141\n",
      "epoch 1153/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4925.6024 - acc: 0.6321 - val_loss: 0.6512 - val_acc: 0.6078\n",
      "epoch 1154/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4946.9722 - acc: 0.6268 - val_loss: 0.6503 - val_acc: 0.6094\n",
      "epoch 1155/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4937.7850 - acc: 0.6307 - val_loss: 0.6501 - val_acc: 0.6125\n",
      "epoch 1156/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 90s 6ms/step - loss: 4934.7333 - acc: 0.6306 - val_loss: 0.6507 - val_acc: 0.6125\n",
      "epoch 1157/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4922.9759 - acc: 0.6329 - val_loss: 0.6519 - val_acc: 0.6062\n",
      "epoch 1158/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4925.8600 - acc: 0.6319 - val_loss: 0.6528 - val_acc: 0.6109\n",
      "epoch 1159/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4933.1339 - acc: 0.6317 - val_loss: 0.6509 - val_acc: 0.6156\n",
      "epoch 1160/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4920.1672 - acc: 0.6321 - val_loss: 0.6518 - val_acc: 0.6125\n",
      "epoch 1161/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4926.5914 - acc: 0.6310 - val_loss: 0.6518 - val_acc: 0.6141\n",
      "epoch 1162/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4943.8053 - acc: 0.6307 - val_loss: 0.6516 - val_acc: 0.6125\n",
      "epoch 1163/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4936.0690 - acc: 0.6287 - val_loss: 0.6530 - val_acc: 0.6156\n",
      "epoch 1164/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4935.0552 - acc: 0.6312 - val_loss: 0.6523 - val_acc: 0.6156\n",
      "epoch 1165/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4938.2209 - acc: 0.6286 - val_loss: 0.6525 - val_acc: 0.6031\n",
      "epoch 1166/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4916.2837 - acc: 0.6312 - val_loss: 0.6521 - val_acc: 0.6188\n",
      "epoch 1167/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4934.4513 - acc: 0.6293 - val_loss: 0.6525 - val_acc: 0.6156\n",
      "epoch 1168/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4939.5429 - acc: 0.6293 - val_loss: 0.6537 - val_acc: 0.6031\n",
      "epoch 1169/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4927.6869 - acc: 0.6313 - val_loss: 0.6542 - val_acc: 0.6062\n",
      "epoch 1170/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4916.5907 - acc: 0.6302 - val_loss: 0.6533 - val_acc: 0.6156\n",
      "epoch 1171/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4925.5520 - acc: 0.6352 - val_loss: 0.6518 - val_acc: 0.6156\n",
      "epoch 1172/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4935.5106 - acc: 0.6276 - val_loss: 0.6522 - val_acc: 0.6094\n",
      "epoch 1173/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4928.8814 - acc: 0.6307 - val_loss: 0.6524 - val_acc: 0.6188\n",
      "epoch 1174/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4926.4719 - acc: 0.6290 - val_loss: 0.6529 - val_acc: 0.6062\n",
      "epoch 1175/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4935.5757 - acc: 0.6297 - val_loss: 0.6518 - val_acc: 0.6141\n",
      "epoch 1176/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4931.9145 - acc: 0.6319 - val_loss: 0.6515 - val_acc: 0.6062\n",
      "epoch 1177/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4919.1270 - acc: 0.6349 - val_loss: 0.6514 - val_acc: 0.6031\n",
      "epoch 1178/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4931.0251 - acc: 0.6313 - val_loss: 0.6529 - val_acc: 0.6094\n",
      "epoch 1179/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4927.7263 - acc: 0.6337 - val_loss: 0.6540 - val_acc: 0.6031\n",
      "epoch 1180/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4914.6634 - acc: 0.6334 - val_loss: 0.6522 - val_acc: 0.6141\n",
      "epoch 1181/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4911.8513 - acc: 0.6348 - val_loss: 0.6527 - val_acc: 0.6156\n",
      "epoch 1182/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4921.4968 - acc: 0.6331 - val_loss: 0.6547 - val_acc: 0.6016\n",
      "epoch 1183/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4911.2569 - acc: 0.6317 - val_loss: 0.6533 - val_acc: 0.6156\n",
      "epoch 1184/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 80s 5ms/step - loss: 4925.4904 - acc: 0.6313 - val_loss: 0.6531 - val_acc: 0.6047\n",
      "epoch 1185/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4916.5550 - acc: 0.6341 - val_loss: 0.6528 - val_acc: 0.6094\n",
      "epoch 1186/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4914.4057 - acc: 0.6314 - val_loss: 0.6522 - val_acc: 0.6156\n",
      "epoch 1187/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4922.9810 - acc: 0.6325 - val_loss: 0.6538 - val_acc: 0.6016\n",
      "epoch 1188/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4917.9115 - acc: 0.6341 - val_loss: 0.6539 - val_acc: 0.6000\n",
      "epoch 1189/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4922.9737 - acc: 0.6341 - val_loss: 0.6520 - val_acc: 0.6078\n",
      "epoch 1190/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4927.7669 - acc: 0.6330 - val_loss: 0.6521 - val_acc: 0.6078\n",
      "epoch 1191/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4917.2348 - acc: 0.6311 - val_loss: 0.6525 - val_acc: 0.6047\n",
      "epoch 1192/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4934.5848 - acc: 0.6329 - val_loss: 0.6524 - val_acc: 0.6047\n",
      "epoch 1193/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4909.5900 - acc: 0.6302 - val_loss: 0.6533 - val_acc: 0.6062\n",
      "epoch 1194/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4921.7011 - acc: 0.6270 - val_loss: 0.6523 - val_acc: 0.6109\n",
      "epoch 1195/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4901.5005 - acc: 0.6363 - val_loss: 0.6516 - val_acc: 0.6172\n",
      "epoch 1196/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4917.6502 - acc: 0.6309 - val_loss: 0.6527 - val_acc: 0.6125\n",
      "epoch 1197/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4912.6165 - acc: 0.6325 - val_loss: 0.6524 - val_acc: 0.6047\n",
      "epoch 1198/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4922.9806 - acc: 0.6316 - val_loss: 0.6527 - val_acc: 0.6078\n",
      "epoch 1199/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4910.6781 - acc: 0.6323 - val_loss: 0.6533 - val_acc: 0.6047\n",
      "epoch 1200/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4918.0572 - acc: 0.6346 - val_loss: 0.6520 - val_acc: 0.6062\n",
      "epoch 1201/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4905.6943 - acc: 0.6331 - val_loss: 0.6522 - val_acc: 0.6156\n",
      "epoch 1202/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4909.3818 - acc: 0.6386 - val_loss: 0.6525 - val_acc: 0.6094\n",
      "epoch 1203/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4912.7353 - acc: 0.6337 - val_loss: 0.6537 - val_acc: 0.6047\n",
      "epoch 1204/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4895.7046 - acc: 0.6371 - val_loss: 0.6545 - val_acc: 0.5984\n",
      "epoch 1205/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4917.2173 - acc: 0.6309 - val_loss: 0.6530 - val_acc: 0.6000\n",
      "epoch 1206/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4907.1378 - acc: 0.6345 - val_loss: 0.6515 - val_acc: 0.6078\n",
      "epoch 1207/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4909.3426 - acc: 0.6337 - val_loss: 0.6525 - val_acc: 0.5984\n",
      "epoch 1208/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4898.4295 - acc: 0.6347 - val_loss: 0.6520 - val_acc: 0.6094\n",
      "epoch 1209/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4888.8188 - acc: 0.6397 - val_loss: 0.6505 - val_acc: 0.6047\n",
      "epoch 1210/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4908.3155 - acc: 0.6321 - val_loss: 0.6514 - val_acc: 0.6188\n",
      "epoch 1211/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4901.4261 - acc: 0.6335 - val_loss: 0.6531 - val_acc: 0.6078\n",
      "epoch 1212/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4906.2296 - acc: 0.6350 - val_loss: 0.6514 - val_acc: 0.6141\n",
      "epoch 1213/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4904.4655 - acc: 0.6358 - val_loss: 0.6522 - val_acc: 0.6125\n",
      "epoch 1214/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4912.1616 - acc: 0.6342 - val_loss: 0.6513 - val_acc: 0.6156\n",
      "epoch 1215/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4893.2733 - acc: 0.6366 - val_loss: 0.6533 - val_acc: 0.6031\n",
      "epoch 1216/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4920.2653 - acc: 0.6318 - val_loss: 0.6527 - val_acc: 0.6109\n",
      "epoch 1217/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4892.2546 - acc: 0.6320 - val_loss: 0.6511 - val_acc: 0.6156\n",
      "epoch 1218/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4899.3399 - acc: 0.6359 - val_loss: 0.6514 - val_acc: 0.6141\n",
      "epoch 1219/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4899.5853 - acc: 0.6349 - val_loss: 0.6526 - val_acc: 0.6047\n",
      "epoch 1220/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4882.6535 - acc: 0.6339 - val_loss: 0.6529 - val_acc: 0.6094\n",
      "epoch 1221/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4910.9231 - acc: 0.6315 - val_loss: 0.6531 - val_acc: 0.6125\n",
      "epoch 1222/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4909.2568 - acc: 0.6351 - val_loss: 0.6525 - val_acc: 0.6188\n",
      "epoch 1223/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4902.8303 - acc: 0.6358 - val_loss: 0.6538 - val_acc: 0.6031\n",
      "epoch 1224/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4893.6413 - acc: 0.6322 - val_loss: 0.6524 - val_acc: 0.6109\n",
      "epoch 1225/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4904.7200 - acc: 0.6344 - val_loss: 0.6535 - val_acc: 0.6062\n",
      "epoch 1226/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4891.9172 - acc: 0.6344 - val_loss: 0.6530 - val_acc: 0.6094\n",
      "epoch 1227/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4898.1884 - acc: 0.6321 - val_loss: 0.6521 - val_acc: 0.6188\n",
      "epoch 1228/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4904.6305 - acc: 0.6353 - val_loss: 0.6522 - val_acc: 0.6141\n",
      "epoch 1229/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4890.9507 - acc: 0.6366 - val_loss: 0.6518 - val_acc: 0.6172\n",
      "epoch 1230/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4894.3142 - acc: 0.6327 - val_loss: 0.6525 - val_acc: 0.6062\n",
      "epoch 1231/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4908.5936 - acc: 0.6329 - val_loss: 0.6515 - val_acc: 0.6156\n",
      "epoch 1232/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4863.8305 - acc: 0.6409 - val_loss: 0.6508 - val_acc: 0.6156\n",
      "epoch 1233/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4909.0590 - acc: 0.6346 - val_loss: 0.6526 - val_acc: 0.6094\n",
      "epoch 1234/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4896.6257 - acc: 0.6332 - val_loss: 0.6537 - val_acc: 0.6078\n",
      "epoch 1235/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4901.2345 - acc: 0.6352 - val_loss: 0.6538 - val_acc: 0.6078\n",
      "epoch 1236/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4901.7801 - acc: 0.6350 - val_loss: 0.6528 - val_acc: 0.6141\n",
      "epoch 1237/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4883.0953 - acc: 0.6372 - val_loss: 0.6537 - val_acc: 0.6109\n",
      "epoch 1238/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4894.5818 - acc: 0.6351 - val_loss: 0.6517 - val_acc: 0.6141\n",
      "epoch 1239/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4900.8665 - acc: 0.6337 - val_loss: 0.6542 - val_acc: 0.6062\n",
      "epoch 1240/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4881.9858 - acc: 0.6371 - val_loss: 0.6523 - val_acc: 0.6141\n",
      "epoch 1241/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4869.1426 - acc: 0.6378 - val_loss: 0.6533 - val_acc: 0.6109\n",
      "epoch 1242/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4888.8423 - acc: 0.6376 - val_loss: 0.6527 - val_acc: 0.6156\n",
      "epoch 1243/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4889.2355 - acc: 0.6363 - val_loss: 0.6544 - val_acc: 0.6109\n",
      "epoch 1244/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4892.6404 - acc: 0.6361 - val_loss: 0.6536 - val_acc: 0.6109\n",
      "epoch 1245/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4897.8645 - acc: 0.6374 - val_loss: 0.6524 - val_acc: 0.6203\n",
      "epoch 1246/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4886.6465 - acc: 0.6370 - val_loss: 0.6522 - val_acc: 0.6172\n",
      "epoch 1247/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4892.1577 - acc: 0.6361 - val_loss: 0.6533 - val_acc: 0.6141\n",
      "epoch 1248/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4890.2661 - acc: 0.6355 - val_loss: 0.6518 - val_acc: 0.6156\n",
      "epoch 1249/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4883.2462 - acc: 0.6357 - val_loss: 0.6524 - val_acc: 0.6188\n",
      "epoch 1250/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4902.7082 - acc: 0.6321 - val_loss: 0.6531 - val_acc: 0.6125\n",
      "epoch 1251/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4878.3462 - acc: 0.6430 - val_loss: 0.6524 - val_acc: 0.6203\n",
      "epoch 1252/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4889.0585 - acc: 0.6325 - val_loss: 0.6543 - val_acc: 0.6094\n",
      "epoch 1253/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4904.4393 - acc: 0.6341 - val_loss: 0.6531 - val_acc: 0.6156\n",
      "epoch 1254/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4895.8712 - acc: 0.6329 - val_loss: 0.6534 - val_acc: 0.6156\n",
      "epoch 1255/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4866.9737 - acc: 0.6358 - val_loss: 0.6536 - val_acc: 0.6109\n",
      "epoch 1256/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4913.2362 - acc: 0.6347 - val_loss: 0.6533 - val_acc: 0.6234\n",
      "epoch 1257/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4901.7804 - acc: 0.6337 - val_loss: 0.6533 - val_acc: 0.6125\n",
      "epoch 1258/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4886.1550 - acc: 0.6336 - val_loss: 0.6531 - val_acc: 0.6188\n",
      "epoch 1259/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4878.2627 - acc: 0.6355 - val_loss: 0.6523 - val_acc: 0.6141\n",
      "epoch 1260/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4868.7135 - acc: 0.6385 - val_loss: 0.6543 - val_acc: 0.6094\n",
      "epoch 1261/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4872.2046 - acc: 0.6364 - val_loss: 0.6528 - val_acc: 0.6141\n",
      "epoch 1262/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4882.7108 - acc: 0.6345 - val_loss: 0.6525 - val_acc: 0.6125\n",
      "epoch 1263/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4897.1462 - acc: 0.6364 - val_loss: 0.6530 - val_acc: 0.6094\n",
      "epoch 1264/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4886.6360 - acc: 0.6341 - val_loss: 0.6547 - val_acc: 0.6094\n",
      "epoch 1265/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4879.6537 - acc: 0.6379 - val_loss: 0.6556 - val_acc: 0.6047\n",
      "epoch 1266/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4868.6229 - acc: 0.6364 - val_loss: 0.6542 - val_acc: 0.6141\n",
      "epoch 1267/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4876.5696 - acc: 0.6366 - val_loss: 0.6544 - val_acc: 0.6141\n",
      "epoch 1268/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4867.3686 - acc: 0.6402 - val_loss: 0.6548 - val_acc: 0.6141\n",
      "epoch 1269/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 4874.7531 - acc: 0.6381 - val_loss: 0.6538 - val_acc: 0.6125\n",
      "epoch 1270/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4879.3933 - acc: 0.6383 - val_loss: 0.6537 - val_acc: 0.6078\n",
      "epoch 1271/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4880.5951 - acc: 0.6380 - val_loss: 0.6542 - val_acc: 0.6062\n",
      "epoch 1272/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4860.5537 - acc: 0.6366 - val_loss: 0.6536 - val_acc: 0.6109\n",
      "epoch 1273/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4878.8048 - acc: 0.6360 - val_loss: 0.6540 - val_acc: 0.6109\n",
      "epoch 1274/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4887.2722 - acc: 0.6356 - val_loss: 0.6517 - val_acc: 0.6203\n",
      "epoch 1275/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4861.7541 - acc: 0.6391 - val_loss: 0.6539 - val_acc: 0.6125\n",
      "epoch 1276/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4881.1594 - acc: 0.6344 - val_loss: 0.6525 - val_acc: 0.6156\n",
      "epoch 1277/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4876.2427 - acc: 0.6398 - val_loss: 0.6531 - val_acc: 0.6141\n",
      "epoch 1278/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4885.5294 - acc: 0.6363 - val_loss: 0.6535 - val_acc: 0.6141\n",
      "epoch 1279/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4884.4741 - acc: 0.6378 - val_loss: 0.6539 - val_acc: 0.6125\n",
      "epoch 1280/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4874.8013 - acc: 0.6389 - val_loss: 0.6540 - val_acc: 0.6109\n",
      "epoch 1281/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4870.9682 - acc: 0.6389 - val_loss: 0.6533 - val_acc: 0.6125\n",
      "epoch 1282/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4868.8091 - acc: 0.6391 - val_loss: 0.6533 - val_acc: 0.6188\n",
      "epoch 1283/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4885.3778 - acc: 0.6348 - val_loss: 0.6524 - val_acc: 0.6188\n",
      "epoch 1284/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4855.3699 - acc: 0.6398 - val_loss: 0.6522 - val_acc: 0.6203\n",
      "epoch 1285/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4894.5237 - acc: 0.6361 - val_loss: 0.6530 - val_acc: 0.6156\n",
      "epoch 1286/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4881.2675 - acc: 0.6331 - val_loss: 0.6513 - val_acc: 0.6125\n",
      "epoch 1287/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4867.2283 - acc: 0.6382 - val_loss: 0.6522 - val_acc: 0.6203\n",
      "epoch 1288/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4875.7140 - acc: 0.6352 - val_loss: 0.6515 - val_acc: 0.6172\n",
      "epoch 1289/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4865.5414 - acc: 0.6379 - val_loss: 0.6520 - val_acc: 0.6125\n",
      "epoch 1290/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4883.9259 - acc: 0.6378 - val_loss: 0.6519 - val_acc: 0.6047\n",
      "epoch 1291/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4866.0031 - acc: 0.6409 - val_loss: 0.6525 - val_acc: 0.6141\n",
      "epoch 1292/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4873.0653 - acc: 0.6411 - val_loss: 0.6521 - val_acc: 0.6203\n",
      "epoch 1293/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4872.3576 - acc: 0.6349 - val_loss: 0.6523 - val_acc: 0.6188\n",
      "epoch 1294/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4872.2739 - acc: 0.6379 - val_loss: 0.6545 - val_acc: 0.6094\n",
      "epoch 1295/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4861.2271 - acc: 0.6386 - val_loss: 0.6521 - val_acc: 0.6125\n",
      "epoch 1296/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4852.4209 - acc: 0.6413 - val_loss: 0.6520 - val_acc: 0.6172\n",
      "epoch 1297/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4865.9339 - acc: 0.6376 - val_loss: 0.6528 - val_acc: 0.6172\n",
      "epoch 1298/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4859.4624 - acc: 0.6392 - val_loss: 0.6537 - val_acc: 0.6156\n",
      "epoch 1299/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4870.6423 - acc: 0.6387 - val_loss: 0.6516 - val_acc: 0.6203\n",
      "epoch 1300/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4877.1834 - acc: 0.6368 - val_loss: 0.6556 - val_acc: 0.6156\n",
      "epoch 1301/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4859.8991 - acc: 0.6352 - val_loss: 0.6542 - val_acc: 0.6219\n",
      "epoch 1302/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4847.7296 - acc: 0.6416 - val_loss: 0.6541 - val_acc: 0.6156\n",
      "epoch 1303/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4866.0435 - acc: 0.6366 - val_loss: 0.6544 - val_acc: 0.6125\n",
      "epoch 1304/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4876.4977 - acc: 0.6362 - val_loss: 0.6523 - val_acc: 0.6125\n",
      "epoch 1305/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4874.9296 - acc: 0.6350 - val_loss: 0.6538 - val_acc: 0.6094\n",
      "epoch 1306/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4845.7531 - acc: 0.6441 - val_loss: 0.6527 - val_acc: 0.6125\n",
      "epoch 1307/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4855.1287 - acc: 0.6385 - val_loss: 0.6549 - val_acc: 0.6047\n",
      "epoch 1308/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4844.1124 - acc: 0.6415 - val_loss: 0.6549 - val_acc: 0.6125\n",
      "epoch 1309/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4850.5185 - acc: 0.6440 - val_loss: 0.6546 - val_acc: 0.6109\n",
      "epoch 1310/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4868.6176 - acc: 0.6411 - val_loss: 0.6541 - val_acc: 0.6062\n",
      "epoch 1311/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4849.2082 - acc: 0.6427 - val_loss: 0.6554 - val_acc: 0.6047\n",
      "epoch 1312/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4867.0468 - acc: 0.6409 - val_loss: 0.6546 - val_acc: 0.6078\n",
      "epoch 1313/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4846.7362 - acc: 0.6376 - val_loss: 0.6557 - val_acc: 0.6062\n",
      "epoch 1314/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4855.9675 - acc: 0.6406 - val_loss: 0.6559 - val_acc: 0.5984\n",
      "epoch 1315/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4853.1051 - acc: 0.6399 - val_loss: 0.6544 - val_acc: 0.6125\n",
      "epoch 1316/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4861.8208 - acc: 0.6364 - val_loss: 0.6544 - val_acc: 0.6016\n",
      "epoch 1317/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4877.5816 - acc: 0.6364 - val_loss: 0.6535 - val_acc: 0.6141\n",
      "epoch 1318/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4848.7299 - acc: 0.6428 - val_loss: 0.6527 - val_acc: 0.6062\n",
      "epoch 1319/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4858.2758 - acc: 0.6404 - val_loss: 0.6550 - val_acc: 0.6000\n",
      "epoch 1320/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4847.3365 - acc: 0.6391 - val_loss: 0.6546 - val_acc: 0.6125\n",
      "epoch 1321/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4863.4566 - acc: 0.6377 - val_loss: 0.6538 - val_acc: 0.6156\n",
      "epoch 1322/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4853.3205 - acc: 0.6391 - val_loss: 0.6539 - val_acc: 0.6156\n",
      "epoch 1323/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4858.9587 - acc: 0.6409 - val_loss: 0.6550 - val_acc: 0.6078\n",
      "epoch 1324/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4858.9412 - acc: 0.6383 - val_loss: 0.6539 - val_acc: 0.6109\n",
      "epoch 1325/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4856.2590 - acc: 0.6402 - val_loss: 0.6539 - val_acc: 0.6125\n",
      "epoch 1326/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4852.6633 - acc: 0.6389 - val_loss: 0.6546 - val_acc: 0.6047\n",
      "epoch 1327/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4862.7108 - acc: 0.6378 - val_loss: 0.6551 - val_acc: 0.6109\n",
      "epoch 1328/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4853.2888 - acc: 0.6397 - val_loss: 0.6541 - val_acc: 0.6156\n",
      "epoch 1329/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4843.2904 - acc: 0.6430 - val_loss: 0.6551 - val_acc: 0.6094\n",
      "epoch 1330/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4863.5724 - acc: 0.6363 - val_loss: 0.6555 - val_acc: 0.6047\n",
      "epoch 1331/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4853.9070 - acc: 0.6391 - val_loss: 0.6540 - val_acc: 0.6141\n",
      "epoch 1332/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4837.3244 - acc: 0.6413 - val_loss: 0.6545 - val_acc: 0.6156\n",
      "epoch 1333/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4839.9319 - acc: 0.6414 - val_loss: 0.6543 - val_acc: 0.6172\n",
      "epoch 1334/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4858.2036 - acc: 0.6365 - val_loss: 0.6531 - val_acc: 0.6141\n",
      "epoch 1335/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4860.2933 - acc: 0.6413 - val_loss: 0.6537 - val_acc: 0.6156\n",
      "epoch 1336/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4848.1737 - acc: 0.6376 - val_loss: 0.6541 - val_acc: 0.6141\n",
      "epoch 1337/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4857.9666 - acc: 0.6395 - val_loss: 0.6535 - val_acc: 0.6109\n",
      "epoch 1338/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4852.9651 - acc: 0.6401 - val_loss: 0.6539 - val_acc: 0.6078\n",
      "epoch 1339/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4821.1096 - acc: 0.6444 - val_loss: 0.6538 - val_acc: 0.6156\n",
      "epoch 1340/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4841.4497 - acc: 0.6430 - val_loss: 0.6563 - val_acc: 0.6031\n",
      "epoch 1341/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4852.5212 - acc: 0.6422 - val_loss: 0.6538 - val_acc: 0.6062\n",
      "epoch 1342/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4862.9914 - acc: 0.6390 - val_loss: 0.6538 - val_acc: 0.6062\n",
      "epoch 1343/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4839.5333 - acc: 0.6415 - val_loss: 0.6548 - val_acc: 0.6031\n",
      "epoch 1344/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4849.2158 - acc: 0.6407 - val_loss: 0.6539 - val_acc: 0.6047\n",
      "epoch 1345/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4830.2296 - acc: 0.6450 - val_loss: 0.6549 - val_acc: 0.6062\n",
      "epoch 1346/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4860.7485 - acc: 0.6391 - val_loss: 0.6553 - val_acc: 0.6016\n",
      "epoch 1347/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4814.1900 - acc: 0.6456 - val_loss: 0.6553 - val_acc: 0.6062\n",
      "epoch 1348/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4832.8908 - acc: 0.6412 - val_loss: 0.6552 - val_acc: 0.6062\n",
      "epoch 1349/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4852.4618 - acc: 0.6405 - val_loss: 0.6535 - val_acc: 0.6203\n",
      "epoch 1350/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4847.9873 - acc: 0.6406 - val_loss: 0.6540 - val_acc: 0.6094\n",
      "epoch 1351/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4848.8240 - acc: 0.6349 - val_loss: 0.6541 - val_acc: 0.6125\n",
      "epoch 1352/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4829.0734 - acc: 0.6450 - val_loss: 0.6545 - val_acc: 0.6141\n",
      "epoch 1353/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4814.5588 - acc: 0.6454 - val_loss: 0.6540 - val_acc: 0.6156\n",
      "epoch 1354/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4838.5245 - acc: 0.6430 - val_loss: 0.6553 - val_acc: 0.6125\n",
      "epoch 1355/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 4850.7106 - acc: 0.6397 - val_loss: 0.6566 - val_acc: 0.6031\n",
      "epoch 1356/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4813.7477 - acc: 0.6432 - val_loss: 0.6549 - val_acc: 0.6094\n",
      "epoch 1357/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4842.7671 - acc: 0.6397 - val_loss: 0.6551 - val_acc: 0.6031\n",
      "epoch 1358/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4857.4379 - acc: 0.6399 - val_loss: 0.6555 - val_acc: 0.6000\n",
      "epoch 1359/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4823.8594 - acc: 0.6399 - val_loss: 0.6522 - val_acc: 0.6141\n",
      "epoch 1360/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4849.7962 - acc: 0.6370 - val_loss: 0.6551 - val_acc: 0.6016\n",
      "epoch 1361/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4844.2936 - acc: 0.6411 - val_loss: 0.6544 - val_acc: 0.6094\n",
      "epoch 1362/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4833.9227 - acc: 0.6418 - val_loss: 0.6544 - val_acc: 0.6078\n",
      "epoch 1363/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4817.7617 - acc: 0.6446 - val_loss: 0.6542 - val_acc: 0.6125\n",
      "epoch 1364/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4839.7981 - acc: 0.6415 - val_loss: 0.6541 - val_acc: 0.6062\n",
      "epoch 1365/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4837.0354 - acc: 0.6430 - val_loss: 0.6539 - val_acc: 0.6078\n",
      "epoch 1366/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4853.0464 - acc: 0.6376 - val_loss: 0.6540 - val_acc: 0.6078\n",
      "epoch 1367/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4844.5341 - acc: 0.6399 - val_loss: 0.6537 - val_acc: 0.6141\n",
      "epoch 1368/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4822.4817 - acc: 0.6441 - val_loss: 0.6525 - val_acc: 0.6156\n",
      "epoch 1369/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4830.1537 - acc: 0.6424 - val_loss: 0.6525 - val_acc: 0.6125\n",
      "epoch 1370/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4836.3564 - acc: 0.6401 - val_loss: 0.6553 - val_acc: 0.6078\n",
      "epoch 1371/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4824.7504 - acc: 0.6443 - val_loss: 0.6539 - val_acc: 0.6125\n",
      "epoch 1372/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4820.6127 - acc: 0.6463 - val_loss: 0.6545 - val_acc: 0.6125\n",
      "epoch 1373/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4848.6635 - acc: 0.6393 - val_loss: 0.6577 - val_acc: 0.5984\n",
      "epoch 1374/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4839.5268 - acc: 0.6389 - val_loss: 0.6561 - val_acc: 0.6016\n",
      "epoch 1375/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4852.3138 - acc: 0.6420 - val_loss: 0.6559 - val_acc: 0.6062\n",
      "epoch 1376/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4839.0163 - acc: 0.6389 - val_loss: 0.6534 - val_acc: 0.6125\n",
      "epoch 1377/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4820.9162 - acc: 0.6403 - val_loss: 0.6542 - val_acc: 0.6156\n",
      "epoch 1378/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4842.0293 - acc: 0.6406 - val_loss: 0.6527 - val_acc: 0.6156\n",
      "epoch 1379/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4795.1898 - acc: 0.6424 - val_loss: 0.6526 - val_acc: 0.6203\n",
      "epoch 1380/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4806.4941 - acc: 0.6442 - val_loss: 0.6525 - val_acc: 0.6141\n",
      "epoch 1381/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4839.9862 - acc: 0.6425 - val_loss: 0.6545 - val_acc: 0.6156\n",
      "epoch 1382/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4840.2565 - acc: 0.6436 - val_loss: 0.6541 - val_acc: 0.6172\n",
      "epoch 1383/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4823.6798 - acc: 0.6434 - val_loss: 0.6542 - val_acc: 0.6125\n",
      "epoch 1384/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4838.8463 - acc: 0.6424 - val_loss: 0.6562 - val_acc: 0.6062\n",
      "epoch 1385/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4845.1234 - acc: 0.6389 - val_loss: 0.6553 - val_acc: 0.6172\n",
      "epoch 1386/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4832.1222 - acc: 0.6421 - val_loss: 0.6576 - val_acc: 0.6016\n",
      "epoch 1387/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4809.3656 - acc: 0.6434 - val_loss: 0.6557 - val_acc: 0.6141\n",
      "epoch 1388/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4816.0282 - acc: 0.6440 - val_loss: 0.6547 - val_acc: 0.6125\n",
      "epoch 1389/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4810.4046 - acc: 0.6432 - val_loss: 0.6555 - val_acc: 0.6141\n",
      "epoch 1390/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4819.3908 - acc: 0.6448 - val_loss: 0.6549 - val_acc: 0.6078\n",
      "epoch 1391/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4817.3269 - acc: 0.6441 - val_loss: 0.6550 - val_acc: 0.6156\n",
      "epoch 1392/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4818.3911 - acc: 0.6450 - val_loss: 0.6538 - val_acc: 0.6125\n",
      "epoch 1393/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4826.0027 - acc: 0.6450 - val_loss: 0.6545 - val_acc: 0.6141\n",
      "epoch 1394/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4834.6126 - acc: 0.6413 - val_loss: 0.6551 - val_acc: 0.6078\n",
      "epoch 1395/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4819.6862 - acc: 0.6402 - val_loss: 0.6565 - val_acc: 0.6109\n",
      "epoch 1396/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4817.3330 - acc: 0.6452 - val_loss: 0.6562 - val_acc: 0.6031\n",
      "epoch 1397/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4842.1213 - acc: 0.6404 - val_loss: 0.6561 - val_acc: 0.6062\n",
      "epoch 1398/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 80s 5ms/step - loss: 4804.9510 - acc: 0.6450 - val_loss: 0.6554 - val_acc: 0.6062\n",
      "epoch 1399/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 75s 5ms/step - loss: 4818.2222 - acc: 0.6469 - val_loss: 0.6544 - val_acc: 0.6078\n",
      "epoch 1400/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 75s 5ms/step - loss: 4818.5011 - acc: 0.6442 - val_loss: 0.6559 - val_acc: 0.6031\n",
      "epoch 1401/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4820.3767 - acc: 0.6415 - val_loss: 0.6555 - val_acc: 0.6031\n",
      "epoch 1402/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4800.7001 - acc: 0.6470 - val_loss: 0.6541 - val_acc: 0.6078\n",
      "epoch 1403/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4822.0197 - acc: 0.6455 - val_loss: 0.6551 - val_acc: 0.6016\n",
      "epoch 1404/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4805.2670 - acc: 0.6391 - val_loss: 0.6554 - val_acc: 0.6047\n",
      "epoch 1405/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4830.1195 - acc: 0.6454 - val_loss: 0.6560 - val_acc: 0.6094\n",
      "epoch 1406/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4819.6148 - acc: 0.6459 - val_loss: 0.6556 - val_acc: 0.6141\n",
      "epoch 1407/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4805.5216 - acc: 0.6460 - val_loss: 0.6564 - val_acc: 0.6094\n",
      "epoch 1408/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4822.2734 - acc: 0.6428 - val_loss: 0.6551 - val_acc: 0.6109\n",
      "epoch 1409/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 75s 5ms/step - loss: 4811.8892 - acc: 0.6399 - val_loss: 0.6562 - val_acc: 0.6062\n",
      "epoch 1410/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 75s 5ms/step - loss: 4798.2999 - acc: 0.6442 - val_loss: 0.6561 - val_acc: 0.6031\n",
      "epoch 1411/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 4818.0044 - acc: 0.6444 - val_loss: 0.6548 - val_acc: 0.6172\n",
      "epoch 1412/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4799.5067 - acc: 0.6476 - val_loss: 0.6559 - val_acc: 0.6094\n",
      "epoch 1413/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4827.4279 - acc: 0.6389 - val_loss: 0.6550 - val_acc: 0.6062\n",
      "epoch 1414/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4799.1539 - acc: 0.6449 - val_loss: 0.6556 - val_acc: 0.6031\n",
      "epoch 1415/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4818.0301 - acc: 0.6476 - val_loss: 0.6549 - val_acc: 0.6078\n",
      "epoch 1416/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4806.9699 - acc: 0.6411 - val_loss: 0.6547 - val_acc: 0.6109\n",
      "epoch 1417/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4813.8550 - acc: 0.6445 - val_loss: 0.6556 - val_acc: 0.6078\n",
      "epoch 1418/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4827.3511 - acc: 0.6449 - val_loss: 0.6566 - val_acc: 0.6078\n",
      "epoch 1419/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 81s 5ms/step - loss: 4802.8309 - acc: 0.6438 - val_loss: 0.6556 - val_acc: 0.6031\n",
      "epoch 1420/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 77s 5ms/step - loss: 4807.8795 - acc: 0.6440 - val_loss: 0.6551 - val_acc: 0.6047\n",
      "epoch 1421/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 79s 5ms/step - loss: 4819.6132 - acc: 0.6440 - val_loss: 0.6556 - val_acc: 0.6109\n",
      "epoch 1422/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4815.9768 - acc: 0.6438 - val_loss: 0.6559 - val_acc: 0.6172\n",
      "epoch 1423/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4786.5903 - acc: 0.6481 - val_loss: 0.6548 - val_acc: 0.6109\n",
      "epoch 1424/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4804.7749 - acc: 0.6437 - val_loss: 0.6551 - val_acc: 0.6094\n",
      "epoch 1425/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4819.1770 - acc: 0.6436 - val_loss: 0.6562 - val_acc: 0.6031 - loss: 4815.7804 - acc: 0.\n",
      "epoch 1426/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4792.5206 - acc: 0.6483 - val_loss: 0.6551 - val_acc: 0.6078\n",
      "epoch 1427/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 79s 5ms/step - loss: 4811.6794 - acc: 0.6418 - val_loss: 0.6573 - val_acc: 0.6047\n",
      "epoch 1428/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 78s 5ms/step - loss: 4796.4523 - acc: 0.6493 - val_loss: 0.6554 - val_acc: 0.6047\n",
      "epoch 1429/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4785.1157 - acc: 0.6487 - val_loss: 0.6550 - val_acc: 0.6125\n",
      "epoch 1430/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4784.3028 - acc: 0.6475 - val_loss: 0.6538 - val_acc: 0.6125\n",
      "epoch 1431/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4797.2855 - acc: 0.6434 - val_loss: 0.6552 - val_acc: 0.6109\n",
      "epoch 1432/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4779.0798 - acc: 0.6522 - val_loss: 0.6549 - val_acc: 0.6109\n",
      "epoch 1433/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4788.7188 - acc: 0.6475 - val_loss: 0.6561 - val_acc: 0.6125\n",
      "epoch 1434/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4799.9507 - acc: 0.6488 - val_loss: 0.6559 - val_acc: 0.6062\n",
      "epoch 1435/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4800.5506 - acc: 0.6463 - val_loss: 0.6563 - val_acc: 0.6000\n",
      "epoch 1436/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4803.8221 - acc: 0.6431 - val_loss: 0.6559 - val_acc: 0.6000\n",
      "epoch 1437/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4787.4815 - acc: 0.6475 - val_loss: 0.6562 - val_acc: 0.6094\n",
      "epoch 1438/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4790.7387 - acc: 0.6481 - val_loss: 0.6573 - val_acc: 0.6047\n",
      "epoch 1439/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4787.6251 - acc: 0.6475 - val_loss: 0.6558 - val_acc: 0.6031\n",
      "epoch 1440/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4799.7543 - acc: 0.6439 - val_loss: 0.6555 - val_acc: 0.6047\n",
      "epoch 1441/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4792.0608 - acc: 0.6459 - val_loss: 0.6566 - val_acc: 0.6047\n",
      "epoch 1442/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4794.8679 - acc: 0.6454 - val_loss: 0.6540 - val_acc: 0.6078\n",
      "epoch 1443/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4799.9944 - acc: 0.6444 - val_loss: 0.6541 - val_acc: 0.6125\n",
      "epoch 1444/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4803.9678 - acc: 0.6448 - val_loss: 0.6545 - val_acc: 0.6062\n",
      "epoch 1445/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4801.0789 - acc: 0.6413 - val_loss: 0.6564 - val_acc: 0.5969\n",
      "epoch 1446/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4809.8118 - acc: 0.6450 - val_loss: 0.6563 - val_acc: 0.6109\n",
      "epoch 1447/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4781.8665 - acc: 0.6487 - val_loss: 0.6554 - val_acc: 0.6125\n",
      "epoch 1448/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4797.7120 - acc: 0.6450 - val_loss: 0.6574 - val_acc: 0.6062\n",
      "epoch 1449/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4815.7251 - acc: 0.6421 - val_loss: 0.6562 - val_acc: 0.6062\n",
      "epoch 1450/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4786.3664 - acc: 0.6465 - val_loss: 0.6559 - val_acc: 0.6094\n",
      "epoch 1451/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4799.4980 - acc: 0.6465 - val_loss: 0.6551 - val_acc: 0.6141\n",
      "epoch 1452/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4788.9855 - acc: 0.6475 - val_loss: 0.6558 - val_acc: 0.6062\n",
      "epoch 1453/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4806.8261 - acc: 0.6461 - val_loss: 0.6555 - val_acc: 0.6141\n",
      "epoch 1454/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4800.2984 - acc: 0.6445 - val_loss: 0.6564 - val_acc: 0.6016\n",
      "epoch 1455/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4778.9357 - acc: 0.6477 - val_loss: 0.6550 - val_acc: 0.6109\n",
      "epoch 1456/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4765.5751 - acc: 0.6523 - val_loss: 0.6565 - val_acc: 0.6156\n",
      "epoch 1457/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4776.6837 - acc: 0.6471 - val_loss: 0.6564 - val_acc: 0.6172\n",
      "epoch 1458/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4778.2520 - acc: 0.6518 - val_loss: 0.6553 - val_acc: 0.6156\n",
      "epoch 1459/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4779.7321 - acc: 0.6462 - val_loss: 0.6567 - val_acc: 0.6094\n",
      "epoch 1460/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4806.0236 - acc: 0.6422 - val_loss: 0.6567 - val_acc: 0.6109\n",
      "epoch 1461/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4763.6927 - acc: 0.6495 - val_loss: 0.6570 - val_acc: 0.6125\n",
      "epoch 1462/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 81s 5ms/step - loss: 4787.9107 - acc: 0.6498 - val_loss: 0.6562 - val_acc: 0.6078\n",
      "epoch 1463/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4791.2554 - acc: 0.6465 - val_loss: 0.6573 - val_acc: 0.6047\n",
      "epoch 1464/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4790.8426 - acc: 0.6454 - val_loss: 0.6558 - val_acc: 0.6125\n",
      "epoch 1465/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4775.4068 - acc: 0.6512 - val_loss: 0.6553 - val_acc: 0.6094\n",
      "epoch 1466/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4773.6807 - acc: 0.6479 - val_loss: 0.6564 - val_acc: 0.6000\n",
      "epoch 1467/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4781.1694 - acc: 0.6471 - val_loss: 0.6587 - val_acc: 0.6000\n",
      "epoch 1468/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4786.8636 - acc: 0.6474 - val_loss: 0.6556 - val_acc: 0.6062\n",
      "epoch 1469/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4764.9449 - acc: 0.6515 - val_loss: 0.6568 - val_acc: 0.6078\n",
      "epoch 1470/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4787.3106 - acc: 0.6484 - val_loss: 0.6566 - val_acc: 0.6078\n",
      "epoch 1471/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4780.4939 - acc: 0.6502 - val_loss: 0.6573 - val_acc: 0.6078\n",
      "epoch 1472/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4777.3405 - acc: 0.6481 - val_loss: 0.6565 - val_acc: 0.6047\n",
      "epoch 1473/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4781.1059 - acc: 0.6509 - val_loss: 0.6549 - val_acc: 0.6094\n",
      "epoch 1474/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4785.8375 - acc: 0.6461 - val_loss: 0.6559 - val_acc: 0.6078\n",
      "epoch 1475/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4777.2393 - acc: 0.6472 - val_loss: 0.6534 - val_acc: 0.6156\n",
      "epoch 1476/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4775.4086 - acc: 0.6468 - val_loss: 0.6556 - val_acc: 0.6078\n",
      "epoch 1477/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4781.2333 - acc: 0.6491 - val_loss: 0.6552 - val_acc: 0.6031\n",
      "epoch 1478/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4789.0630 - acc: 0.6498 - val_loss: 0.6536 - val_acc: 0.6172\n",
      "epoch 1479/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4784.7369 - acc: 0.6455 - val_loss: 0.6562 - val_acc: 0.6031\n",
      "epoch 1480/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4787.5732 - acc: 0.6489 - val_loss: 0.6570 - val_acc: 0.6094\n",
      "epoch 1481/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4779.5546 - acc: 0.6434 - val_loss: 0.6568 - val_acc: 0.6109\n",
      "epoch 1482/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4812.1779 - acc: 0.6469 - val_loss: 0.6549 - val_acc: 0.6016\n",
      "epoch 1483/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4785.1616 - acc: 0.6502 - val_loss: 0.6568 - val_acc: 0.6016\n",
      "epoch 1484/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4768.6393 - acc: 0.6514 - val_loss: 0.6562 - val_acc: 0.6016\n",
      "epoch 1485/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4770.1012 - acc: 0.6504 - val_loss: 0.6578 - val_acc: 0.6047\n",
      "epoch 1486/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4771.1749 - acc: 0.6506 - val_loss: 0.6557 - val_acc: 0.6078\n",
      "epoch 1487/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4778.3583 - acc: 0.6460 - val_loss: 0.6555 - val_acc: 0.6109\n",
      "epoch 1488/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4745.1160 - acc: 0.6531 - val_loss: 0.6544 - val_acc: 0.6125\n",
      "epoch 1489/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4774.2812 - acc: 0.6457 - val_loss: 0.6542 - val_acc: 0.6156\n",
      "epoch 1490/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4761.7878 - acc: 0.6557 - val_loss: 0.6541 - val_acc: 0.6188\n",
      "epoch 1491/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4776.4236 - acc: 0.6483 - val_loss: 0.6558 - val_acc: 0.6078\n",
      "epoch 1492/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4762.2195 - acc: 0.6502 - val_loss: 0.6548 - val_acc: 0.6047\n",
      "epoch 1493/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4788.1248 - acc: 0.6471 - val_loss: 0.6557 - val_acc: 0.5984\n",
      "epoch 1494/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4769.1439 - acc: 0.6512 - val_loss: 0.6572 - val_acc: 0.6000\n",
      "epoch 1495/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4757.5443 - acc: 0.6494 - val_loss: 0.6549 - val_acc: 0.6125\n",
      "epoch 1496/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4772.8261 - acc: 0.6501 - val_loss: 0.6541 - val_acc: 0.6141\n",
      "epoch 1497/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4787.9491 - acc: 0.6474 - val_loss: 0.6537 - val_acc: 0.6094\n",
      "epoch 1498/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4763.8565 - acc: 0.6483 - val_loss: 0.6555 - val_acc: 0.6094\n",
      "epoch 1499/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4753.7473 - acc: 0.6509 - val_loss: 0.6554 - val_acc: 0.6094\n",
      "epoch 1500/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4758.6177 - acc: 0.6473 - val_loss: 0.6561 - val_acc: 0.6109\n",
      "epoch 1501/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4765.9506 - acc: 0.6503 - val_loss: 0.6551 - val_acc: 0.6031\n",
      "epoch 1502/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4781.3630 - acc: 0.6483 - val_loss: 0.6565 - val_acc: 0.6078\n",
      "epoch 1503/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4731.6243 - acc: 0.6543 - val_loss: 0.6577 - val_acc: 0.6109\n",
      "epoch 1504/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4752.8917 - acc: 0.6522 - val_loss: 0.6545 - val_acc: 0.6094\n",
      "epoch 1505/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4769.4340 - acc: 0.6489 - val_loss: 0.6550 - val_acc: 0.6125\n",
      "epoch 1506/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4759.9804 - acc: 0.6487 - val_loss: 0.6550 - val_acc: 0.6078\n",
      "epoch 1507/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4781.8705 - acc: 0.6457 - val_loss: 0.6561 - val_acc: 0.6078\n",
      "epoch 1508/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4777.2314 - acc: 0.6489 - val_loss: 0.6546 - val_acc: 0.6094\n",
      "epoch 1509/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4769.8528 - acc: 0.6471 - val_loss: 0.6551 - val_acc: 0.6062\n",
      "epoch 1510/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4760.2483 - acc: 0.6477 - val_loss: 0.6539 - val_acc: 0.6094\n",
      "epoch 1511/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4760.9682 - acc: 0.6490 - val_loss: 0.6547 - val_acc: 0.6078\n",
      "epoch 1512/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4747.5180 - acc: 0.6495 - val_loss: 0.6531 - val_acc: 0.6172\n",
      "epoch 1513/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4769.4621 - acc: 0.6475 - val_loss: 0.6550 - val_acc: 0.6047\n",
      "epoch 1514/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4756.2134 - acc: 0.6533 - val_loss: 0.6544 - val_acc: 0.6109\n",
      "epoch 1515/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4750.6944 - acc: 0.6523 - val_loss: 0.6578 - val_acc: 0.6031\n",
      "epoch 1516/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4750.5483 - acc: 0.6543 - val_loss: 0.6547 - val_acc: 0.6062\n",
      "epoch 1517/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4752.5743 - acc: 0.6498 - val_loss: 0.6558 - val_acc: 0.6109: 0s - loss: 4749.4737 - acc: 0.\n",
      "epoch 1518/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4766.3996 - acc: 0.6487 - val_loss: 0.6553 - val_acc: 0.6062\n",
      "epoch 1519/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4774.2398 - acc: 0.6487 - val_loss: 0.6552 - val_acc: 0.6125\n",
      "epoch 1520/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4752.1917 - acc: 0.6541 - val_loss: 0.6550 - val_acc: 0.6031\n",
      "epoch 1521/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4745.5826 - acc: 0.6475 - val_loss: 0.6542 - val_acc: 0.6109\n",
      "epoch 1522/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4769.3846 - acc: 0.6490 - val_loss: 0.6554 - val_acc: 0.6047\n",
      "epoch 1523/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4756.5440 - acc: 0.6483 - val_loss: 0.6532 - val_acc: 0.6250\n",
      "epoch 1524/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4762.3106 - acc: 0.6512 - val_loss: 0.6571 - val_acc: 0.6078\n",
      "epoch 1525/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4746.9010 - acc: 0.6504 - val_loss: 0.6541 - val_acc: 0.6125\n",
      "epoch 1526/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 81s 5ms/step - loss: 4757.9885 - acc: 0.6545 - val_loss: 0.6550 - val_acc: 0.6062\n",
      "epoch 1527/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4730.1108 - acc: 0.6516 - val_loss: 0.6544 - val_acc: 0.6062\n",
      "epoch 1528/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4735.0351 - acc: 0.6547 - val_loss: 0.6554 - val_acc: 0.6109\n",
      "epoch 1529/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4734.5166 - acc: 0.6537 - val_loss: 0.6557 - val_acc: 0.6062\n",
      "epoch 1530/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4757.2303 - acc: 0.6539 - val_loss: 0.6546 - val_acc: 0.6078\n",
      "epoch 1531/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4731.7600 - acc: 0.6562 - val_loss: 0.6565 - val_acc: 0.6125\n",
      "epoch 1532/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4726.5340 - acc: 0.6549 - val_loss: 0.6556 - val_acc: 0.6172\n",
      "epoch 1533/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4745.5282 - acc: 0.6510 - val_loss: 0.6544 - val_acc: 0.6078\n",
      "epoch 1534/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4762.5167 - acc: 0.6527 - val_loss: 0.6581 - val_acc: 0.6031\n",
      "epoch 1535/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4733.9468 - acc: 0.6490 - val_loss: 0.6566 - val_acc: 0.6078\n",
      "epoch 1536/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4754.5840 - acc: 0.6505 - val_loss: 0.6558 - val_acc: 0.6094\n",
      "epoch 1537/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4777.2182 - acc: 0.6474 - val_loss: 0.6586 - val_acc: 0.6016\n",
      "epoch 1538/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4734.8522 - acc: 0.6527 - val_loss: 0.6566 - val_acc: 0.6094\n",
      "epoch 1539/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4755.9970 - acc: 0.6495 - val_loss: 0.6555 - val_acc: 0.6094\n",
      "epoch 1540/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4733.5056 - acc: 0.6576 - val_loss: 0.6559 - val_acc: 0.6094\n",
      "epoch 1541/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4742.5620 - acc: 0.6501 - val_loss: 0.6566 - val_acc: 0.6156\n",
      "epoch 1542/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4738.1235 - acc: 0.6525 - val_loss: 0.6565 - val_acc: 0.6156\n",
      "epoch 1543/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4741.3472 - acc: 0.6535 - val_loss: 0.6577 - val_acc: 0.6109\n",
      "epoch 1544/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4744.7155 - acc: 0.6517 - val_loss: 0.6561 - val_acc: 0.6078\n",
      "epoch 1545/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4738.7802 - acc: 0.6532 - val_loss: 0.6560 - val_acc: 0.6109\n",
      "epoch 1546/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4753.0413 - acc: 0.6504 - val_loss: 0.6553 - val_acc: 0.6203\n",
      "epoch 1547/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4739.3452 - acc: 0.6546 - val_loss: 0.6562 - val_acc: 0.6141\n",
      "epoch 1548/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4735.7755 - acc: 0.6510 - val_loss: 0.6551 - val_acc: 0.6078\n",
      "epoch 1549/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4732.4993 - acc: 0.6531 - val_loss: 0.6561 - val_acc: 0.6172\n",
      "epoch 1550/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4722.1791 - acc: 0.6559 - val_loss: 0.6558 - val_acc: 0.6141\n",
      "epoch 1551/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4734.1489 - acc: 0.6537 - val_loss: 0.6569 - val_acc: 0.6016\n",
      "epoch 1552/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4739.4466 - acc: 0.6543 - val_loss: 0.6551 - val_acc: 0.6109\n",
      "epoch 1553/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4747.6137 - acc: 0.6466 - val_loss: 0.6559 - val_acc: 0.6141\n",
      "epoch 1554/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4739.2675 - acc: 0.6533 - val_loss: 0.6562 - val_acc: 0.6141\n",
      "epoch 1555/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4720.2925 - acc: 0.6543 - val_loss: 0.6548 - val_acc: 0.6172\n",
      "epoch 1556/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 87s 6ms/step - loss: 4732.3154 - acc: 0.6528 - val_loss: 0.6535 - val_acc: 0.6297\n",
      "epoch 1557/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4720.5663 - acc: 0.6550 - val_loss: 0.6531 - val_acc: 0.6188\n",
      "epoch 1558/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4725.4453 - acc: 0.6517 - val_loss: 0.6552 - val_acc: 0.6078\n",
      "epoch 1559/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4723.4903 - acc: 0.6512 - val_loss: 0.6555 - val_acc: 0.6094\n",
      "epoch 1560/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4759.8401 - acc: 0.6489 - val_loss: 0.6561 - val_acc: 0.5984\n",
      "epoch 1561/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4728.9039 - acc: 0.6526 - val_loss: 0.6551 - val_acc: 0.6125\n",
      "epoch 1562/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4716.9667 - acc: 0.6542 - val_loss: 0.6584 - val_acc: 0.6078\n",
      "epoch 1563/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4759.4176 - acc: 0.6510 - val_loss: 0.6565 - val_acc: 0.6109\n",
      "epoch 1564/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4738.1397 - acc: 0.6547 - val_loss: 0.6549 - val_acc: 0.6094\n",
      "epoch 1565/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4735.0736 - acc: 0.6524 - val_loss: 0.6555 - val_acc: 0.6125\n",
      "epoch 1566/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4745.8312 - acc: 0.6510 - val_loss: 0.6554 - val_acc: 0.6078\n",
      "epoch 1567/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4728.3083 - acc: 0.6553 - val_loss: 0.6551 - val_acc: 0.6141\n",
      "epoch 1568/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4729.1101 - acc: 0.6529 - val_loss: 0.6554 - val_acc: 0.6141\n",
      "epoch 1569/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4711.4248 - acc: 0.6576 - val_loss: 0.6567 - val_acc: 0.6156\n",
      "epoch 1570/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4722.4524 - acc: 0.6536 - val_loss: 0.6577 - val_acc: 0.6031\n",
      "epoch 1571/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4736.1738 - acc: 0.6524 - val_loss: 0.6563 - val_acc: 0.6141\n",
      "epoch 1572/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4741.6362 - acc: 0.6523 - val_loss: 0.6570 - val_acc: 0.6031\n",
      "epoch 1573/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4718.1360 - acc: 0.6565 - val_loss: 0.6564 - val_acc: 0.6000\n",
      "epoch 1574/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4733.4483 - acc: 0.6549 - val_loss: 0.6571 - val_acc: 0.6047\n",
      "epoch 1575/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4716.4335 - acc: 0.6564 - val_loss: 0.6569 - val_acc: 0.6078\n",
      "epoch 1576/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4706.8909 - acc: 0.6566 - val_loss: 0.6550 - val_acc: 0.6141\n",
      "epoch 1577/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4714.0215 - acc: 0.6551 - val_loss: 0.6551 - val_acc: 0.6156\n",
      "epoch 1578/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4742.7582 - acc: 0.6516 - val_loss: 0.6559 - val_acc: 0.6141\n",
      "epoch 1579/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4728.9310 - acc: 0.6540 - val_loss: 0.6559 - val_acc: 0.6109\n",
      "epoch 1580/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4706.4613 - acc: 0.6534 - val_loss: 0.6562 - val_acc: 0.6156\n",
      "epoch 1581/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4705.2521 - acc: 0.6552 - val_loss: 0.6555 - val_acc: 0.6156\n",
      "epoch 1582/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4731.2846 - acc: 0.6541 - val_loss: 0.6562 - val_acc: 0.6109\n",
      "epoch 1583/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4732.4825 - acc: 0.6525 - val_loss: 0.6563 - val_acc: 0.6141\n",
      "epoch 1584/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4720.5206 - acc: 0.6553 - val_loss: 0.6551 - val_acc: 0.6156\n",
      "epoch 1585/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4713.8816 - acc: 0.6532 - val_loss: 0.6541 - val_acc: 0.6078\n",
      "epoch 1586/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4711.2413 - acc: 0.6562 - val_loss: 0.6546 - val_acc: 0.6078\n",
      "epoch 1587/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4694.0351 - acc: 0.6576 - val_loss: 0.6537 - val_acc: 0.6172\n",
      "epoch 1588/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4719.4785 - acc: 0.6510 - val_loss: 0.6577 - val_acc: 0.6094\n",
      "epoch 1589/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4726.9949 - acc: 0.6549 - val_loss: 0.6558 - val_acc: 0.6047\n",
      "epoch 1590/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4720.7140 - acc: 0.6550 - val_loss: 0.6564 - val_acc: 0.6078\n",
      "epoch 1591/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4713.7077 - acc: 0.6521 - val_loss: 0.6526 - val_acc: 0.6141\n",
      "epoch 1592/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4714.9484 - acc: 0.6579 - val_loss: 0.6546 - val_acc: 0.6156\n",
      "epoch 1593/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4739.7520 - acc: 0.6507 - val_loss: 0.6550 - val_acc: 0.6062\n",
      "epoch 1594/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4714.4848 - acc: 0.6599 - val_loss: 0.6565 - val_acc: 0.6047\n",
      "epoch 1595/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4714.0618 - acc: 0.6557 - val_loss: 0.6558 - val_acc: 0.6016\n",
      "epoch 1596/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4719.2126 - acc: 0.6506 - val_loss: 0.6560 - val_acc: 0.6078\n",
      "epoch 1597/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4705.8938 - acc: 0.6584 - val_loss: 0.6559 - val_acc: 0.6047\n",
      "epoch 1598/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4716.3672 - acc: 0.6534 - val_loss: 0.6555 - val_acc: 0.6078\n",
      "epoch 1599/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4744.2922 - acc: 0.6520 - val_loss: 0.6551 - val_acc: 0.6031\n",
      "epoch 1600/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4697.7624 - acc: 0.6581 - val_loss: 0.6564 - val_acc: 0.6109 -\n",
      "epoch 1601/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4720.2578 - acc: 0.6585 - val_loss: 0.6549 - val_acc: 0.6094\n",
      "epoch 1602/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4718.1557 - acc: 0.6574 - val_loss: 0.6566 - val_acc: 0.6109\n",
      "epoch 1603/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4720.5066 - acc: 0.6551 - val_loss: 0.6567 - val_acc: 0.6094\n",
      "epoch 1604/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4708.2473 - acc: 0.6514 - val_loss: 0.6560 - val_acc: 0.6125\n",
      "epoch 1605/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4714.1792 - acc: 0.6551 - val_loss: 0.6583 - val_acc: 0.6016\n",
      "epoch 1606/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4709.3997 - acc: 0.6541 - val_loss: 0.6579 - val_acc: 0.6062\n",
      "epoch 1607/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4729.5924 - acc: 0.6555 - val_loss: 0.6573 - val_acc: 0.6125\n",
      "epoch 1608/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4717.7383 - acc: 0.6559 - val_loss: 0.6564 - val_acc: 0.6109\n",
      "epoch 1609/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4706.6500 - acc: 0.6527 - val_loss: 0.6569 - val_acc: 0.6062\n",
      "epoch 1610/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4693.0136 - acc: 0.6584 - val_loss: 0.6557 - val_acc: 0.6141\n",
      "epoch 1611/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 82s 5ms/step - loss: 4703.2516 - acc: 0.6547 - val_loss: 0.6587 - val_acc: 0.6062\n",
      "epoch 1612/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4718.4720 - acc: 0.6539 - val_loss: 0.6572 - val_acc: 0.6094\n",
      "epoch 1613/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4681.7650 - acc: 0.6611 - val_loss: 0.6573 - val_acc: 0.6078\n",
      "epoch 1614/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4715.9442 - acc: 0.6564 - val_loss: 0.6548 - val_acc: 0.6094\n",
      "epoch 1615/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4711.6851 - acc: 0.6569 - val_loss: 0.6553 - val_acc: 0.6125\n",
      "epoch 1616/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4703.4465 - acc: 0.6547 - val_loss: 0.6560 - val_acc: 0.6172\n",
      "epoch 1617/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4704.1712 - acc: 0.6557 - val_loss: 0.6563 - val_acc: 0.6141\n",
      "epoch 1618/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4698.7426 - acc: 0.6590 - val_loss: 0.6560 - val_acc: 0.6109\n",
      "epoch 1619/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 87s 6ms/step - loss: 4686.1515 - acc: 0.6590 - val_loss: 0.6564 - val_acc: 0.6188\n",
      "epoch 1620/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4714.8989 - acc: 0.6553 - val_loss: 0.6559 - val_acc: 0.6125\n",
      "epoch 1621/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4714.6107 - acc: 0.6512 - val_loss: 0.6553 - val_acc: 0.6141\n",
      "epoch 1622/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4664.1234 - acc: 0.6596 - val_loss: 0.6566 - val_acc: 0.6062\n",
      "epoch 1623/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4692.3453 - acc: 0.6560 - val_loss: 0.6584 - val_acc: 0.6094\n",
      "epoch 1624/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4690.6946 - acc: 0.6570 - val_loss: 0.6585 - val_acc: 0.6047\n",
      "epoch 1625/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4709.0147 - acc: 0.6562 - val_loss: 0.6579 - val_acc: 0.6094\n",
      "epoch 1626/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4701.9519 - acc: 0.6534 - val_loss: 0.6558 - val_acc: 0.6062\n",
      "epoch 1627/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 5ms/step - loss: 4686.8776 - acc: 0.6575 - val_loss: 0.6561 - val_acc: 0.6141\n",
      "epoch 1628/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 87s 6ms/step - loss: 4694.0518 - acc: 0.6574 - val_loss: 0.6588 - val_acc: 0.6094\n",
      "epoch 1629/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4684.2378 - acc: 0.6603 - val_loss: 0.6570 - val_acc: 0.6094\n",
      "epoch 1630/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 86s 6ms/step - loss: 4691.5890 - acc: 0.6591 - val_loss: 0.6572 - val_acc: 0.6109\n",
      "epoch 1631/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4674.8128 - acc: 0.6588 - val_loss: 0.6583 - val_acc: 0.6172\n",
      "epoch 1632/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4686.6912 - acc: 0.6588 - val_loss: 0.6582 - val_acc: 0.6094\n",
      "epoch 1633/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4710.2923 - acc: 0.6533 - val_loss: 0.6587 - val_acc: 0.6016\n",
      "epoch 1634/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4695.9914 - acc: 0.6597 - val_loss: 0.6565 - val_acc: 0.6203\n",
      "epoch 1635/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4686.5872 - acc: 0.6605 - val_loss: 0.6597 - val_acc: 0.6078\n",
      "epoch 1636/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4682.7503 - acc: 0.6583 - val_loss: 0.6570 - val_acc: 0.6125\n",
      "epoch 1637/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4696.8021 - acc: 0.6574 - val_loss: 0.6604 - val_acc: 0.6094\n",
      "epoch 1638/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4680.9806 - acc: 0.6605 - val_loss: 0.6567 - val_acc: 0.6234\n",
      "epoch 1639/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4682.5867 - acc: 0.6586 - val_loss: 0.6571 - val_acc: 0.6203\n",
      "epoch 1640/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4678.0880 - acc: 0.6587 - val_loss: 0.6568 - val_acc: 0.6094\n",
      "epoch 1641/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4681.2302 - acc: 0.6569 - val_loss: 0.6574 - val_acc: 0.6078\n",
      "epoch 1642/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4689.0339 - acc: 0.6570 - val_loss: 0.6574 - val_acc: 0.6172\n",
      "epoch 1643/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4691.9160 - acc: 0.6580 - val_loss: 0.6579 - val_acc: 0.6109\n",
      "epoch 1644/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4694.8572 - acc: 0.6598 - val_loss: 0.6562 - val_acc: 0.6078\n",
      "epoch 1645/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4683.2786 - acc: 0.6582 - val_loss: 0.6561 - val_acc: 0.6109\n",
      "epoch 1646/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4682.7637 - acc: 0.6588 - val_loss: 0.6567 - val_acc: 0.6109\n",
      "epoch 1647/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4667.4354 - acc: 0.6615 - val_loss: 0.6576 - val_acc: 0.6141\n",
      "epoch 1648/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4707.8074 - acc: 0.6563 - val_loss: 0.6557 - val_acc: 0.6219\n",
      "epoch 1649/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4662.0155 - acc: 0.6607 - val_loss: 0.6537 - val_acc: 0.6266\n",
      "epoch 1650/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 85s 6ms/step - loss: 4690.7883 - acc: 0.6569 - val_loss: 0.6554 - val_acc: 0.6156\n",
      "epoch 1651/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4672.9979 - acc: 0.6638 - val_loss: 0.6572 - val_acc: 0.6125\n",
      "epoch 1652/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4667.8640 - acc: 0.6618 - val_loss: 0.6572 - val_acc: 0.6125\n",
      "epoch 1653/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4677.8304 - acc: 0.6611 - val_loss: 0.6561 - val_acc: 0.6156\n",
      "epoch 1654/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 84s 6ms/step - loss: 4682.8725 - acc: 0.6551 - val_loss: 0.6557 - val_acc: 0.6156\n",
      "epoch 1655/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 83s 6ms/step - loss: 4700.3219 - acc: 0.6537 - val_loss: 0.6581 - val_acc: 0.6062\n",
      "epoch 1656/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 112s 7ms/step - loss: 4688.3493 - acc: 0.6572 - val_loss: 0.6569 - val_acc: 0.6172\n",
      "epoch 1657/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 106s 7ms/step - loss: 4678.3484 - acc: 0.6540 - val_loss: 0.6612 - val_acc: 0.6094\n",
      "epoch 1658/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 112s 7ms/step - loss: 4692.9447 - acc: 0.6561 - val_loss: 0.6587 - val_acc: 0.6094\n",
      "epoch 1659/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 111s 7ms/step - loss: 4680.2761 - acc: 0.6574 - val_loss: 0.6594 - val_acc: 0.6078\n",
      "epoch 1660/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 110s 7ms/step - loss: 4675.3681 - acc: 0.6554 - val_loss: 0.6572 - val_acc: 0.6125\n",
      "epoch 1661/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 134s 9ms/step - loss: 4687.8388 - acc: 0.6564 - val_loss: 0.6569 - val_acc: 0.6078\n",
      "epoch 1662/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 123s 8ms/step - loss: 4672.8165 - acc: 0.6609 - val_loss: 0.6565 - val_acc: 0.6094\n",
      "epoch 1663/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 130s 9ms/step - loss: 4671.1014 - acc: 0.6576 - val_loss: 0.6545 - val_acc: 0.6172\n",
      "epoch 1664/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 110s 7ms/step - loss: 4677.5511 - acc: 0.6581 - val_loss: 0.6568 - val_acc: 0.6188\n",
      "epoch 1665/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 119s 8ms/step - loss: 4674.2006 - acc: 0.6617 - val_loss: 0.6571 - val_acc: 0.6172\n",
      "epoch 1666/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 112s 7ms/step - loss: 4666.3163 - acc: 0.6622 - val_loss: 0.6573 - val_acc: 0.6094\n",
      "epoch 1667/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 119s 8ms/step - loss: 4653.6351 - acc: 0.6635 - val_loss: 0.6580 - val_acc: 0.6062\n",
      "epoch 1668/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 118s 8ms/step - loss: 4681.0989 - acc: 0.6588 - val_loss: 0.6584 - val_acc: 0.6156\n",
      "epoch 1669/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 112s 7ms/step - loss: 4678.5407 - acc: 0.6561 - val_loss: 0.6585 - val_acc: 0.6125\n",
      "epoch 1670/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 127s 8ms/step - loss: 4650.0514 - acc: 0.6631 - val_loss: 0.6570 - val_acc: 0.6188\n",
      "epoch 1671/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 125s 8ms/step - loss: 4689.0920 - acc: 0.6562 - val_loss: 0.6565 - val_acc: 0.6109\n",
      "epoch 1672/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 112s 7ms/step - loss: 4681.9272 - acc: 0.6585 - val_loss: 0.6585 - val_acc: 0.6062\n",
      "epoch 1673/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 112s 7ms/step - loss: 4673.1538 - acc: 0.6621 - val_loss: 0.6580 - val_acc: 0.6219\n",
      "epoch 1674/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 122s 8ms/step - loss: 4675.6888 - acc: 0.6598 - val_loss: 0.6570 - val_acc: 0.6141\n",
      "epoch 1675/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 97s 6ms/step - loss: 4676.6396 - acc: 0.6570 - val_loss: 0.6568 - val_acc: 0.6141\n",
      "epoch 1676/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136/15136 [==============================] - 121s 8ms/step - loss: 4680.7941 - acc: 0.6592 - val_loss: 0.6586 - val_acc: 0.6094\n",
      "epoch 1677/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 138s 9ms/step - loss: 4638.3742 - acc: 0.6644 - val_loss: 0.6588 - val_acc: 0.6109\n",
      "epoch 1678/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 110s 7ms/step - loss: 4682.9603 - acc: 0.6571 - val_loss: 0.6584 - val_acc: 0.6078\n",
      "epoch 1679/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 121s 8ms/step - loss: 4645.2026 - acc: 0.6634 - val_loss: 0.6587 - val_acc: 0.6203\n",
      "epoch 1680/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "15136/15136 [==============================] - 104s 7ms/step - loss: 4685.8708 - acc: 0.6580 - val_loss: 0.6605 - val_acc: 0.6031\n",
      "epoch 1681/1600 **\n",
      "Train on 15136 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "14752/15136 [============================>.] - ETA: 2s - loss: 4660.0095 - acc: 0.6620"
     ]
    }
   ],
   "source": [
    "# Resume training\n",
    "n_epochs_resume = 1600\n",
    "\n",
    "for n in range(n_epochs_resume):\n",
    "    print('epoch {}/{} **'.format(counter, n_epochs_resume))\n",
    "\n",
    "    history = lstm.fit(x=X_train, y=y_train, epochs=1, validation_data=(X_test, y_test),\n",
    "                       batch_size=batch_size, shuffle=False, callbacks=callbacks,\n",
    "                      class_weight=class_weights,\n",
    "                      use_multiprocessing=True)\n",
    "\n",
    "     # Append the list to follow the evolution of loss on train and test sets\n",
    "    train_loss_list.append(history.history['loss'][0])\n",
    "    train_acc_list.append(history.history['acc'][0])\n",
    "\n",
    "    test_loss_list.append(history.history['val_loss'][0])\n",
    "    test_acc_list.append(history.history['val_acc'][0])\n",
    "\n",
    "\n",
    "    # Reset the cell states (required for stateful)\n",
    "    lstm.reset_states()\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "Ul8qG2Oh_IPF",
    "outputId": "8ce44178-cd1b-4ba2-8210-16f8f10d050b"
   },
   "outputs": [],
   "source": [
    "# Plot the errors\n",
    "fig, ax = plt.subplots(nrows=4)\n",
    "_ = ax[0].plot(range(1, counter), train_loss_list)\n",
    "_ = ax[0].set_title('Binary Crossentropy Loss on train set')\n",
    "\n",
    "_ = ax[1].plot(range(1, counter), train_acc_list)\n",
    "_ = ax[1].set_title('Accuracy Loss on train set')\n",
    "\n",
    "_ = ax[2].plot(range(1, counter), test_loss_list)\n",
    "_ = ax[2].set_title('Binary Crossentropy Loss on test set')\n",
    "\n",
    "_ = ax[3].plot(range(1, counter), test_acc_list)\n",
    "_ = ax[3].set_title('Accuracy Loss on test set')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Trained/BTC_LSTM_{}ep.h5\".format(n_epochs + n_epochs_resume) \n",
    "lstm.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cJrB6wZRf0xm"
   },
   "source": [
    "## Load and Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "KbFtFjur_IPI",
    "outputId": "042da526-6953-4115-c28d-b4c95ea874c9"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-899c589eacf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/gdrive/My Drive/.Startup/biLSTM_BTC_400ep.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m       \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    111\u001b[0m                   (export_dir,\n\u001b[1;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /content/gdrive/My Drive/.Startup/biLSTM_BTC_400ep.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "path = 'Trained/BTC_LSTM_400ep.h5\"\n",
    "lstm = keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kULQpQ1PffLf"
   },
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "gqxh9zLtfZvT",
    "outputId": "0abe10f4-410c-4688-a0d8-6dc6028080bb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bf43e52ed434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs_resume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch {}/{} **'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs_resume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     history = lstm.fit(x=X_train, y=y_train, epochs=1, validation_data=(X_test, y_test),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'counter' is not defined"
     ]
    }
   ],
   "source": [
    "# Resume training\n",
    "n_epochs_resume = 400\n",
    "\n",
    "for n in range(n_epochs_resume):\n",
    "    print('epoch {}/{} **'.format(counter, n_epochs_resume))\n",
    "\n",
    "    history = lstm.fit(x=X_train, y=y_train, epochs=1, validation_data=(X_test, y_test),\n",
    "                       batch_size=batch_size, shuffle=False, callbacks=callbacks,\n",
    "                      class_weight=class_weights,\n",
    "                      use_multiprocessing=True)\n",
    "\n",
    "     # Append the list to follow the evolution of loss on train and test sets\n",
    "    train_loss_list.append(history.history['loss'][0])\n",
    "    train_acc_list.append(history.history['acc'][0])\n",
    "\n",
    "    test_loss_list.append(history.history['val_loss'][0])\n",
    "    test_acc_list.append(history.history['val_acc'][0])\n",
    "\n",
    "\n",
    "    # Reset the cell states (required for stateful)\n",
    "    lstm.reset_states()\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NqEGFql-aR6o"
   },
   "outputs": [],
   "source": [
    "# Plot the errors\n",
    "fig, ax = plt.subplots(nrows=4)\n",
    "_ = ax[0].plot(range(1, counter), train_loss_list)\n",
    "_ = ax[0].set_title('Binary Crossentropy Loss on train set')\n",
    "\n",
    "_ = ax[1].plot(range(1, counter), train_acc_list)\n",
    "_ = ax[1].set_title('Accuracy Loss on train set')\n",
    "\n",
    "_ = ax[2].plot(range(1, counter), test_loss_list)\n",
    "_ = ax[2].set_title('Binary Crossentropy Loss on test set')\n",
    "\n",
    "_ = ax[3].plot(range(1, counter), test_acc_list)\n",
    "_ = ax[3].set_title('Accuracy Loss on test set')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xIiIIQhKaMpx"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "BTC Pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

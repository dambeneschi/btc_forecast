{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,12)\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, Softmax, Dense\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TABLE OF CONTENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Data Query\n",
    "## Prices Query\n",
    "- Platform is coinBase\n",
    "- BTC/USD price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- EUR/BTC Prices from 1589007600 to 1596207600 \n",
      "- EUR/BTC Prices from 1581807600 to 1589007600 \n",
      "- EUR/BTC Prices from 1574607600 to 1581807600 \n",
      "- EUR/BTC Prices from 1567407600 to 1574607600 \n",
      "- EUR/BTC Prices from 1560207600 to 1567407600 \n",
      "- EUR/BTC Prices from 1553007600 to 1560207600 \n",
      "- EUR/BTC Prices from 1545807600 to 1553007600 \n",
      "- EUR/BTC Prices from 1538607600 to 1545807600 \n"
     ]
    }
   ],
   "source": [
    "url_call = 'https://min-api.cryptocompare.com/data/v2/histohour?fsym=BTC&tsym={}&limit={}&e=Coinbase'\n",
    "\n",
    "# get data\n",
    "currency = 'EUR'\n",
    "n_batch_obs = 8\n",
    "n_obs = n_batch_obs * 2000\n",
    "reqs = []\n",
    "\n",
    "if n_obs > 2000:\n",
    "    \n",
    "    # Initial Call\n",
    "    req = json.loads(requests.get(url_call.format(currency, 2000)).text)\n",
    "    print('- {}/BTC Prices from {} to {} '.format(currency, req['Data']['TimeFrom'], req['Data']['TimeTo']))\n",
    "    reqs.append(req)\n",
    "    \n",
    "    for i in range(1, n_batch_obs):\n",
    "        # Second query to ave double the history if n_obs > 2000\n",
    "        req = json.loads(requests.get(url_call.format(currency, 2000) + '&toTs={}'.format(req['Data']['TimeFrom'])).text)\n",
    "        print('- {}/BTC Prices from {} to {} '.format(currency, req['Data']['TimeFrom'], req['Data']['TimeTo']))\n",
    "        reqs.append(req)\n",
    "\n",
    "else:\n",
    "\n",
    "    req = json.loads(requests.get(url_call.format(currency, n_obs)).text)\n",
    "    print('- {}/BTC Prices from {} to {} '.format(currency, req['Data']['TimeFrom'], req['Data']['TimeTo']))\n",
    "    reqs.append(req)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15996 entries, 2018-10-03 23:00:00 to 2020-07-31 15:00:00\n",
      "Data columns (total 6 columns):\n",
      "close         15996 non-null float64\n",
      "high          15996 non-null float64\n",
      "low           15996 non-null float64\n",
      "open          15996 non-null float64\n",
      "volumefrom    15996 non-null float64\n",
      "volumeto      15996 non-null float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 874.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Format as dataframe & sort DatetimeIndex\n",
    "df = pd.concat([pd.DataFrame(req['Data']['Data']) for req in reqs], axis=0)\n",
    "df.index = pd.to_datetime(df['time'], origin='unix', unit='s')\n",
    "df.drop(columns=['time', 'conversionType', 'conversionSymbol'], inplace=True)\n",
    "df.sort_index(ascending=True, inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News query"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "url_news = 'https://min-api.cryptocompare.com/data/v2/news/?lang=EN&excludeCategories=ETH,LTC,XMR,ZEC,XRP,TRX,ADA,DASH,XTZ,USDT&feeds=coindesk,yahoofinance,cointelegraph,bitcoin.com&ITs=1486506200'\n",
    "api_key = '?488602bf800b39d2d59f3d9a34e5062e7ba950ae55efc8a1845270c6b41e00f8'\n",
    "\n",
    "req = json.loads(requests.get(url_news + api_key).text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_news = pd.DataFrame(req['Data'])\n",
    "df_news.index = pd.to_datetime(df_news['published_on'], origin='unix', unit='s')\n",
    "df_news.drop(columns=['published_on', 'id', 'guid', 'imageurl', 'url', 'source', 'upvotes', 'downvotes', 'lang', 'source_info'], inplace=True)\n",
    "df_news.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "df_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Engineering\n",
    "## Features Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_tscores(series, window):\n",
    "    '''\n",
    "    Compute the T-Score on the previous values from a rolling window\n",
    "    in order to not calculate a t-score based on a distribution containing future values\n",
    "\n",
    "    return: time series of the t-score based on previous values window sample\n",
    "    '''\n",
    "\n",
    "    # Get the rolling window\n",
    "    roll_series = series.rolling(window)\n",
    "\n",
    "    # Get the mean & std of the sample of previous records (distribution)\n",
    "    m = roll_series.mean().shift(1)\n",
    "    s = roll_series.std(ddof=0).shift(1)\n",
    "\n",
    "    tscores = (series - m) / s\n",
    "\n",
    "    return tscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15996 entries, 2018-10-03 23:00:00 to 2020-07-31 15:00:00\n",
      "Data columns (total 26 columns):\n",
      "volumefrom           15996 non-null float64\n",
      "volumeto             15996 non-null float64\n",
      "close_mov1H          15995 non-null float64\n",
      "high_mov1H           15995 non-null float64\n",
      "low_mov1H            15995 non-null float64\n",
      "open_mov1H           15995 non-null float64\n",
      "volumefrom_mov1H     15995 non-null float64\n",
      "volumeto_mov1H       15995 non-null float64\n",
      "close_mov6H          15990 non-null float64\n",
      "high_mov6H           15990 non-null float64\n",
      "low_mov6H            15990 non-null float64\n",
      "open_mov6H           15990 non-null float64\n",
      "volumefrom_mov6H     15990 non-null float64\n",
      "volumeto_mov6H       15990 non-null float64\n",
      "close_mov12H         15984 non-null float64\n",
      "high_mov12H          15984 non-null float64\n",
      "low_mov12H           15984 non-null float64\n",
      "open_mov12H          15984 non-null float64\n",
      "volumefrom_mov12H    15984 non-null float64\n",
      "volumeto_mov12H      15984 non-null float64\n",
      "close_mov24H         15972 non-null float64\n",
      "high_mov24H          15972 non-null float64\n",
      "low_mov24H           15972 non-null float64\n",
      "open_mov24H          15972 non-null float64\n",
      "volumefrom_mov24H    15972 non-null float64\n",
      "volumeto_mov24H      15972 non-null float64\n",
      "dtypes: float64(26)\n",
      "memory usage: 3.3 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15996 entries, 2018-10-03 23:00:00 to 2020-07-31 15:00:00\n",
      "Columns: 858 entries, volumefrom to volumeto_mov24H.MSum24H.diff\n",
      "dtypes: float64(858)\n",
      "memory usage: 104.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# original columns to keep\n",
    "orig_cols = df.columns.tolist()[-2:]\n",
    "\n",
    "#----------------------\n",
    "# Movements and pct return (time step is hour)\n",
    "periods = [1, 6, 12, 24]\n",
    "movs_list = [df.diff(i) for i in periods]# + [df.pct_change(i) for i in periods]\n",
    "movs_labels = []\n",
    "\n",
    "for i in periods:\n",
    "    # Labels for the time derivatives\n",
    "    movs_labels += [col + '_mov{}H'.format(i) for col in df.columns]\n",
    "    \n",
    "#for i in periods:\n",
    "    # Labels for pct change\n",
    "    #movs_labels += [col + '_return{}H'.format(i) for col in df.columns]\n",
    "\n",
    "# Concatenate\n",
    "feats_df = pd.concat([df.loc[:, orig_cols]] + movs_list, axis=1)\n",
    "feats_df.columns = orig_cols + movs_labels\n",
    "\n",
    "print(feats_df.info())\n",
    "\n",
    "\n",
    "#----------------------\n",
    "# Rolling Statistics & T-Score\n",
    "for col in feats_df.columns:\n",
    "    # Get the series\n",
    "    series = feats_df.loc[:, col]\n",
    "    \n",
    "    for i in periods[1:]:\n",
    "\n",
    "        # Moving Averages series & combinations\n",
    "        feats_df[col +'.MA{}H'.format(i)] = series.rolling(\"{}H\".format(i)).mean()\n",
    "        feats_df[col + '.MA{}H.diff'.format(i)] = series.rolling(\"{}H\".format(i)).mean().diff()\n",
    "        \n",
    "        # Moving stats\n",
    "        feats_df[col + '.MStd{}H'.format(i)] = series.rolling(\"{}H\".format(i)).std()\n",
    "        feats_df[col + '.MStd{}H.diff'.format(i)] = series.rolling(\"{}H\".format(i)).std().diff()\n",
    "        \n",
    "        feats_df[col + '.MMin{}H'.format(i)] = series.rolling(\"{}H\".format(i)).min()\n",
    "        feats_df[col + '.MMin{}H.diff'.format(i)] = series.rolling(\"{}H\".format(i)).min().diff()\n",
    "        \n",
    "        feats_df[col + '.MMax{}H'.format(i)] = series.rolling(\"{}H\".format(i)).max()\n",
    "        feats_df[col + '.MMax{}H.diff'.format(i)] = series.rolling(\"{}H\".format(i)).max().diff()\n",
    "        \n",
    "        feats_df[col + '.MSum{}H'.format(i)] = series.rolling(\"{}H\".format(i)).sum()\n",
    "        feats_df[col + '.MSum{}H.diff'.format(i)] = series.rolling(\"{}H\".format(i)).sum().diff()\n",
    "      \n",
    "\n",
    "        # T-Score on rolling 1 month & 6 months sample (tscore is zscore on a sample, not on whole distribution)\n",
    "        feats_df[col + '.TScore6M'] = rolling_tscores(series=series, window='4400H')\n",
    "        feats_df[col + '.TScore1M'] = rolling_tscores(series=series, window='720H')\n",
    "        \n",
    "\n",
    "\n",
    "print(feats_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15996 entries, 2018-10-03 23:00:00 to 2020-07-31 15:00:00\n",
      "Columns: 1716 entries, volumefrom to volumeto_mov24H.MSum24H.diff.Squared\n",
      "dtypes: float64(1716)\n",
      "memory usage: 209.5 MB\n"
     ]
    }
   ],
   "source": [
    "# suqared features\n",
    "squared = []\n",
    "\n",
    "for col in feats_df.columns:\n",
    "    feats_df[col + '.Squared'] = feats_df[col] * feats_df[col]\n",
    "    \n",
    "feats_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15948 entries, 2018-10-05 23:00:00 to 2020-07-31 15:00:00\n",
      "Columns: 1716 entries, volumefrom to volumeto_mov24H.MSum24H.diff.Squared\n",
      "dtypes: float64(1716)\n",
      "memory usage: 208.9 MB\n",
      "None\n",
      "0 NaNs in the features\n",
      "0 inf values in the features\n"
     ]
    }
   ],
   "source": [
    "# Check for Inf or Nan values\n",
    "feats_df.dropna(inplace=True)\n",
    "print(feats_df.info())\n",
    "print('{} NaNs in the features'.format(feats_df.isnull().sum().sum()))\n",
    "print('{} inf values in the features'.format(feats_df.isin([np.inf, -np.inf]).sum().sum()))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time \n",
    "\n",
    "#----------------------\n",
    "# Polynomial features\n",
    "poly_transformer = PolynomialFeatures(degree=2, interaction_only=False, include_bias=True, order='F')\n",
    "feats_poly_values = poly_transformer.fit_transform(feats_df.dropna())\n",
    "\n",
    "feats_poly = pd.DataFrame(feats_poly_values,\n",
    "                          index=feats_df.index,\n",
    "                          columns=['PolyFeat{}'.format(i) for i in range(1, poly_transformer.n_output_features_+1)])\n",
    "\n",
    "print(feats_poly.info())\n",
    "\n",
    "# Add to the features df\n",
    "all_feats_df = pd.concat([feats_df, feats_poly], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TArget Engineering\n",
    "Target:\n",
    "* 2 labels: up/down\n",
    "* trend keep/change\n",
    "\n",
    "Features derived from target\n",
    "* difference of price from the min or max, average over last period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT OF THE BTC PRICE\n",
    "fig, ax = plt.subplots(nrows=2)\n",
    "\n",
    "_ = df['close'].plot(ax=ax[0], title='BTC price')\n",
    "_ = df['close'].diff().plot(ax=ax[1], title='BTC movement')\n",
    "_ = plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 2 labels: up/down\n",
    "price_mov = df['close'].diff().dropna()\n",
    "price_mov_class = price_mov.apply(lambda x: 'up' if x>=0 else 'down')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "_ = price_mov_class.value_counts().plot(kind='bar', title='Up/Down directions count', ax=ax[0])\n",
    "\n",
    "# Same/Different trend as previous one\n",
    "price_trend = (price_mov_class == price_mov_class.shift(1)).dropna()\n",
    "price_trend = price_trend.map({True: 0, False: 1})\n",
    "\n",
    "_ = price_trend.value_counts().plot(kind='bar', title='Keep(0)/Change(1) Trend direction count', ax=ax[1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n",
      "2018-10-04 00:00:00    1\n",
      "2018-10-04 01:00:00    0\n",
      "2018-10-04 02:00:00    0\n",
      "2018-10-04 03:00:00    1\n",
      "2018-10-04 04:00:00    1\n",
      "2018-10-04 05:00:00    1\n",
      "2018-10-04 06:00:00    0\n",
      "2018-10-04 07:00:00    1\n",
      "2018-10-04 08:00:00    0\n",
      "2018-10-04 09:00:00    1\n",
      "2018-10-04 10:00:00    0\n",
      "2018-10-04 11:00:00    1\n",
      "2018-10-04 12:00:00    1\n",
      "2018-10-04 13:00:00    1\n",
      "2018-10-04 14:00:00    1\n",
      "2018-10-04 15:00:00    1\n",
      "2018-10-04 16:00:00    0\n",
      "2018-10-04 17:00:00    0\n",
      "2018-10-04 18:00:00    0\n",
      "2018-10-04 19:00:00    0\n",
      "2018-10-04 20:00:00    1\n",
      "2018-10-04 21:00:00    1\n",
      "2018-10-04 22:00:00    0\n",
      "2018-10-04 23:00:00    1\n",
      "2018-10-05 00:00:00    1\n",
      "2018-10-05 01:00:00    1\n",
      "2018-10-05 02:00:00    0\n",
      "2018-10-05 03:00:00    1\n",
      "2018-10-05 04:00:00    1\n",
      "2018-10-05 05:00:00    1\n",
      "                      ..\n",
      "2020-07-30 10:00:00    0\n",
      "2020-07-30 11:00:00    0\n",
      "2020-07-30 12:00:00    0\n",
      "2020-07-30 13:00:00    1\n",
      "2020-07-30 14:00:00    1\n",
      "2020-07-30 15:00:00    1\n",
      "2020-07-30 16:00:00    0\n",
      "2020-07-30 17:00:00    0\n",
      "2020-07-30 18:00:00    0\n",
      "2020-07-30 19:00:00    0\n",
      "2020-07-30 20:00:00    0\n",
      "2020-07-30 21:00:00    1\n",
      "2020-07-30 22:00:00    1\n",
      "2020-07-30 23:00:00    1\n",
      "2020-07-31 00:00:00    0\n",
      "2020-07-31 01:00:00    0\n",
      "2020-07-31 02:00:00    0\n",
      "2020-07-31 03:00:00    0\n",
      "2020-07-31 04:00:00    1\n",
      "2020-07-31 05:00:00    1\n",
      "2020-07-31 06:00:00    1\n",
      "2020-07-31 07:00:00    0\n",
      "2020-07-31 08:00:00    1\n",
      "2020-07-31 09:00:00    0\n",
      "2020-07-31 10:00:00    1\n",
      "2020-07-31 11:00:00    0\n",
      "2020-07-31 12:00:00    0\n",
      "2020-07-31 13:00:00    1\n",
      "2020-07-31 14:00:00    1\n",
      "2020-07-31 15:00:00    0\n",
      "Name: close, Length: 15995, dtype: int64\n",
      "{1: 8687, 0: 7308}\n"
     ]
    }
   ],
   "source": [
    "target = price_trend\n",
    "class_weights = price_trend.value_counts().to_dict()\n",
    "print(target)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Selection, Splitting\n",
    "Kbest with f_classif criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass k=400 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15948 entries, 2018-10-05 23:00:00 to 2020-07-31 15:00:00\n",
      "Columns: 400 entries, volumefrom to volumeto_mov24H.MMax12H.diff.Squared\n",
      "dtypes: float64(400)\n",
      "memory usage: 48.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Align the features & Target indexes\n",
    "feats_df['target'] = target\n",
    "feats_df.dropna(inplace=True)\n",
    "target = feats_df['target']\n",
    "feats_df.drop(columns=['target'], inplace=True)\n",
    "\n",
    "# Keep the 400 most relevant features\n",
    "n_best = 400\n",
    "kbest_selector = SelectKBest(f_classif, n_best)\n",
    "\n",
    "# Fit on data\n",
    "kbest_values = kbest_selector.fit_transform(feats_df, target)\n",
    "kbest_df = pd.DataFrame(kbest_values,\n",
    "                        index=feats_df.index,\n",
    "                        columns=feats_df.loc[:, kbest_selector.get_support().tolist()].columns)\n",
    "\n",
    "kbest_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- compute lag 6\n",
      "- compute lag 5\n",
      "- compute lag 4\n",
      "- compute lag 3\n",
      "- compute lag 2\n",
      "- compute lag 1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15942 entries, 2018-10-06 05:00:00 to 2020-07-31 15:00:00\n",
      "Columns: 2800 entries, volumefrom(t6) to volumeto_mov24H.MMax12H.diff.Squared\n",
      "dtypes: float64(2800)\n",
      "memory usage: 340.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Add the 3rd dimension for the lags\n",
    "look_back = 6\n",
    "\n",
    "lagged = []\n",
    "labels = []\n",
    "\n",
    "# Add Lagged Features (from last to newest)\n",
    "for l in range(look_back, 0, -1):\n",
    "    print('- compute lag {}'.format(l))\n",
    "    lagged.append(kbest_df.shift(l))\n",
    "    labels += ['{}(t{})'.format(col, l) for col in kbest_df.columns]\n",
    "\n",
    "# Add actual features dataframe (no lag)\n",
    "lagged.append(kbest_df)\n",
    "labels += kbest_df.columns.tolist()\n",
    "\n",
    "# Put together into DF\n",
    "third_df = pd.concat(lagged, axis=1)\n",
    "third_df.columns = labels\n",
    "\n",
    "\n",
    "# Align the features & Target indexes\n",
    "third_df['target'] = target\n",
    "third_df.dropna(inplace=True)\n",
    "target = third_df['target']\n",
    "third_df.drop(columns=['target'], inplace=True)\n",
    "\n",
    "\n",
    "third_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14342\n",
      "448\n",
      "Train: 14336, Test:1280, Validation:320\n",
      "- Features arrays shapes: (15942, 2800) (14336, 2800) (1280, 2800) (320, 2800)\n",
      "- Features arrays shapes: (14336, 7, 400) (1280, 7, 400) (320, 7, 400)\n",
      "- Target arrays shapes: (14336,) (1280,) (320,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data - validation on 1 week\n",
    "batch_size = 32\n",
    "n_test = 40 * batch_size\n",
    "n_val = 10 * batch_size\n",
    "\n",
    "# Number of obs to keep in train set to have a round number of batches\n",
    "n_train = int((len(third_df) -n_test-n_val) / batch_size) * batch_size\n",
    "print(len(third_df)-n_test-n_val)\n",
    "print(int((len(third_df) -n_test-n_val) / batch_size))\n",
    "\n",
    "print('Train: {}, Test:{}, Validation:{}'.format(n_train, n_test, n_val))\n",
    "\n",
    "# Features splitting & Scaling\n",
    "X_all = third_df.values\n",
    "X_train = X_all[-n_train-n_test-n_val:-n_test-n_val, :]\n",
    "X_test = X_all[-n_test-n_val:-n_val, :]\n",
    "X_val = X_all[-n_val:, :]\n",
    "\n",
    "print('- Features arrays shapes: {} {} {} {}'.format(X_all.shape, X_train.shape, X_test.shape, X_val.shape))\n",
    "\n",
    "# Scale the values between [-1,1]\n",
    "X_scaler = MinMaxScaler((-1,1))\n",
    "\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "X_val = X_scaler.transform(X_val)\n",
    "\n",
    "# Reshape\n",
    "X_train = X_train.reshape(n_train, look_back+1, n_best)\n",
    "X_test = X_test.reshape(n_test, look_back+1, n_best)\n",
    "X_val = X_val.reshape(n_val, look_back+1, n_best)\n",
    "\n",
    "print('- Features arrays shapes: {} {} {}'.format(X_train.shape, X_test.shape, X_val.shape))\n",
    "\n",
    "# Targets\n",
    "y_all = target.values\n",
    "y_train = y_all[-n_train-n_test-n_val:-n_test-n_val]\n",
    "y_test = y_all[-n_test-n_val:-n_val]\n",
    "y_val = y_all[-n_val:]\n",
    "\n",
    "print('- Target arrays shapes: {} {} {}'.format(y_train.shape, y_test.shape, y_val.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM parameters\n",
    "lr = 1e-5\n",
    "n_epochs = 6000\n",
    "activation = 'tanh'\n",
    "dr = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0731 17:11:30.841953 4554251712 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (32, 7, 200)              480800    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (32, 7, 200)              320800    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (32, 7, 100)              120400    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (32, 40)                  22560     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 1)                   41        \n",
      "=================================================================\n",
      "Total params: 944,601\n",
      "Trainable params: 944,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Network Architecture\n",
    "lstm = Sequential()\n",
    "\n",
    "\n",
    "lstm.add(LSTM(200, activation=activation, stateful=True,\n",
    "              batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "              return_sequences=True, dropout=dr, recurrent_dropout=dr))\n",
    "\n",
    "lstm.add(LSTM(200, activation=activation, stateful=True,\n",
    "              batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "              return_sequences=True, dropout=dr, recurrent_dropout=dr))\n",
    "\n",
    "lstm.add(LSTM(100, activation=activation, stateful=True,\n",
    "              batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "              return_sequences=True, dropout=dr, recurrent_dropout=dr))\n",
    "\n",
    "lstm.add(LSTM(40, activation=activation, stateful=True,\n",
    "              batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "              return_sequences=False, dropout=dr, recurrent_dropout=dr))\n",
    "\n",
    "# Output layer\n",
    "lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "print(lstm.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting across epochs\n",
    "callbacks = [ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=10, \n",
    "                               mode=\"auto\", min_delta=0.0001, min_lr=1e-9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** epoch 1/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 28s 2ms/sample - loss: 5483.0311 - acc: 0.5413 - val_loss: 0.6907 - val_acc: 0.5586\n",
      "** epoch 2/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 29s 2ms/sample - loss: 5483.1244 - acc: 0.5414 - val_loss: 0.6908 - val_acc: 0.5586\n",
      "** epoch 3/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 31s 2ms/sample - loss: 5475.6302 - acc: 0.5412 - val_loss: 0.6906 - val_acc: 0.5586\n",
      "** epoch 4/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 32s 2ms/sample - loss: 5480.7542 - acc: 0.5416 - val_loss: 0.6906 - val_acc: 0.5586\n",
      "** epoch 5/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 33s 2ms/sample - loss: 5475.1590 - acc: 0.5415 - val_loss: 0.6904 - val_acc: 0.5586\n",
      "** epoch 6/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 34s 2ms/sample - loss: 5477.4908 - acc: 0.5416 - val_loss: 0.6905 - val_acc: 0.5586\n",
      "** epoch 7/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 35s 2ms/sample - loss: 5478.8075 - acc: 0.5414 - val_loss: 0.6902 - val_acc: 0.5586\n",
      "** epoch 8/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 36s 3ms/sample - loss: 5477.7540 - acc: 0.5414 - val_loss: 0.6907 - val_acc: 0.5586\n",
      "** epoch 9/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 37s 3ms/sample - loss: 5473.4445 - acc: 0.5414 - val_loss: 0.6900 - val_acc: 0.5586\n",
      "** epoch 10/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 38s 3ms/sample - loss: 5475.1433 - acc: 0.5415 - val_loss: 0.6898 - val_acc: 0.5586\n",
      "** epoch 11/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 39s 3ms/sample - loss: 5476.2791 - acc: 0.5415 - val_loss: 0.6902 - val_acc: 0.5586\n",
      "** epoch 12/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 40s 3ms/sample - loss: 5476.7882 - acc: 0.5416 - val_loss: 0.6898 - val_acc: 0.5586\n",
      "** epoch 13/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 41s 3ms/sample - loss: 5478.7441 - acc: 0.5415 - val_loss: 0.6901 - val_acc: 0.5586\n",
      "** epoch 14/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 42s 3ms/sample - loss: 5472.6368 - acc: 0.5415 - val_loss: 0.6899 - val_acc: 0.5586\n",
      "** epoch 15/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 44s 3ms/sample - loss: 5476.1872 - acc: 0.5415 - val_loss: 0.6900 - val_acc: 0.5586\n",
      "** epoch 16/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5475.4277 - acc: 0.5415 - val_loss: 0.6899 - val_acc: 0.5586\n",
      "** epoch 17/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5476.1618 - acc: 0.5415 - val_loss: 0.6900 - val_acc: 0.5586\n",
      "** epoch 18/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 48s 3ms/sample - loss: 5474.4451 - acc: 0.5415 - val_loss: 0.6899 - val_acc: 0.5586\n",
      "** epoch 19/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 50s 3ms/sample - loss: 5476.6275 - acc: 0.5415 - val_loss: 0.6897 - val_acc: 0.5586\n",
      "** epoch 20/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 50s 3ms/sample - loss: 5471.9748 - acc: 0.5415 - val_loss: 0.6900 - val_acc: 0.5586\n",
      "** epoch 21/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 52s 4ms/sample - loss: 5472.6042 - acc: 0.5415 - val_loss: 0.6893 - val_acc: 0.5586\n",
      "** epoch 22/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 53s 4ms/sample - loss: 5473.8855 - acc: 0.5415 - val_loss: 0.6893 - val_acc: 0.5586\n",
      "** epoch 23/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 58s 4ms/sample - loss: 5473.9313 - acc: 0.5415 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 24/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 54s 4ms/sample - loss: 5470.6885 - acc: 0.5415 - val_loss: 0.6897 - val_acc: 0.5586\n",
      "** epoch 25/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 55s 4ms/sample - loss: 5474.6941 - acc: 0.5415 - val_loss: 0.6897 - val_acc: 0.5586\n",
      "** epoch 26/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 56s 4ms/sample - loss: 5469.5007 - acc: 0.5415 - val_loss: 0.6893 - val_acc: 0.5586\n",
      "** epoch 27/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 48s 3ms/sample - loss: 5475.5745 - acc: 0.5415 - val_loss: 0.6895 - val_acc: 0.5586\n",
      "** epoch 28/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5475.2817 - acc: 0.5415 - val_loss: 0.6896 - val_acc: 0.5586\n",
      "** epoch 29/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5473.0140 - acc: 0.5415 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 30/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5473.8933 - acc: 0.5415 - val_loss: 0.6894 - val_acc: 0.5586\n",
      "** epoch 31/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5475.9345 - acc: 0.5415 - val_loss: 0.6894 - val_acc: 0.5586\n",
      "** epoch 32/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5474.8511 - acc: 0.5415 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 33/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5472.4818 - acc: 0.5415 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 34/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5471.0615 - acc: 0.5415 - val_loss: 0.6893 - val_acc: 0.5586\n",
      "** epoch 35/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5471.2753 - acc: 0.5415 - val_loss: 0.6893 - val_acc: 0.5586\n",
      "** epoch 36/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5474.1333 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 37/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5474.1607 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 38/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5473.0395 - acc: 0.5415 - val_loss: 0.6893 - val_acc: 0.5586\n",
      "** epoch 39/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5468.0503 - acc: 0.5415 - val_loss: 0.6894 - val_acc: 0.5586\n",
      "** epoch 40/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5470.9134 - acc: 0.5415 - val_loss: 0.6893 - val_acc: 0.5586\n",
      "** epoch 41/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5471.1052 - acc: 0.5415 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 42/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5470.3543 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 43/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5475.2169 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 44/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5472.3109 - acc: 0.5415 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 45/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 44s 3ms/sample - loss: 5469.3210 - acc: 0.5415 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 46/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5470.2789 - acc: 0.5415 - val_loss: 0.6894 - val_acc: 0.5586\n",
      "** epoch 47/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 44s 3ms/sample - loss: 5472.6313 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 48/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5473.9460 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 49/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5468.1494 - acc: 0.5415 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 50/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5472.7534 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 51/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5471.8604 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 52/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 44s 3ms/sample - loss: 5470.7121 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 53/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 44s 3ms/sample - loss: 5470.5055 - acc: 0.5415 - val_loss: 0.6894 - val_acc: 0.5586\n",
      "** epoch 54/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 44s 3ms/sample - loss: 5470.6171 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 55/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5470.6110 - acc: 0.5415 - val_loss: 0.6893 - val_acc: 0.5586\n",
      "** epoch 56/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5473.8168 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 57/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5469.7834 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 58/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5473.3077 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 59/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 45s 3ms/sample - loss: 5473.4462 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 60/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5470.6667 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 61/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5471.9809 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 62/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5473.1841 - acc: 0.5415 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 63/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5473.7633 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 64/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5471.3495 - acc: 0.5415 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 65/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5470.5721 - acc: 0.5415 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 66/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5470.6152 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 67/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 47s 3ms/sample - loss: 5470.6888 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 68/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 46s 3ms/sample - loss: 5468.1658 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 69/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 47s 3ms/sample - loss: 5471.1577 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 70/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 47s 3ms/sample - loss: 5471.5441 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 71/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 47s 3ms/sample - loss: 5472.3546 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 72/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 48s 3ms/sample - loss: 5470.6544 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 73/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 47s 3ms/sample - loss: 5473.1874 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 74/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 47s 3ms/sample - loss: 5467.8485 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 75/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 48s 3ms/sample - loss: 5471.9565 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 76/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 48s 3ms/sample - loss: 5469.9336 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 77/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 49s 3ms/sample - loss: 5470.6954 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 78/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 49s 3ms/sample - loss: 5470.4398 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 79/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 47s 3ms/sample - loss: 5468.9806 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 80/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 48s 3ms/sample - loss: 5471.1732 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 81/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 49s 3ms/sample - loss: 5471.9941 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 82/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 49s 3ms/sample - loss: 5467.4791 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 83/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14336/14336 [==============================] - 49s 3ms/sample - loss: 5472.1345 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 84/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 50s 3ms/sample - loss: 5468.0446 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 85/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 49s 3ms/sample - loss: 5470.8021 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 86/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 49s 3ms/sample - loss: 5468.4338 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 87/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 49s 3ms/sample - loss: 5471.0430 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 88/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 52s 4ms/sample - loss: 5472.4329 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 89/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 49s 3ms/sample - loss: 5472.0934 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 90/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 49s 3ms/sample - loss: 5474.1058 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 91/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 50s 3ms/sample - loss: 5469.3103 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 92/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 51s 4ms/sample - loss: 5470.2936 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 93/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 51s 4ms/sample - loss: 5471.7715 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 94/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 51s 4ms/sample - loss: 5471.8312 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 95/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 53s 4ms/sample - loss: 5469.3077 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 96/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 50s 4ms/sample - loss: 5468.6112 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 97/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 50s 3ms/sample - loss: 5469.9883 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 98/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 50s 3ms/sample - loss: 5470.5178 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 99/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 50s 3ms/sample - loss: 5467.8713 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 100/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 50s 3ms/sample - loss: 5471.9946 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 101/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 50s 4ms/sample - loss: 5469.6813 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 102/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 50s 3ms/sample - loss: 5468.5970 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 103/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 50s 4ms/sample - loss: 5470.8257 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 104/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 50s 4ms/sample - loss: 5469.6390 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 105/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 50s 4ms/sample - loss: 5469.8164 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 106/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 51s 4ms/sample - loss: 5471.0496 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 107/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 51s 4ms/sample - loss: 5473.8897 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 108/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 50s 4ms/sample - loss: 5469.1843 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 109/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 51s 4ms/sample - loss: 5469.3795 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 110/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 51s 4ms/sample - loss: 5470.9522 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 111/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 52s 4ms/sample - loss: 5470.2745 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 112/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 51s 4ms/sample - loss: 5466.3606 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 113/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 51s 4ms/sample - loss: 5470.7400 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 114/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 52s 4ms/sample - loss: 5470.3987 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 115/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 53s 4ms/sample - loss: 5471.6454 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 116/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 51s 4ms/sample - loss: 5472.2439 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 117/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 52s 4ms/sample - loss: 5472.3636 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 118/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 54s 4ms/sample - loss: 5472.5637 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 119/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 52s 4ms/sample - loss: 5471.6832 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 120/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 53s 4ms/sample - loss: 5469.3835 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 121/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 53s 4ms/sample - loss: 5469.8706 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 122/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 53s 4ms/sample - loss: 5471.2429 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 123/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 53s 4ms/sample - loss: 5469.9939 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 124/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14336/14336 [==============================] - 53s 4ms/sample - loss: 5468.9746 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 125/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 53s 4ms/sample - loss: 5471.0383 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 126/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 53s 4ms/sample - loss: 5470.8698 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 127/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 53s 4ms/sample - loss: 5471.7615 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 128/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 53s 4ms/sample - loss: 5466.6952 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 129/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 53s 4ms/sample - loss: 5468.3932 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 130/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 53s 4ms/sample - loss: 5469.6626 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 131/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 55s 4ms/sample - loss: 5468.8623 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 132/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 53s 4ms/sample - loss: 5469.1299 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 133/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 54s 4ms/sample - loss: 5470.3651 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 134/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 54s 4ms/sample - loss: 5471.9047 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 135/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 54s 4ms/sample - loss: 5469.8611 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 136/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 54s 4ms/sample - loss: 5467.7131 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 137/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 55s 4ms/sample - loss: 5473.3656 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 138/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 56s 4ms/sample - loss: 5468.9304 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 139/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 55s 4ms/sample - loss: 5471.2222 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 140/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 55s 4ms/sample - loss: 5470.1338 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 141/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 58s 4ms/sample - loss: 5469.1511 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 142/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 55s 4ms/sample - loss: 5468.3416 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 143/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 56s 4ms/sample - loss: 5468.0749 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 144/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 57s 4ms/sample - loss: 5472.1385 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 145/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 56s 4ms/sample - loss: 5468.7948 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 146/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 58s 4ms/sample - loss: 5471.9092 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 147/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 58s 4ms/sample - loss: 5472.0446 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 148/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 56s 4ms/sample - loss: 5466.1664 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 149/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 56s 4ms/sample - loss: 5468.3454 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 150/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 56s 4ms/sample - loss: 5470.2423 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 151/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 57s 4ms/sample - loss: 5470.1534 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 152/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 57s 4ms/sample - loss: 5471.9791 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 153/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 57s 4ms/sample - loss: 5469.5895 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 154/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 57s 4ms/sample - loss: 5466.4280 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 155/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 58s 4ms/sample - loss: 5470.7472 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 156/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 59s 4ms/sample - loss: 5467.2748 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 157/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 57s 4ms/sample - loss: 5470.4731 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 158/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 58s 4ms/sample - loss: 5472.8743 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 159/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 58s 4ms/sample - loss: 5469.4389 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 160/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 58s 4ms/sample - loss: 5470.1197 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 161/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 59s 4ms/sample - loss: 5470.8237 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 162/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 59s 4ms/sample - loss: 5467.6895 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 163/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 58s 4ms/sample - loss: 5467.0578 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 164/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 59s 4ms/sample - loss: 5471.3423 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 165/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14336/14336 [==============================] - 59s 4ms/sample - loss: 5470.0980 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 166/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 59s 4ms/sample - loss: 5467.4563 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 167/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 59s 4ms/sample - loss: 5470.5401 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 168/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 59s 4ms/sample - loss: 5469.5607 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 169/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 60s 4ms/sample - loss: 5472.0789 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 170/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 60s 4ms/sample - loss: 5472.7103 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 171/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 61s 4ms/sample - loss: 5469.6403 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 172/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 60s 4ms/sample - loss: 5469.2040 - acc: 0.5415 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 173/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 60s 4ms/sample - loss: 5469.9023 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 174/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 60s 4ms/sample - loss: 5473.5097 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 175/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 60s 4ms/sample - loss: 5470.5026 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 176/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 60s 4ms/sample - loss: 5469.2991 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 177/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 61s 4ms/sample - loss: 5467.4226 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 178/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 61s 4ms/sample - loss: 5468.7962 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 179/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 62s 4ms/sample - loss: 5467.6036 - acc: 0.5415 - val_loss: 0.6894 - val_acc: 0.5586\n",
      "** epoch 180/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 62s 4ms/sample - loss: 5470.0361 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 181/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 62s 4ms/sample - loss: 5470.8178 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 182/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 62s 4ms/sample - loss: 5469.7734 - acc: 0.5415 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 183/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 64s 4ms/sample - loss: 5470.1827 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 184/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 65s 5ms/sample - loss: 5469.4970 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 185/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 62s 4ms/sample - loss: 5469.4410 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 186/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 64s 4ms/sample - loss: 5469.4333 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 187/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 64s 4ms/sample - loss: 5470.9278 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 188/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 72s 5ms/sample - loss: 5468.2474 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 189/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 72s 5ms/sample - loss: 5469.2905 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 190/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 73s 5ms/sample - loss: 5468.4184 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 191/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 71s 5ms/sample - loss: 5469.4601 - acc: 0.5415 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 192/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 72s 5ms/sample - loss: 5469.0101 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 193/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 73s 5ms/sample - loss: 5467.6558 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 194/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 73s 5ms/sample - loss: 5467.8167 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 195/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 72s 5ms/sample - loss: 5468.4256 - acc: 0.5415 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 196/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 73s 5ms/sample - loss: 5468.4667 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 197/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 73s 5ms/sample - loss: 5468.4747 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 198/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 72s 5ms/sample - loss: 5468.3059 - acc: 0.5415 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 199/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 75s 5ms/sample - loss: 5468.5711 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 200/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 66s 5ms/sample - loss: 5468.5460 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 201/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 66s 5ms/sample - loss: 5472.2878 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 202/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 68s 5ms/sample - loss: 5467.4341 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 203/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 66s 5ms/sample - loss: 5469.0579 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 204/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 66s 5ms/sample - loss: 5468.9326 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 205/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 66s 5ms/sample - loss: 5470.7687 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 206/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14336/14336 [==============================] - 67s 5ms/sample - loss: 5469.0656 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 207/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 68s 5ms/sample - loss: 5468.1784 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 208/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 68s 5ms/sample - loss: 5466.2863 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 209/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 69s 5ms/sample - loss: 5467.7713 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 210/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 68s 5ms/sample - loss: 5468.4841 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 211/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 69s 5ms/sample - loss: 5472.3958 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 212/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 70s 5ms/sample - loss: 5470.5537 - acc: 0.5415 - val_loss: 0.6893 - val_acc: 0.5586\n",
      "** epoch 213/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 70s 5ms/sample - loss: 5468.7515 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 214/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 70s 5ms/sample - loss: 5469.7113 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 215/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 71s 5ms/sample - loss: 5469.6866 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 216/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 71s 5ms/sample - loss: 5470.7989 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 217/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 71s 5ms/sample - loss: 5470.8591 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 218/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 73s 5ms/sample - loss: 5466.8974 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 219/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 75s 5ms/sample - loss: 5469.5238 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 220/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 73s 5ms/sample - loss: 5470.6191 - acc: 0.5415 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 221/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 73s 5ms/sample - loss: 5470.2458 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 222/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 73s 5ms/sample - loss: 5468.1118 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 223/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 74s 5ms/sample - loss: 5467.9595 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 224/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 74s 5ms/sample - loss: 5469.2126 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 225/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 75s 5ms/sample - loss: 5467.9034 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 226/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 73s 5ms/sample - loss: 5469.5186 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 227/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 74s 5ms/sample - loss: 5472.1762 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 228/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 75s 5ms/sample - loss: 5467.5302 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 229/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 85s 6ms/sample - loss: 5468.9225 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 230/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 79s 6ms/sample - loss: 5469.5732 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 231/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 77s 5ms/sample - loss: 5470.4387 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 232/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 79s 6ms/sample - loss: 5471.1874 - acc: 0.5415 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 233/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 77s 5ms/sample - loss: 5471.5160 - acc: 0.5415 - val_loss: 0.6880 - val_acc: 0.5586\n",
      "** epoch 234/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 78s 5ms/sample - loss: 5468.3413 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 235/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 77s 5ms/sample - loss: 5469.3500 - acc: 0.5415 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 236/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 77s 5ms/sample - loss: 5469.4936 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 237/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 77s 5ms/sample - loss: 5467.1879 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 238/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 77s 5ms/sample - loss: 5468.5790 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 239/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 75s 5ms/sample - loss: 5468.8659 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 240/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 74s 5ms/sample - loss: 5470.6230 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 241/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 75s 5ms/sample - loss: 5469.1095 - acc: 0.5415 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 242/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 74s 5ms/sample - loss: 5470.1874 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 243/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 73s 5ms/sample - loss: 5468.0391 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 244/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 75s 5ms/sample - loss: 5468.3862 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 245/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 74s 5ms/sample - loss: 5467.9212 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 246/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 73s 5ms/sample - loss: 5468.2946 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 247/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14336/14336 [==============================] - 73s 5ms/sample - loss: 5468.2556 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 248/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 74s 5ms/sample - loss: 5469.2067 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 249/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 74s 5ms/sample - loss: 5471.3390 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 250/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 79s 5ms/sample - loss: 5469.8565 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 251/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 75s 5ms/sample - loss: 5467.5550 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 252/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 75s 5ms/sample - loss: 5468.3907 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 253/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 76s 5ms/sample - loss: 5470.4640 - acc: 0.5415 - val_loss: 0.6893 - val_acc: 0.5586\n",
      "** epoch 254/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 75s 5ms/sample - loss: 5469.4199 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 255/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 75s 5ms/sample - loss: 5468.2959 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 256/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 76s 5ms/sample - loss: 5468.4343 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 257/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 76s 5ms/sample - loss: 5467.0870 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 258/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 77s 5ms/sample - loss: 5469.1869 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 259/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 77s 5ms/sample - loss: 5468.5068 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 260/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 77s 5ms/sample - loss: 5468.2103 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 261/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 78s 5ms/sample - loss: 5469.4820 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 262/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 77s 5ms/sample - loss: 5468.0951 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 263/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 78s 5ms/sample - loss: 5467.0311 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 264/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 78s 5ms/sample - loss: 5470.3873 - acc: 0.5415 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 265/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 81s 6ms/sample - loss: 5468.9274 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 266/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 78s 5ms/sample - loss: 5471.0566 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 267/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 78s 5ms/sample - loss: 5470.4831 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 268/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 80s 6ms/sample - loss: 5467.0148 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 269/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 79s 6ms/sample - loss: 5468.9444 - acc: 0.5415 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 270/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 80s 6ms/sample - loss: 5468.7422 - acc: 0.5416 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 271/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 82s 6ms/sample - loss: 5469.4744 - acc: 0.5415 - val_loss: 0.6895 - val_acc: 0.5586\n",
      "** epoch 272/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 81s 6ms/sample - loss: 5470.4765 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 273/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 80s 6ms/sample - loss: 5467.4695 - acc: 0.5415 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 274/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 80s 6ms/sample - loss: 5468.6504 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 275/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 81s 6ms/sample - loss: 5466.7803 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 276/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 82s 6ms/sample - loss: 5470.5089 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 277/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 81s 6ms/sample - loss: 5470.3585 - acc: 0.5415 - val_loss: 0.6883 - val_acc: 0.5586\n",
      "** epoch 278/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 81s 6ms/sample - loss: 5468.2515 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 279/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 90s 6ms/sample - loss: 5469.9126 - acc: 0.5415 - val_loss: 0.6893 - val_acc: 0.5586\n",
      "** epoch 280/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 81s 6ms/sample - loss: 5468.5711 - acc: 0.5415 - val_loss: 0.6893 - val_acc: 0.5586\n",
      "** epoch 281/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 84s 6ms/sample - loss: 5468.7414 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 282/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 84s 6ms/sample - loss: 5471.5631 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 283/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 86s 6ms/sample - loss: 5469.6306 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 284/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 84s 6ms/sample - loss: 5467.5974 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 285/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 110s 8ms/sample - loss: 5467.5388 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 286/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 83s 6ms/sample - loss: 5471.3671 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 287/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 83s 6ms/sample - loss: 5467.4558 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 288/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14336/14336 [==============================] - 82s 6ms/sample - loss: 5468.9750 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 289/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 82s 6ms/sample - loss: 5466.1315 - acc: 0.5415 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 290/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 85s 6ms/sample - loss: 5468.9210 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 291/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 82s 6ms/sample - loss: 5468.6409 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 292/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 90s 6ms/sample - loss: 5468.9616 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 293/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 85s 6ms/sample - loss: 5469.1794 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 294/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 87s 6ms/sample - loss: 5470.5639 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 295/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 88s 6ms/sample - loss: 5468.1984 - acc: 0.5415 - val_loss: 0.6883 - val_acc: 0.5586\n",
      "** epoch 296/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 88s 6ms/sample - loss: 5470.9248 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 297/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 86s 6ms/sample - loss: 5468.5315 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 298/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 90s 6ms/sample - loss: 5467.8573 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 299/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 92s 6ms/sample - loss: 5464.8344 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 300/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 97s 7ms/sample - loss: 5469.5388 - acc: 0.5415 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 301/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 93s 7ms/sample - loss: 5467.4572 - acc: 0.5415 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 302/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 99s 7ms/sample - loss: 5467.5826 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 303/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 109s 8ms/sample - loss: 5467.9822 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 304/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 101s 7ms/sample - loss: 5468.6917 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 305/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 99s 7ms/sample - loss: 5467.8472 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 306/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 104s 7ms/sample - loss: 5470.2963 - acc: 0.5416 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 307/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 103s 7ms/sample - loss: 5466.7155 - acc: 0.5416 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 308/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 104s 7ms/sample - loss: 5470.2956 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 309/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 106s 7ms/sample - loss: 5468.0841 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 310/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 107s 7ms/sample - loss: 5467.7842 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 311/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 105s 7ms/sample - loss: 5468.6366 - acc: 0.5415 - val_loss: 0.6893 - val_acc: 0.5586\n",
      "** epoch 312/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 108s 8ms/sample - loss: 5465.6338 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 313/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 104s 7ms/sample - loss: 5467.6569 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 314/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 111s 8ms/sample - loss: 5469.3688 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 315/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 105s 7ms/sample - loss: 5469.8074 - acc: 0.5416 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 316/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 115s 8ms/sample - loss: 5468.3458 - acc: 0.5416 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 317/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 108s 8ms/sample - loss: 5467.0548 - acc: 0.5416 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 318/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 106s 7ms/sample - loss: 5468.1776 - acc: 0.5416 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 319/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 113s 8ms/sample - loss: 5467.3607 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 320/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 108s 8ms/sample - loss: 5466.7080 - acc: 0.5416 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 321/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 114s 8ms/sample - loss: 5468.5157 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 322/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 114s 8ms/sample - loss: 5468.4669 - acc: 0.5416 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 323/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 122s 9ms/sample - loss: 5465.6031 - acc: 0.5416 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 324/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 114s 8ms/sample - loss: 5469.1750 - acc: 0.5415 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 325/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 121s 8ms/sample - loss: 5469.5963 - acc: 0.5414 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 326/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 111s 8ms/sample - loss: 5469.4825 - acc: 0.5416 - val_loss: 0.6892 - val_acc: 0.5586\n",
      "** epoch 327/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 114s 8ms/sample - loss: 5468.6579 - acc: 0.5416 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 328/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 115s 8ms/sample - loss: 5465.8111 - acc: 0.5416 - val_loss: 0.6891 - val_acc: 0.5586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** epoch 329/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 115s 8ms/sample - loss: 5469.1917 - acc: 0.5416 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 330/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 106s 7ms/sample - loss: 5471.2842 - acc: 0.5416 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 331/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 119s 8ms/sample - loss: 5467.7375 - acc: 0.5416 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 332/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 110s 8ms/sample - loss: 5466.3650 - acc: 0.5416 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 333/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 114s 8ms/sample - loss: 5469.5462 - acc: 0.5415 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 334/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 119s 8ms/sample - loss: 5468.9661 - acc: 0.5416 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 335/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 113s 8ms/sample - loss: 5467.6736 - acc: 0.5417 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 336/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 122s 8ms/sample - loss: 5468.9242 - acc: 0.5416 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 337/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 114s 8ms/sample - loss: 5466.3429 - acc: 0.5414 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 338/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 111s 8ms/sample - loss: 5468.4429 - acc: 0.5416 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 339/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 116s 8ms/sample - loss: 5470.8830 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 340/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 133s 9ms/sample - loss: 5468.5538 - acc: 0.5417 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 341/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 118s 8ms/sample - loss: 5467.8215 - acc: 0.5417 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 342/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 129s 9ms/sample - loss: 5466.6721 - acc: 0.5416 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 343/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 128s 9ms/sample - loss: 5469.7811 - acc: 0.5415 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 344/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 121s 8ms/sample - loss: 5468.4733 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 345/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 142s 10ms/sample - loss: 5464.5121 - acc: 0.5416 - val_loss: 0.6891 - val_acc: 0.5586\n",
      "** epoch 346/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 126s 9ms/sample - loss: 5468.9871 - acc: 0.5416 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 347/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 129s 9ms/sample - loss: 5468.3060 - acc: 0.5416 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 348/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 134s 9ms/sample - loss: 5469.1925 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 349/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 129s 9ms/sample - loss: 5468.6514 - acc: 0.5416 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 350/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 130s 9ms/sample - loss: 5468.1345 - acc: 0.5418 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 351/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 138s 10ms/sample - loss: 5468.5346 - acc: 0.5416 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 352/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 141s 10ms/sample - loss: 5469.0677 - acc: 0.5416 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 353/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 140s 10ms/sample - loss: 5467.7316 - acc: 0.5416 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 354/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 138s 10ms/sample - loss: 5468.9771 - acc: 0.5415 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 355/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 138s 10ms/sample - loss: 5470.1960 - acc: 0.5417 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 356/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 118s 8ms/sample - loss: 5469.0980 - acc: 0.5416 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 357/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 113s 8ms/sample - loss: 5469.1875 - acc: 0.5415 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 358/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 116s 8ms/sample - loss: 5466.4885 - acc: 0.5418 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 359/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 122s 9ms/sample - loss: 5467.3268 - acc: 0.5415 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 360/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 115s 8ms/sample - loss: 5467.2235 - acc: 0.5417 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 361/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 123s 9ms/sample - loss: 5466.5005 - acc: 0.5416 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 362/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 115s 8ms/sample - loss: 5467.5891 - acc: 0.5417 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 363/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 121s 8ms/sample - loss: 5466.7544 - acc: 0.5418 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 364/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 122s 9ms/sample - loss: 5466.3953 - acc: 0.5420 - val_loss: 0.6883 - val_acc: 0.5586\n",
      "** epoch 365/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 136s 9ms/sample - loss: 5470.5308 - acc: 0.5418 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 366/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 126s 9ms/sample - loss: 5470.2116 - acc: 0.5419 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 367/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 117s 8ms/sample - loss: 5470.2852 - acc: 0.5419 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 368/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 131s 9ms/sample - loss: 5468.2863 - acc: 0.5417 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 369/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14336/14336 [==============================] - 125s 9ms/sample - loss: 5465.6715 - acc: 0.5418 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 370/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 125s 9ms/sample - loss: 5467.0821 - acc: 0.5419 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 371/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 123s 9ms/sample - loss: 5467.1361 - acc: 0.5419 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 372/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 121s 8ms/sample - loss: 5468.1046 - acc: 0.5415 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 373/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 146s 10ms/sample - loss: 5469.6069 - acc: 0.5418 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 374/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 133s 9ms/sample - loss: 5466.6440 - acc: 0.5416 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 375/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 135s 9ms/sample - loss: 5467.5712 - acc: 0.5416 - val_loss: 0.6890 - val_acc: 0.5586\n",
      "** epoch 376/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 134s 9ms/sample - loss: 5467.3108 - acc: 0.5418 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 377/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 149s 10ms/sample - loss: 5466.9611 - acc: 0.5418 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 378/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 135s 9ms/sample - loss: 5467.7043 - acc: 0.5419 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 379/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 143s 10ms/sample - loss: 5468.1706 - acc: 0.5415 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 380/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 138s 10ms/sample - loss: 5466.1361 - acc: 0.5417 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 381/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 138s 10ms/sample - loss: 5468.1359 - acc: 0.5416 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 382/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 139s 10ms/sample - loss: 5466.9808 - acc: 0.5419 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 383/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 139s 10ms/sample - loss: 5467.5740 - acc: 0.5418 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 384/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 137s 10ms/sample - loss: 5467.8980 - acc: 0.5418 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 385/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 148s 10ms/sample - loss: 5466.9694 - acc: 0.5416 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 386/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 145s 10ms/sample - loss: 5467.3806 - acc: 0.5419 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 387/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 144s 10ms/sample - loss: 5469.4623 - acc: 0.5421 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 388/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 149s 10ms/sample - loss: 5466.4929 - acc: 0.5417 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 389/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 161s 11ms/sample - loss: 5466.6010 - acc: 0.5419 - val_loss: 0.6883 - val_acc: 0.5586\n",
      "** epoch 390/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 148s 10ms/sample - loss: 5468.3427 - acc: 0.5418 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 391/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 158s 11ms/sample - loss: 5467.6030 - acc: 0.5419 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 392/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 145s 10ms/sample - loss: 5464.6133 - acc: 0.5421 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 393/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 156s 11ms/sample - loss: 5466.2996 - acc: 0.5420 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 394/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 153s 11ms/sample - loss: 5469.3024 - acc: 0.5419 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 395/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 141s 10ms/sample - loss: 5466.1101 - acc: 0.5419 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "** epoch 396/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 151s 10ms/sample - loss: 5467.2258 - acc: 0.5420 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 397/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 156s 11ms/sample - loss: 5465.0784 - acc: 0.5421 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 398/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 145s 10ms/sample - loss: 5467.3234 - acc: 0.5421 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 399/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 172s 12ms/sample - loss: 5466.0031 - acc: 0.5421 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 400/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 167s 12ms/sample - loss: 5467.7192 - acc: 0.5423 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 401/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 151s 11ms/sample - loss: 5467.8606 - acc: 0.5422 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 402/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 166s 12ms/sample - loss: 5469.6444 - acc: 0.5421 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 403/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 150s 10ms/sample - loss: 5468.0235 - acc: 0.5423 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 404/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 151s 11ms/sample - loss: 5466.0203 - acc: 0.5419 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 405/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 166s 12ms/sample - loss: 5464.9476 - acc: 0.5422 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 406/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 170s 12ms/sample - loss: 5467.7077 - acc: 0.5418 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 407/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 172s 12ms/sample - loss: 5469.0686 - acc: 0.5420 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 408/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 169s 12ms/sample - loss: 5466.9539 - acc: 0.5421 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 409/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14336/14336 [==============================] - 156s 11ms/sample - loss: 5466.1854 - acc: 0.5423 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 410/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 167s 12ms/sample - loss: 5465.5246 - acc: 0.5421 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 411/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 173s 12ms/sample - loss: 5469.9461 - acc: 0.5423 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 412/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 168s 12ms/sample - loss: 5466.7349 - acc: 0.5422 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 413/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 179s 12ms/sample - loss: 5467.0814 - acc: 0.5422 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 414/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 168s 12ms/sample - loss: 5466.9320 - acc: 0.5426 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 415/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 176s 12ms/sample - loss: 5469.0370 - acc: 0.5422 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 416/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 191s 13ms/sample - loss: 5466.7241 - acc: 0.5423 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 417/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 178s 12ms/sample - loss: 5467.4457 - acc: 0.5421 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 418/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 182s 13ms/sample - loss: 5467.5479 - acc: 0.5423 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 419/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 180s 13ms/sample - loss: 5467.6389 - acc: 0.5417 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 420/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 185s 13ms/sample - loss: 5466.0961 - acc: 0.5421 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 421/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 169s 12ms/sample - loss: 5467.0319 - acc: 0.5422 - val_loss: 0.6889 - val_acc: 0.5586\n",
      "** epoch 422/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 192s 13ms/sample - loss: 5465.6704 - acc: 0.5423 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 423/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 189s 13ms/sample - loss: 5469.0602 - acc: 0.5424 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 424/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 198s 14ms/sample - loss: 5467.3701 - acc: 0.5421 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 425/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 195s 14ms/sample - loss: 5467.8325 - acc: 0.5423 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 426/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 188s 13ms/sample - loss: 5466.5207 - acc: 0.5421 - val_loss: 0.6880 - val_acc: 0.5586\n",
      "** epoch 427/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 211s 15ms/sample - loss: 5465.6352 - acc: 0.5423 - val_loss: 0.6883 - val_acc: 0.5586\n",
      "** epoch 428/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 202s 14ms/sample - loss: 5466.4607 - acc: 0.5421 - val_loss: 0.6880 - val_acc: 0.5586\n",
      "** epoch 429/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 204s 14ms/sample - loss: 5466.0676 - acc: 0.5421 - val_loss: 0.6880 - val_acc: 0.5586\n",
      "** epoch 430/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 216s 15ms/sample - loss: 5468.1650 - acc: 0.5420 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 431/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 203s 14ms/sample - loss: 5467.1981 - acc: 0.5422 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 432/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 208s 15ms/sample - loss: 5467.4161 - acc: 0.5421 - val_loss: 0.6883 - val_acc: 0.5586\n",
      "** epoch 433/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 219s 15ms/sample - loss: 5464.9089 - acc: 0.5421 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 434/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 205s 14ms/sample - loss: 5465.7461 - acc: 0.5422 - val_loss: 0.6877 - val_acc: 0.5586\n",
      "** epoch 435/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 219s 15ms/sample - loss: 5469.0689 - acc: 0.5420 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 436/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 214s 15ms/sample - loss: 5466.5044 - acc: 0.5427 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 437/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 218s 15ms/sample - loss: 5464.4111 - acc: 0.5428 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 438/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 219s 15ms/sample - loss: 5467.7215 - acc: 0.5422 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 439/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 214s 15ms/sample - loss: 5466.0908 - acc: 0.5421 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 440/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 218s 15ms/sample - loss: 5466.4903 - acc: 0.5426 - val_loss: 0.6879 - val_acc: 0.5586\n",
      "** epoch 441/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 235s 16ms/sample - loss: 5469.2500 - acc: 0.5426 - val_loss: 0.6883 - val_acc: 0.5586\n",
      "** epoch 442/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 301s 21ms/sample - loss: 5465.7967 - acc: 0.5428 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 443/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 179s 12ms/sample - loss: 5468.5639 - acc: 0.5418 - val_loss: 0.6880 - val_acc: 0.5586\n",
      "** epoch 444/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 191s 13ms/sample - loss: 5466.1028 - acc: 0.5421 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 445/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 179s 13ms/sample - loss: 5465.0018 - acc: 0.5422 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 446/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 212s 15ms/sample - loss: 5466.8237 - acc: 0.5421 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 447/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 173s 12ms/sample - loss: 5465.9882 - acc: 0.5422 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 448/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 175s 12ms/sample - loss: 5468.2432 - acc: 0.5420 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 449/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14336/14336 [==============================] - 164s 11ms/sample - loss: 5467.3550 - acc: 0.5425 - val_loss: 0.6883 - val_acc: 0.5586\n",
      "** epoch 450/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 178s 12ms/sample - loss: 5467.4823 - acc: 0.5422 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 451/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 188s 13ms/sample - loss: 5465.3444 - acc: 0.5424 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "** epoch 452/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 165s 11ms/sample - loss: 5466.5349 - acc: 0.5418 - val_loss: 0.6885 - val_acc: 0.5586\n",
      "** epoch 453/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 177s 12ms/sample - loss: 5466.8839 - acc: 0.5419 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 454/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 177s 12ms/sample - loss: 5464.2461 - acc: 0.5423 - val_loss: 0.6886 - val_acc: 0.5586\n",
      "** epoch 455/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 181s 13ms/sample - loss: 5466.2311 - acc: 0.5425 - val_loss: 0.6879 - val_acc: 0.5586\n",
      "** epoch 456/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 181s 13ms/sample - loss: 5466.2784 - acc: 0.5421 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 457/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 173s 12ms/sample - loss: 5465.8933 - acc: 0.5423 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 458/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 174s 12ms/sample - loss: 5466.8789 - acc: 0.5421 - val_loss: 0.6883 - val_acc: 0.5586\n",
      "** epoch 459/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 181s 13ms/sample - loss: 5463.6468 - acc: 0.5421 - val_loss: 0.6883 - val_acc: 0.5586\n",
      "** epoch 460/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 174s 12ms/sample - loss: 5465.7538 - acc: 0.5425 - val_loss: 0.6884 - val_acc: 0.5586\n",
      "** epoch 461/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 188s 13ms/sample - loss: 5466.6430 - acc: 0.5423 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 462/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 187s 13ms/sample - loss: 5469.1330 - acc: 0.5424 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 463/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 182s 13ms/sample - loss: 5466.6724 - acc: 0.5419 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 464/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 187s 13ms/sample - loss: 5466.7804 - acc: 0.5426 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 465/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 196s 14ms/sample - loss: 5464.8394 - acc: 0.5421 - val_loss: 0.6883 - val_acc: 0.5586\n",
      "** epoch 466/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 199s 14ms/sample - loss: 5463.3555 - acc: 0.5426 - val_loss: 0.6878 - val_acc: 0.5586\n",
      "** epoch 467/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 199s 14ms/sample - loss: 5462.9879 - acc: 0.5431 - val_loss: 0.6880 - val_acc: 0.5578\n",
      "** epoch 468/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 192s 13ms/sample - loss: 5466.9691 - acc: 0.5421 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 469/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 197s 14ms/sample - loss: 5467.6663 - acc: 0.5421 - val_loss: 0.6880 - val_acc: 0.5586\n",
      "** epoch 470/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 190s 13ms/sample - loss: 5464.3300 - acc: 0.5423 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 471/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 201s 14ms/sample - loss: 5464.3621 - acc: 0.5421 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 472/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 181s 13ms/sample - loss: 5465.1599 - acc: 0.5423 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 473/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 205s 14ms/sample - loss: 5463.8043 - acc: 0.5426 - val_loss: 0.6880 - val_acc: 0.5586\n",
      "** epoch 474/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 206s 14ms/sample - loss: 5463.4833 - acc: 0.5421 - val_loss: 0.6879 - val_acc: 0.5586\n",
      "** epoch 475/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 207s 14ms/sample - loss: 5468.5562 - acc: 0.5423 - val_loss: 0.6877 - val_acc: 0.5586\n",
      "** epoch 476/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 212s 15ms/sample - loss: 5468.3652 - acc: 0.5421 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 477/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 198s 14ms/sample - loss: 5467.8136 - acc: 0.5423 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 478/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 204s 14ms/sample - loss: 5464.9557 - acc: 0.5424 - val_loss: 0.6883 - val_acc: 0.5586\n",
      "** epoch 479/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 211s 15ms/sample - loss: 5464.1820 - acc: 0.5419 - val_loss: 0.6878 - val_acc: 0.5586\n",
      "** epoch 480/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 205s 14ms/sample - loss: 5462.5148 - acc: 0.5424 - val_loss: 0.6882 - val_acc: 0.5586\n",
      "** epoch 481/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 222s 16ms/sample - loss: 5464.4307 - acc: 0.5420 - val_loss: 0.6880 - val_acc: 0.5586\n",
      "** epoch 482/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 222s 15ms/sample - loss: 5467.6922 - acc: 0.5421 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 483/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 225s 16ms/sample - loss: 5463.2823 - acc: 0.5423 - val_loss: 0.6880 - val_acc: 0.5586\n",
      "** epoch 484/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 226s 16ms/sample - loss: 5465.7835 - acc: 0.5426 - val_loss: 0.6883 - val_acc: 0.5586\n",
      "** epoch 485/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 225s 16ms/sample - loss: 5466.4894 - acc: 0.5426 - val_loss: 0.6878 - val_acc: 0.5586\n",
      "** epoch 486/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 225s 16ms/sample - loss: 5465.4043 - acc: 0.5419 - val_loss: 0.6877 - val_acc: 0.5586\n",
      "** epoch 487/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 216s 15ms/sample - loss: 5464.3423 - acc: 0.5423 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 488/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 214s 15ms/sample - loss: 5465.5839 - acc: 0.5421 - val_loss: 0.6879 - val_acc: 0.5586\n",
      "** epoch 489/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14336/14336 [==============================] - 218s 15ms/sample - loss: 5466.5176 - acc: 0.5430 - val_loss: 0.6877 - val_acc: 0.5586\n",
      "** epoch 490/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 232s 16ms/sample - loss: 5464.5127 - acc: 0.5423 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 491/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 241s 17ms/sample - loss: 5464.5465 - acc: 0.5425 - val_loss: 0.6879 - val_acc: 0.5586\n",
      "** epoch 492/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 229s 16ms/sample - loss: 5464.4290 - acc: 0.5423 - val_loss: 0.6879 - val_acc: 0.5586\n",
      "** epoch 493/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 230s 16ms/sample - loss: 5462.0542 - acc: 0.5423 - val_loss: 0.6877 - val_acc: 0.5586\n",
      "** epoch 494/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 242s 17ms/sample - loss: 5466.1544 - acc: 0.5422 - val_loss: 0.6880 - val_acc: 0.5586\n",
      "** epoch 495/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 243s 17ms/sample - loss: 5464.9897 - acc: 0.5427 - val_loss: 0.6877 - val_acc: 0.5586\n",
      "** epoch 496/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 242s 17ms/sample - loss: 5464.8264 - acc: 0.5426 - val_loss: 0.6879 - val_acc: 0.5586\n",
      "** epoch 497/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 264s 18ms/sample - loss: 5463.4621 - acc: 0.5421 - val_loss: 0.6878 - val_acc: 0.5586\n",
      "** epoch 498/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 260s 18ms/sample - loss: 5463.1220 - acc: 0.5426 - val_loss: 0.6878 - val_acc: 0.5586\n",
      "** epoch 499/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 260s 18ms/sample - loss: 5466.9436 - acc: 0.5423 - val_loss: 0.6874 - val_acc: 0.5586\n",
      "** epoch 500/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 272s 19ms/sample - loss: 5463.3402 - acc: 0.5431 - val_loss: 0.6880 - val_acc: 0.5586\n",
      "** epoch 501/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 273s 19ms/sample - loss: 5464.7438 - acc: 0.5423 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 502/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 277s 19ms/sample - loss: 5463.9418 - acc: 0.5425 - val_loss: 0.6881 - val_acc: 0.5586\n",
      "** epoch 503/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 276s 19ms/sample - loss: 5462.1466 - acc: 0.5426 - val_loss: 0.6877 - val_acc: 0.5586\n",
      "** epoch 504/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 286s 20ms/sample - loss: 5465.4126 - acc: 0.5422 - val_loss: 0.6877 - val_acc: 0.5586\n",
      "** epoch 505/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 287s 20ms/sample - loss: 5463.8950 - acc: 0.5430 - val_loss: 0.6878 - val_acc: 0.5586\n",
      "** epoch 506/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 270s 19ms/sample - loss: 5459.5994 - acc: 0.5427 - val_loss: 0.6880 - val_acc: 0.5586\n",
      "** epoch 507/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 290s 20ms/sample - loss: 5466.6217 - acc: 0.5425 - val_loss: 0.6878 - val_acc: 0.5586\n",
      "** epoch 508/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 276s 19ms/sample - loss: 5462.9187 - acc: 0.5426 - val_loss: 0.6878 - val_acc: 0.5586\n",
      "** epoch 509/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 277s 19ms/sample - loss: 5464.2176 - acc: 0.5424 - val_loss: 0.6877 - val_acc: 0.5586\n",
      "** epoch 510/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 263s 18ms/sample - loss: 5462.2870 - acc: 0.5425 - val_loss: 0.6875 - val_acc: 0.5586\n",
      "** epoch 511/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 287s 20ms/sample - loss: 5464.0536 - acc: 0.5426 - val_loss: 0.6877 - val_acc: 0.5586\n",
      "** epoch 512/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 270s 19ms/sample - loss: 5460.9933 - acc: 0.5428 - val_loss: 0.6876 - val_acc: 0.5586\n",
      "** epoch 513/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 284s 20ms/sample - loss: 5466.7149 - acc: 0.5425 - val_loss: 0.6878 - val_acc: 0.5586\n",
      "** epoch 514/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 289s 20ms/sample - loss: 5465.1349 - acc: 0.5423 - val_loss: 0.6879 - val_acc: 0.5586\n",
      "** epoch 515/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 315s 22ms/sample - loss: 5463.3183 - acc: 0.5430 - val_loss: 0.6876 - val_acc: 0.5586\n",
      "** epoch 516/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 278s 19ms/sample - loss: 5463.4041 - acc: 0.5426 - val_loss: 0.6877 - val_acc: 0.5586\n",
      "** epoch 517/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 280s 20ms/sample - loss: 5462.4614 - acc: 0.5423 - val_loss: 0.6878 - val_acc: 0.5586\n",
      "** epoch 518/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 284s 20ms/sample - loss: 5464.7654 - acc: 0.5426 - val_loss: 0.6877 - val_acc: 0.5586\n",
      "** epoch 519/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 284s 20ms/sample - loss: 5461.8154 - acc: 0.5428 - val_loss: 0.6877 - val_acc: 0.5586\n",
      "** epoch 520/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 284s 20ms/sample - loss: 5464.8569 - acc: 0.5430 - val_loss: 0.6878 - val_acc: 0.5586\n",
      "** epoch 521/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 308s 21ms/sample - loss: 5463.1468 - acc: 0.5426 - val_loss: 0.6878 - val_acc: 0.5586\n",
      "** epoch 522/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 289s 20ms/sample - loss: 5463.0543 - acc: 0.5427 - val_loss: 0.6877 - val_acc: 0.5586\n",
      "** epoch 523/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n",
      "14336/14336 [==============================] - 306s 21ms/sample - loss: 5462.5154 - acc: 0.5423 - val_loss: 0.6875 - val_acc: 0.5586\n",
      "** epoch 524/6000 **\n",
      "Train on 14336 samples, validate on 1280 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compiling Optimizer\n",
    "rmsprop = RMSprop(lr=lr, rho=0.9, epsilon=None, decay=0.0)\n",
    "lstm.compile(loss=BinaryCrossentropy(), optimizer=rmsprop, \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# loss arrays\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "counter = 1\n",
    "\n",
    "for n in range(n_epochs):\n",
    "    print('** epoch {}/{} **'.format(counter, n_epochs))\n",
    "\n",
    "    history = lstm.fit(x=X_train, y=y_train, epochs=1, validation_data=(X_test, y_test),\n",
    "                       batch_size=batch_size, shuffle=False, callbacks=callbacks,\n",
    "                      class_weight=class_weights,\n",
    "                      use_multiprocessing=True)\n",
    "\n",
    "    # Append the list to follow the evolution of loss on train and test sets\n",
    "    train_loss_list.append(history.history['loss'][0])\n",
    "    train_acc_list.append(history.history['acc'][0])\n",
    "    \n",
    "    test_loss_list.append(history.history['val_loss'][0])\n",
    "    test_acc_list.append(history.history['val_acc'][0])\n",
    "\n",
    "    # Reset the cell states (required for stateful)\n",
    "    lstm.reset_states()\n",
    "\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the errors\n",
    "fig, ax = plt.subplots(nrows=4)\n",
    "_ = ax[0].plot(range(1, counter), train_loss_list)\n",
    "_ = ax[0].set_title('Binary Crossentropy Loss on train set')\n",
    "\n",
    "_ = ax[1].plot(range(1, counter), train_acc_list)\n",
    "_ = ax[1].set_title('Accuracy Loss on train set')\n",
    "\n",
    "_ = ax[2].plot(range(1, counter), test_loss_list)\n",
    "_ = ax[2].set_title('Binary Crossentropy Loss on test set')\n",
    "\n",
    "_ = ax[3].plot(range(1, counter), test_acc_list)\n",
    "_ = ax[3].set_title('Accuracy Loss on test set')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = os.path.join(os.path.abspath('../'), 'Trained/BTC_{}ep.h5'.format(n_epochs))\n",
    "lstm.save(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict n validation set\n",
    "y_pred = lstm.predict(X_val)\n",
    "print(y_val)\n",
    "print(y_pred)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "ConfusionMatrixDisplay(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "lstm = load_model(model_path)\n",
    "\n",
    "# Resume training\n",
    "n_epochs_resume = 1000\n",
    "\n",
    "for n in range(n_epochs_resume):\n",
    "    print('epoch {}/{} **'.format(counter, n_epochs_resume))\n",
    "\n",
    "    history = lstm.fit(x=X_train, y=y_train, epochs=1, validation_data=(X_test, y_test),\n",
    "                       batch_size=batch_size, shuffle=False, callbacks=callbacks,\n",
    "                      class_weight=class_weights,\n",
    "                      use_multiprocessing=True)\n",
    "\n",
    "    # Append the list to follow the evolution of loss on train and test sets\n",
    "    train_loss_list.append(history.history['loss'][0])\n",
    "    train_acc_list.append(history.history['accuracy'][0])\n",
    "    \n",
    "    test_loss_list.append(history.history['val_loss'][0])\n",
    "    test_acc_list.append(history.history['val_accuracy'][0])\n",
    "\n",
    "\n",
    "    # Reset the cell states (required for stateful)\n",
    "    lstm.reset_states()\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the errors\n",
    "fig, ax = plt.subplots(nrows=4)\n",
    "_ = ax[0].plot(range(1, counter), train_loss_list)\n",
    "_ = ax[0].set_title('Binary Crossentropy Loss on train set')\n",
    "\n",
    "_ = ax[1].plot(range(1, counter), train_acc_list)\n",
    "_ = ax[1].set_title('Accuracy Loss on train set')\n",
    "\n",
    "_ = ax[2].plot(range(1, counter), test_loss_list)\n",
    "_ = ax[2].set_title('Binary Crossentropy Loss on test set')\n",
    "\n",
    "_ = ax[3].plot(range(1, counter), test_acc_list)\n",
    "_ = ax[3].set_title('Accuracy Loss on test set')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = 'BTC_{}ep.h5'.format(n_epochs+n_epochs_resume)\n",
    "lstm.save(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "lstm = load_model('BTC_2000ep.h5')\n",
    "counter = 2000\n",
    "\n",
    "# Resume training\n",
    "n_epochs_resume = 1000\n",
    "\n",
    "for n in range(n_epochs_resume):\n",
    "    print('epoch {}/{} **'.format(counter, n_epochs_resume))\n",
    "\n",
    "    history = lstm.fit(x=X_train, y=y_train, epochs=1, validation_data=(X_test, y_test),\n",
    "                       batch_size=batch_size, shuffle=False, callbacks=callbacks,\n",
    "                      class_weight=class_weights,\n",
    "                      use_multiprocessing=True)\n",
    "\n",
    "    # Append the list to follow the evolution of loss on train and test sets\n",
    "    train_loss_list.append(history.history['loss'][0])\n",
    "    train_acc_list.append(history.history['accuracy'][0])\n",
    "    \n",
    "    test_loss_list.append(history.history['val_loss'][0])\n",
    "    test_acc_list.append(history.history['val_accuracy'][0])\n",
    "\n",
    "\n",
    "    # Reset the cell states (required for stateful)\n",
    "    lstm.reset_states()\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the errors\n",
    "fig, ax = plt.subplots(nrows=4)\n",
    "_ = ax[0].plot(range(1, counter), train_loss_list)\n",
    "_ = ax[0].set_title('Binary Crossentropy Loss on train set')\n",
    "\n",
    "_ = ax[1].plot(range(1, counter), train_acc_list)\n",
    "_ = ax[1].set_title('Accuracy Loss on train set')\n",
    "\n",
    "_ = ax[2].plot(range(1, counter), test_loss_list)\n",
    "_ = ax[2].set_title('Binary Crossentropy Loss on test set')\n",
    "\n",
    "_ = ax[3].plot(range(1, counter), test_acc_list)\n",
    "_ = ax[3].set_title('Accuracy Loss on test set')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = 'BTC_{}ep.h5'.format(2000 + n_epochs_resume)\n",
    "lstm.save(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
